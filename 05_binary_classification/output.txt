Iteration    0 => Loss: 0.6931471806
Iteration    1 => Loss: 0.6825069293
Iteration    2 => Loss: 0.6744083486
Iteration    3 => Loss: 0.6681067786
Iteration    4 => Loss: 0.6630768990
Iteration    5 => Loss: 0.6589497728
Iteration    6 => Loss: 0.6554665412
Iteration    7 => Loss: 0.6524453711
Iteration    8 => Loss: 0.6497582323
Iteration    9 => Loss: 0.6473147052
Iteration   10 => Loss: 0.6450507197
Iteration   11 => Loss: 0.6429207200
Iteration   12 => Loss: 0.6408922027
Iteration   13 => Loss: 0.6389418963
Iteration   14 => Loss: 0.6370530809
Iteration   15 => Loss: 0.6352137000
Iteration   16 => Loss: 0.6334150260
Iteration   17 => Loss: 0.6316507140
Iteration   18 => Loss: 0.6299161283
Iteration   19 => Loss: 0.6282078621
Iteration   20 => Loss: 0.6265233943
Iteration   21 => Loss: 0.6248608425
Iteration   22 => Loss: 0.6232187866
Iteration   23 => Loss: 0.6215961410
Iteration   24 => Loss: 0.6199920630
Iteration   25 => Loss: 0.6184058865
Iteration   26 => Loss: 0.6168370737
Iteration   27 => Loss: 0.6152851810
Iteration   28 => Loss: 0.6137498334
Iteration   29 => Loss: 0.6122307064
Iteration   30 => Loss: 0.6107275129
Iteration   31 => Loss: 0.6092399935
Iteration   32 => Loss: 0.6077679095
Iteration   33 => Loss: 0.6063110379
Iteration   34 => Loss: 0.6048691677
Iteration   35 => Loss: 0.6034420971
Iteration   36 => Loss: 0.6020296318
Iteration   37 => Loss: 0.6006315833
Iteration   38 => Loss: 0.5992477680
Iteration   39 => Loss: 0.5978780064
Iteration   40 => Loss: 0.5965221225
Iteration   41 => Loss: 0.5951799437
Iteration   42 => Loss: 0.5938512999
Iteration   43 => Loss: 0.5925360238
Iteration   44 => Loss: 0.5912339506
Iteration   45 => Loss: 0.5899449178
Iteration   46 => Loss: 0.5886687650
Iteration   47 => Loss: 0.5874053340
Iteration   48 => Loss: 0.5861544689
Iteration   49 => Loss: 0.5849160155
Iteration   50 => Loss: 0.5836898220
Iteration   51 => Loss: 0.5824757383
Iteration   52 => Loss: 0.5812736162
Iteration   53 => Loss: 0.5800833097
Iteration   54 => Loss: 0.5789046744
Iteration   55 => Loss: 0.5777375679
Iteration   56 => Loss: 0.5765818497
Iteration   57 => Loss: 0.5754373810
Iteration   58 => Loss: 0.5743040249
Iteration   59 => Loss: 0.5731816462
Iteration   60 => Loss: 0.5720701115
Iteration   61 => Loss: 0.5709692891
Iteration   62 => Loss: 0.5698790491
Iteration   63 => Loss: 0.5687992633
Iteration   64 => Loss: 0.5677298051
Iteration   65 => Loss: 0.5666705495
Iteration   66 => Loss: 0.5656213734
Iteration   67 => Loss: 0.5645821551
Iteration   68 => Loss: 0.5635527745
Iteration   69 => Loss: 0.5625331131
Iteration   70 => Loss: 0.5615230542
Iteration   71 => Loss: 0.5605224823
Iteration   72 => Loss: 0.5595312835
Iteration   73 => Loss: 0.5585493456
Iteration   74 => Loss: 0.5575765578
Iteration   75 => Loss: 0.5566128106
Iteration   76 => Loss: 0.5556579961
Iteration   77 => Loss: 0.5547120078
Iteration   78 => Loss: 0.5537747407
Iteration   79 => Loss: 0.5528460911
Iteration   80 => Loss: 0.5519259566
Iteration   81 => Loss: 0.5510142362
Iteration   82 => Loss: 0.5501108304
Iteration   83 => Loss: 0.5492156409
Iteration   84 => Loss: 0.5483285707
Iteration   85 => Loss: 0.5474495240
Iteration   86 => Loss: 0.5465784065
Iteration   87 => Loss: 0.5457151250
Iteration   88 => Loss: 0.5448595875
Iteration   89 => Loss: 0.5440117033
Iteration   90 => Loss: 0.5431713829
Iteration   91 => Loss: 0.5423385379
Iteration   92 => Loss: 0.5415130813
Iteration   93 => Loss: 0.5406949270
Iteration   94 => Loss: 0.5398839902
Iteration   95 => Loss: 0.5390801870
Iteration   96 => Loss: 0.5382834350
Iteration   97 => Loss: 0.5374936525
Iteration   98 => Loss: 0.5367107592
Iteration   99 => Loss: 0.5359346756
Iteration  100 => Loss: 0.5351653234
Iteration  101 => Loss: 0.5344026254
Iteration  102 => Loss: 0.5336465051
Iteration  103 => Loss: 0.5328968874
Iteration  104 => Loss: 0.5321536981
Iteration  105 => Loss: 0.5314168637
Iteration  106 => Loss: 0.5306863120
Iteration  107 => Loss: 0.5299619715
Iteration  108 => Loss: 0.5292437720
Iteration  109 => Loss: 0.5285316438
Iteration  110 => Loss: 0.5278255183
Iteration  111 => Loss: 0.5271253279
Iteration  112 => Loss: 0.5264310058
Iteration  113 => Loss: 0.5257424860
Iteration  114 => Loss: 0.5250597034
Iteration  115 => Loss: 0.5243825939
Iteration  116 => Loss: 0.5237110941
Iteration  117 => Loss: 0.5230451414
Iteration  118 => Loss: 0.5223846741
Iteration  119 => Loss: 0.5217296312
Iteration  120 => Loss: 0.5210799528
Iteration  121 => Loss: 0.5204355793
Iteration  122 => Loss: 0.5197964522
Iteration  123 => Loss: 0.5191625137
Iteration  124 => Loss: 0.5185337068
Iteration  125 => Loss: 0.5179099751
Iteration  126 => Loss: 0.5172912630
Iteration  127 => Loss: 0.5166775156
Iteration  128 => Loss: 0.5160686789
Iteration  129 => Loss: 0.5154646992
Iteration  130 => Loss: 0.5148655238
Iteration  131 => Loss: 0.5142711006
Iteration  132 => Loss: 0.5136813782
Iteration  133 => Loss: 0.5130963059
Iteration  134 => Loss: 0.5125158334
Iteration  135 => Loss: 0.5119399113
Iteration  136 => Loss: 0.5113684908
Iteration  137 => Loss: 0.5108015237
Iteration  138 => Loss: 0.5102389622
Iteration  139 => Loss: 0.5096807595
Iteration  140 => Loss: 0.5091268692
Iteration  141 => Loss: 0.5085772453
Iteration  142 => Loss: 0.5080318428
Iteration  143 => Loss: 0.5074906168
Iteration  144 => Loss: 0.5069535234
Iteration  145 => Loss: 0.5064205190
Iteration  146 => Loss: 0.5058915606
Iteration  147 => Loss: 0.5053666058
Iteration  148 => Loss: 0.5048456126
Iteration  149 => Loss: 0.5043285397
Iteration  150 => Loss: 0.5038153462
Iteration  151 => Loss: 0.5033059917
Iteration  152 => Loss: 0.5028004364
Iteration  153 => Loss: 0.5022986410
Iteration  154 => Loss: 0.5018005666
Iteration  155 => Loss: 0.5013061747
Iteration  156 => Loss: 0.5008154276
Iteration  157 => Loss: 0.5003282877
Iteration  158 => Loss: 0.4998447182
Iteration  159 => Loss: 0.4993646825
Iteration  160 => Loss: 0.4988881445
Iteration  161 => Loss: 0.4984150686
Iteration  162 => Loss: 0.4979454197
Iteration  163 => Loss: 0.4974791631
Iteration  164 => Loss: 0.4970162643
Iteration  165 => Loss: 0.4965566896
Iteration  166 => Loss: 0.4961004054
Iteration  167 => Loss: 0.4956473786
Iteration  168 => Loss: 0.4951975767
Iteration  169 => Loss: 0.4947509673
Iteration  170 => Loss: 0.4943075185
Iteration  171 => Loss: 0.4938671990
Iteration  172 => Loss: 0.4934299775
Iteration  173 => Loss: 0.4929958233
Iteration  174 => Loss: 0.4925647061
Iteration  175 => Loss: 0.4921365959
Iteration  176 => Loss: 0.4917114630
Iteration  177 => Loss: 0.4912892782
Iteration  178 => Loss: 0.4908700125
Iteration  179 => Loss: 0.4904536374
Iteration  180 => Loss: 0.4900401247
Iteration  181 => Loss: 0.4896294464
Iteration  182 => Loss: 0.4892215749
Iteration  183 => Loss: 0.4888164831
Iteration  184 => Loss: 0.4884141440
Iteration  185 => Loss: 0.4880145311
Iteration  186 => Loss: 0.4876176179
Iteration  187 => Loss: 0.4872233787
Iteration  188 => Loss: 0.4868317876
Iteration  189 => Loss: 0.4864428194
Iteration  190 => Loss: 0.4860564490
Iteration  191 => Loss: 0.4856726515
Iteration  192 => Loss: 0.4852914027
Iteration  193 => Loss: 0.4849126781
Iteration  194 => Loss: 0.4845364540
Iteration  195 => Loss: 0.4841627067
Iteration  196 => Loss: 0.4837914128
Iteration  197 => Loss: 0.4834225493
Iteration  198 => Loss: 0.4830560933
Iteration  199 => Loss: 0.4826920224
Iteration  200 => Loss: 0.4823303141
Iteration  201 => Loss: 0.4819709464
Iteration  202 => Loss: 0.4816138977
Iteration  203 => Loss: 0.4812591462
Iteration  204 => Loss: 0.4809066709
Iteration  205 => Loss: 0.4805564505
Iteration  206 => Loss: 0.4802084644
Iteration  207 => Loss: 0.4798626919
Iteration  208 => Loss: 0.4795191127
Iteration  209 => Loss: 0.4791777068
Iteration  210 => Loss: 0.4788384542
Iteration  211 => Loss: 0.4785013353
Iteration  212 => Loss: 0.4781663307
Iteration  213 => Loss: 0.4778334211
Iteration  214 => Loss: 0.4775025877
Iteration  215 => Loss: 0.4771738116
Iteration  216 => Loss: 0.4768470742
Iteration  217 => Loss: 0.4765223572
Iteration  218 => Loss: 0.4761996425
Iteration  219 => Loss: 0.4758789121
Iteration  220 => Loss: 0.4755601482
Iteration  221 => Loss: 0.4752433333
Iteration  222 => Loss: 0.4749284501
Iteration  223 => Loss: 0.4746154813
Iteration  224 => Loss: 0.4743044100
Iteration  225 => Loss: 0.4739952195
Iteration  226 => Loss: 0.4736878931
Iteration  227 => Loss: 0.4733824144
Iteration  228 => Loss: 0.4730787672
Iteration  229 => Loss: 0.4727769353
Iteration  230 => Loss: 0.4724769030
Iteration  231 => Loss: 0.4721786545
Iteration  232 => Loss: 0.4718821743
Iteration  233 => Loss: 0.4715874470
Iteration  234 => Loss: 0.4712944573
Iteration  235 => Loss: 0.4710031903
Iteration  236 => Loss: 0.4707136311
Iteration  237 => Loss: 0.4704257650
Iteration  238 => Loss: 0.4701395774
Iteration  239 => Loss: 0.4698550539
Iteration  240 => Loss: 0.4695721802
Iteration  241 => Loss: 0.4692909423
Iteration  242 => Loss: 0.4690113263
Iteration  243 => Loss: 0.4687333183
Iteration  244 => Loss: 0.4684569047
Iteration  245 => Loss: 0.4681820719
Iteration  246 => Loss: 0.4679088067
Iteration  247 => Loss: 0.4676370958
Iteration  248 => Loss: 0.4673669262
Iteration  249 => Loss: 0.4670982849
Iteration  250 => Loss: 0.4668311590
Iteration  251 => Loss: 0.4665655360
Iteration  252 => Loss: 0.4663014033
Iteration  253 => Loss: 0.4660387485
Iteration  254 => Loss: 0.4657775594
Iteration  255 => Loss: 0.4655178237
Iteration  256 => Loss: 0.4652595295
Iteration  257 => Loss: 0.4650026648
Iteration  258 => Loss: 0.4647472180
Iteration  259 => Loss: 0.4644931773
Iteration  260 => Loss: 0.4642405313
Iteration  261 => Loss: 0.4639892685
Iteration  262 => Loss: 0.4637393776
Iteration  263 => Loss: 0.4634908475
Iteration  264 => Loss: 0.4632436671
Iteration  265 => Loss: 0.4629978255
Iteration  266 => Loss: 0.4627533118
Iteration  267 => Loss: 0.4625101153
Iteration  268 => Loss: 0.4622682254
Iteration  269 => Loss: 0.4620276316
Iteration  270 => Loss: 0.4617883236
Iteration  271 => Loss: 0.4615502909
Iteration  272 => Loss: 0.4613135234
Iteration  273 => Loss: 0.4610780110
Iteration  274 => Loss: 0.4608437438
Iteration  275 => Loss: 0.4606107119
Iteration  276 => Loss: 0.4603789054
Iteration  277 => Loss: 0.4601483148
Iteration  278 => Loss: 0.4599189303
Iteration  279 => Loss: 0.4596907426
Iteration  280 => Loss: 0.4594637421
Iteration  281 => Loss: 0.4592379197
Iteration  282 => Loss: 0.4590132661
Iteration  283 => Loss: 0.4587897722
Iteration  284 => Loss: 0.4585674289
Iteration  285 => Loss: 0.4583462274
Iteration  286 => Loss: 0.4581261587
Iteration  287 => Loss: 0.4579072141
Iteration  288 => Loss: 0.4576893849
Iteration  289 => Loss: 0.4574726625
Iteration  290 => Loss: 0.4572570385
Iteration  291 => Loss: 0.4570425043
Iteration  292 => Loss: 0.4568290517
Iteration  293 => Loss: 0.4566166724
Iteration  294 => Loss: 0.4564053582
Iteration  295 => Loss: 0.4561951009
Iteration  296 => Loss: 0.4559858927
Iteration  297 => Loss: 0.4557777254
Iteration  298 => Loss: 0.4555705913
Iteration  299 => Loss: 0.4553644826
Iteration  300 => Loss: 0.4551593915
Iteration  301 => Loss: 0.4549553105
Iteration  302 => Loss: 0.4547522318
Iteration  303 => Loss: 0.4545501481
Iteration  304 => Loss: 0.4543490518
Iteration  305 => Loss: 0.4541489358
Iteration  306 => Loss: 0.4539497925
Iteration  307 => Loss: 0.4537516150
Iteration  308 => Loss: 0.4535543959
Iteration  309 => Loss: 0.4533581282
Iteration  310 => Loss: 0.4531628049
Iteration  311 => Loss: 0.4529684190
Iteration  312 => Loss: 0.4527749638
Iteration  313 => Loss: 0.4525824322
Iteration  314 => Loss: 0.4523908177
Iteration  315 => Loss: 0.4522001135
Iteration  316 => Loss: 0.4520103129
Iteration  317 => Loss: 0.4518214094
Iteration  318 => Loss: 0.4516333966
Iteration  319 => Loss: 0.4514462679
Iteration  320 => Loss: 0.4512600170
Iteration  321 => Loss: 0.4510746375
Iteration  322 => Loss: 0.4508901232
Iteration  323 => Loss: 0.4507064679
Iteration  324 => Loss: 0.4505236653
Iteration  325 => Loss: 0.4503417096
Iteration  326 => Loss: 0.4501605945
Iteration  327 => Loss: 0.4499803140
Iteration  328 => Loss: 0.4498008624
Iteration  329 => Loss: 0.4496222337
Iteration  330 => Loss: 0.4494444220
Iteration  331 => Loss: 0.4492674216
Iteration  332 => Loss: 0.4490912268
Iteration  333 => Loss: 0.4489158320
Iteration  334 => Loss: 0.4487412314
Iteration  335 => Loss: 0.4485674196
Iteration  336 => Loss: 0.4483943910
Iteration  337 => Loss: 0.4482221402
Iteration  338 => Loss: 0.4480506618
Iteration  339 => Loss: 0.4478799503
Iteration  340 => Loss: 0.4477100006
Iteration  341 => Loss: 0.4475408072
Iteration  342 => Loss: 0.4473723650
Iteration  343 => Loss: 0.4472046689
Iteration  344 => Loss: 0.4470377136
Iteration  345 => Loss: 0.4468714941
Iteration  346 => Loss: 0.4467060054
Iteration  347 => Loss: 0.4465412424
Iteration  348 => Loss: 0.4463772002
Iteration  349 => Loss: 0.4462138740
Iteration  350 => Loss: 0.4460512588
Iteration  351 => Loss: 0.4458893498
Iteration  352 => Loss: 0.4457281422
Iteration  353 => Loss: 0.4455676314
Iteration  354 => Loss: 0.4454078125
Iteration  355 => Loss: 0.4452486811
Iteration  356 => Loss: 0.4450902323
Iteration  357 => Loss: 0.4449324618
Iteration  358 => Loss: 0.4447753648
Iteration  359 => Loss: 0.4446189371
Iteration  360 => Loss: 0.4444631740
Iteration  361 => Loss: 0.4443080711
Iteration  362 => Loss: 0.4441536242
Iteration  363 => Loss: 0.4439998288
Iteration  364 => Loss: 0.4438466806
Iteration  365 => Loss: 0.4436941755
Iteration  366 => Loss: 0.4435423090
Iteration  367 => Loss: 0.4433910772
Iteration  368 => Loss: 0.4432404757
Iteration  369 => Loss: 0.4430905005
Iteration  370 => Loss: 0.4429411475
Iteration  371 => Loss: 0.4427924126
Iteration  372 => Loss: 0.4426442918
Iteration  373 => Loss: 0.4424967811
Iteration  374 => Loss: 0.4423498766
Iteration  375 => Loss: 0.4422035744
Iteration  376 => Loss: 0.4420578705
Iteration  377 => Loss: 0.4419127612
Iteration  378 => Loss: 0.4417682425
Iteration  379 => Loss: 0.4416243108
Iteration  380 => Loss: 0.4414809622
Iteration  381 => Loss: 0.4413381931
Iteration  382 => Loss: 0.4411959997
Iteration  383 => Loss: 0.4410543783
Iteration  384 => Loss: 0.4409133254
Iteration  385 => Loss: 0.4407728373
Iteration  386 => Loss: 0.4406329105
Iteration  387 => Loss: 0.4404935414
Iteration  388 => Loss: 0.4403547265
Iteration  389 => Loss: 0.4402164623
Iteration  390 => Loss: 0.4400787454
Iteration  391 => Loss: 0.4399415724
Iteration  392 => Loss: 0.4398049397
Iteration  393 => Loss: 0.4396688442
Iteration  394 => Loss: 0.4395332823
Iteration  395 => Loss: 0.4393982508
Iteration  396 => Loss: 0.4392637465
Iteration  397 => Loss: 0.4391297660
Iteration  398 => Loss: 0.4389963061
Iteration  399 => Loss: 0.4388633636
Iteration  400 => Loss: 0.4387309353
Iteration  401 => Loss: 0.4385990181
Iteration  402 => Loss: 0.4384676088
Iteration  403 => Loss: 0.4383367043
Iteration  404 => Loss: 0.4382063016
Iteration  405 => Loss: 0.4380763975
Iteration  406 => Loss: 0.4379469890
Iteration  407 => Loss: 0.4378180731
Iteration  408 => Loss: 0.4376896469
Iteration  409 => Loss: 0.4375617074
Iteration  410 => Loss: 0.4374342516
Iteration  411 => Loss: 0.4373072766
Iteration  412 => Loss: 0.4371807796
Iteration  413 => Loss: 0.4370547576
Iteration  414 => Loss: 0.4369292078
Iteration  415 => Loss: 0.4368041275
Iteration  416 => Loss: 0.4366795137
Iteration  417 => Loss: 0.4365553637
Iteration  418 => Loss: 0.4364316747
Iteration  419 => Loss: 0.4363084441
Iteration  420 => Loss: 0.4361856690
Iteration  421 => Loss: 0.4360633469
Iteration  422 => Loss: 0.4359414750
Iteration  423 => Loss: 0.4358200506
Iteration  424 => Loss: 0.4356990713
Iteration  425 => Loss: 0.4355785342
Iteration  426 => Loss: 0.4354584369
Iteration  427 => Loss: 0.4353387767
Iteration  428 => Loss: 0.4352195512
Iteration  429 => Loss: 0.4351007578
Iteration  430 => Loss: 0.4349823939
Iteration  431 => Loss: 0.4348644571
Iteration  432 => Loss: 0.4347469450
Iteration  433 => Loss: 0.4346298550
Iteration  434 => Loss: 0.4345131847
Iteration  435 => Loss: 0.4343969317
Iteration  436 => Loss: 0.4342810936
Iteration  437 => Loss: 0.4341656680
Iteration  438 => Loss: 0.4340506526
Iteration  439 => Loss: 0.4339360451
Iteration  440 => Loss: 0.4338218430
Iteration  441 => Loss: 0.4337080441
Iteration  442 => Loss: 0.4335946461
Iteration  443 => Loss: 0.4334816467
Iteration  444 => Loss: 0.4333690436
Iteration  445 => Loss: 0.4332568347
Iteration  446 => Loss: 0.4331450177
Iteration  447 => Loss: 0.4330335903
Iteration  448 => Loss: 0.4329225505
Iteration  449 => Loss: 0.4328118960
Iteration  450 => Loss: 0.4327016246
Iteration  451 => Loss: 0.4325917343
Iteration  452 => Loss: 0.4324822229
Iteration  453 => Loss: 0.4323730882
Iteration  454 => Loss: 0.4322643283
Iteration  455 => Loss: 0.4321559410
Iteration  456 => Loss: 0.4320479242
Iteration  457 => Loss: 0.4319402759
Iteration  458 => Loss: 0.4318329941
Iteration  459 => Loss: 0.4317260768
Iteration  460 => Loss: 0.4316195219
Iteration  461 => Loss: 0.4315133275
Iteration  462 => Loss: 0.4314074915
Iteration  463 => Loss: 0.4313020121
Iteration  464 => Loss: 0.4311968872
Iteration  465 => Loss: 0.4310921150
Iteration  466 => Loss: 0.4309876936
Iteration  467 => Loss: 0.4308836209
Iteration  468 => Loss: 0.4307798952
Iteration  469 => Loss: 0.4306765146
Iteration  470 => Loss: 0.4305734772
Iteration  471 => Loss: 0.4304707811
Iteration  472 => Loss: 0.4303684246
Iteration  473 => Loss: 0.4302664057
Iteration  474 => Loss: 0.4301647227
Iteration  475 => Loss: 0.4300633738
Iteration  476 => Loss: 0.4299623572
Iteration  477 => Loss: 0.4298616712
Iteration  478 => Loss: 0.4297613139
Iteration  479 => Loss: 0.4296612837
Iteration  480 => Loss: 0.4295615787
Iteration  481 => Loss: 0.4294621974
Iteration  482 => Loss: 0.4293631379
Iteration  483 => Loss: 0.4292643985
Iteration  484 => Loss: 0.4291659777
Iteration  485 => Loss: 0.4290678737
Iteration  486 => Loss: 0.4289700848
Iteration  487 => Loss: 0.4288726095
Iteration  488 => Loss: 0.4287754460
Iteration  489 => Loss: 0.4286785927
Iteration  490 => Loss: 0.4285820481
Iteration  491 => Loss: 0.4284858105
Iteration  492 => Loss: 0.4283898783
Iteration  493 => Loss: 0.4282942500
Iteration  494 => Loss: 0.4281989240
Iteration  495 => Loss: 0.4281038987
Iteration  496 => Loss: 0.4280091725
Iteration  497 => Loss: 0.4279147440
Iteration  498 => Loss: 0.4278206116
Iteration  499 => Loss: 0.4277267738
Iteration  500 => Loss: 0.4276332291
Iteration  501 => Loss: 0.4275399760
Iteration  502 => Loss: 0.4274470129
Iteration  503 => Loss: 0.4273543386
Iteration  504 => Loss: 0.4272619513
Iteration  505 => Loss: 0.4271698498
Iteration  506 => Loss: 0.4270780326
Iteration  507 => Loss: 0.4269864982
Iteration  508 => Loss: 0.4268952452
Iteration  509 => Loss: 0.4268042721
Iteration  510 => Loss: 0.4267135777
Iteration  511 => Loss: 0.4266231605
Iteration  512 => Loss: 0.4265330190
Iteration  513 => Loss: 0.4264431520
Iteration  514 => Loss: 0.4263535580
Iteration  515 => Loss: 0.4262642358
Iteration  516 => Loss: 0.4261751839
Iteration  517 => Loss: 0.4260864009
Iteration  518 => Loss: 0.4259978857
Iteration  519 => Loss: 0.4259096368
Iteration  520 => Loss: 0.4258216530
Iteration  521 => Loss: 0.4257339328
Iteration  522 => Loss: 0.4256464752
Iteration  523 => Loss: 0.4255592786
Iteration  524 => Loss: 0.4254723420
Iteration  525 => Loss: 0.4253856639
Iteration  526 => Loss: 0.4252992432
Iteration  527 => Loss: 0.4252130785
Iteration  528 => Loss: 0.4251271687
Iteration  529 => Loss: 0.4250415125
Iteration  530 => Loss: 0.4249561086
Iteration  531 => Loss: 0.4248709559
Iteration  532 => Loss: 0.4247860532
Iteration  533 => Loss: 0.4247013992
Iteration  534 => Loss: 0.4246169927
Iteration  535 => Loss: 0.4245328325
Iteration  536 => Loss: 0.4244489175
Iteration  537 => Loss: 0.4243652465
Iteration  538 => Loss: 0.4242818183
Iteration  539 => Loss: 0.4241986318
Iteration  540 => Loss: 0.4241156858
Iteration  541 => Loss: 0.4240329792
Iteration  542 => Loss: 0.4239505108
Iteration  543 => Loss: 0.4238682795
Iteration  544 => Loss: 0.4237862841
Iteration  545 => Loss: 0.4237045237
Iteration  546 => Loss: 0.4236229970
Iteration  547 => Loss: 0.4235417030
Iteration  548 => Loss: 0.4234606405
Iteration  549 => Loss: 0.4233798085
Iteration  550 => Loss: 0.4232992060
Iteration  551 => Loss: 0.4232188317
Iteration  552 => Loss: 0.4231386847
Iteration  553 => Loss: 0.4230587640
Iteration  554 => Loss: 0.4229790683
Iteration  555 => Loss: 0.4228995968
Iteration  556 => Loss: 0.4228203484
Iteration  557 => Loss: 0.4227413220
Iteration  558 => Loss: 0.4226625166
Iteration  559 => Loss: 0.4225839312
Iteration  560 => Loss: 0.4225055648
Iteration  561 => Loss: 0.4224274164
Iteration  562 => Loss: 0.4223494850
Iteration  563 => Loss: 0.4222717695
Iteration  564 => Loss: 0.4221942691
Iteration  565 => Loss: 0.4221169826
Iteration  566 => Loss: 0.4220399092
Iteration  567 => Loss: 0.4219630479
Iteration  568 => Loss: 0.4218863977
Iteration  569 => Loss: 0.4218099576
Iteration  570 => Loss: 0.4217337268
Iteration  571 => Loss: 0.4216577042
Iteration  572 => Loss: 0.4215818889
Iteration  573 => Loss: 0.4215062800
Iteration  574 => Loss: 0.4214308766
Iteration  575 => Loss: 0.4213556777
Iteration  576 => Loss: 0.4212806825
Iteration  577 => Loss: 0.4212058899
Iteration  578 => Loss: 0.4211312992
Iteration  579 => Loss: 0.4210569094
Iteration  580 => Loss: 0.4209827196
Iteration  581 => Loss: 0.4209087289
Iteration  582 => Loss: 0.4208349365
Iteration  583 => Loss: 0.4207613414
Iteration  584 => Loss: 0.4206879428
Iteration  585 => Loss: 0.4206147399
Iteration  586 => Loss: 0.4205417317
Iteration  587 => Loss: 0.4204689174
Iteration  588 => Loss: 0.4203962963
Iteration  589 => Loss: 0.4203238673
Iteration  590 => Loss: 0.4202516297
Iteration  591 => Loss: 0.4201795826
Iteration  592 => Loss: 0.4201077253
Iteration  593 => Loss: 0.4200360568
Iteration  594 => Loss: 0.4199645764
Iteration  595 => Loss: 0.4198932832
Iteration  596 => Loss: 0.4198221765
Iteration  597 => Loss: 0.4197512554
Iteration  598 => Loss: 0.4196805192
Iteration  599 => Loss: 0.4196099670
Iteration  600 => Loss: 0.4195395980
Iteration  601 => Loss: 0.4194694115
Iteration  602 => Loss: 0.4193994067
Iteration  603 => Loss: 0.4193295827
Iteration  604 => Loss: 0.4192599389
Iteration  605 => Loss: 0.4191904744
Iteration  606 => Loss: 0.4191211886
Iteration  607 => Loss: 0.4190520805
Iteration  608 => Loss: 0.4189831496
Iteration  609 => Loss: 0.4189143950
Iteration  610 => Loss: 0.4188458159
Iteration  611 => Loss: 0.4187774118
Iteration  612 => Loss: 0.4187091817
Iteration  613 => Loss: 0.4186411249
Iteration  614 => Loss: 0.4185732409
Iteration  615 => Loss: 0.4185055287
Iteration  616 => Loss: 0.4184379878
Iteration  617 => Loss: 0.4183706173
Iteration  618 => Loss: 0.4183034166
Iteration  619 => Loss: 0.4182363850
Iteration  620 => Loss: 0.4181695217
Iteration  621 => Loss: 0.4181028261
Iteration  622 => Loss: 0.4180362975
Iteration  623 => Loss: 0.4179699352
Iteration  624 => Loss: 0.4179037384
Iteration  625 => Loss: 0.4178377065
Iteration  626 => Loss: 0.4177718389
Iteration  627 => Loss: 0.4177061348
Iteration  628 => Loss: 0.4176405936
Iteration  629 => Loss: 0.4175752146
Iteration  630 => Loss: 0.4175099972
Iteration  631 => Loss: 0.4174449406
Iteration  632 => Loss: 0.4173800443
Iteration  633 => Loss: 0.4173153076
Iteration  634 => Loss: 0.4172507298
Iteration  635 => Loss: 0.4171863103
Iteration  636 => Loss: 0.4171220484
Iteration  637 => Loss: 0.4170579435
Iteration  638 => Loss: 0.4169939950
Iteration  639 => Loss: 0.4169302023
Iteration  640 => Loss: 0.4168665646
Iteration  641 => Loss: 0.4168030815
Iteration  642 => Loss: 0.4167397522
Iteration  643 => Loss: 0.4166765762
Iteration  644 => Loss: 0.4166135528
Iteration  645 => Loss: 0.4165506815
Iteration  646 => Loss: 0.4164879615
Iteration  647 => Loss: 0.4164253924
Iteration  648 => Loss: 0.4163629736
Iteration  649 => Loss: 0.4163007043
Iteration  650 => Loss: 0.4162385841
Iteration  651 => Loss: 0.4161766123
Iteration  652 => Loss: 0.4161147884
Iteration  653 => Loss: 0.4160531118
Iteration  654 => Loss: 0.4159915818
Iteration  655 => Loss: 0.4159301980
Iteration  656 => Loss: 0.4158689597
Iteration  657 => Loss: 0.4158078664
Iteration  658 => Loss: 0.4157469175
Iteration  659 => Loss: 0.4156861125
Iteration  660 => Loss: 0.4156254507
Iteration  661 => Loss: 0.4155649317
Iteration  662 => Loss: 0.4155045548
Iteration  663 => Loss: 0.4154443196
Iteration  664 => Loss: 0.4153842254
Iteration  665 => Loss: 0.4153242718
Iteration  666 => Loss: 0.4152644581
Iteration  667 => Loss: 0.4152047839
Iteration  668 => Loss: 0.4151452486
Iteration  669 => Loss: 0.4150858517
Iteration  670 => Loss: 0.4150265926
Iteration  671 => Loss: 0.4149674708
Iteration  672 => Loss: 0.4149084858
Iteration  673 => Loss: 0.4148496371
Iteration  674 => Loss: 0.4147909241
Iteration  675 => Loss: 0.4147323463
Iteration  676 => Loss: 0.4146739033
Iteration  677 => Loss: 0.4146155945
Iteration  678 => Loss: 0.4145574193
Iteration  679 => Loss: 0.4144993774
Iteration  680 => Loss: 0.4144414681
Iteration  681 => Loss: 0.4143836911
Iteration  682 => Loss: 0.4143260457
Iteration  683 => Loss: 0.4142685315
Iteration  684 => Loss: 0.4142111480
Iteration  685 => Loss: 0.4141538947
Iteration  686 => Loss: 0.4140967712
Iteration  687 => Loss: 0.4140397769
Iteration  688 => Loss: 0.4139829113
Iteration  689 => Loss: 0.4139261740
Iteration  690 => Loss: 0.4138695646
Iteration  691 => Loss: 0.4138130824
Iteration  692 => Loss: 0.4137567271
Iteration  693 => Loss: 0.4137004982
Iteration  694 => Loss: 0.4136443952
Iteration  695 => Loss: 0.4135884177
Iteration  696 => Loss: 0.4135325652
Iteration  697 => Loss: 0.4134768372
Iteration  698 => Loss: 0.4134212332
Iteration  699 => Loss: 0.4133657529
Iteration  700 => Loss: 0.4133103958
Iteration  701 => Loss: 0.4132551613
Iteration  702 => Loss: 0.4132000492
Iteration  703 => Loss: 0.4131450588
Iteration  704 => Loss: 0.4130901899
Iteration  705 => Loss: 0.4130354419
Iteration  706 => Loss: 0.4129808143
Iteration  707 => Loss: 0.4129263069
Iteration  708 => Loss: 0.4128719191
Iteration  709 => Loss: 0.4128176504
Iteration  710 => Loss: 0.4127635006
Iteration  711 => Loss: 0.4127094691
Iteration  712 => Loss: 0.4126555555
Iteration  713 => Loss: 0.4126017594
Iteration  714 => Loss: 0.4125480803
Iteration  715 => Loss: 0.4124945180
Iteration  716 => Loss: 0.4124410718
Iteration  717 => Loss: 0.4123877415
Iteration  718 => Loss: 0.4123345266
Iteration  719 => Loss: 0.4122814267
Iteration  720 => Loss: 0.4122284413
Iteration  721 => Loss: 0.4121755702
Iteration  722 => Loss: 0.4121228128
Iteration  723 => Loss: 0.4120701688
Iteration  724 => Loss: 0.4120176378
Iteration  725 => Loss: 0.4119652194
Iteration  726 => Loss: 0.4119129132
Iteration  727 => Loss: 0.4118607187
Iteration  728 => Loss: 0.4118086357
Iteration  729 => Loss: 0.4117566636
Iteration  730 => Loss: 0.4117048022
Iteration  731 => Loss: 0.4116530510
Iteration  732 => Loss: 0.4116014097
Iteration  733 => Loss: 0.4115498778
Iteration  734 => Loss: 0.4114984550
Iteration  735 => Loss: 0.4114471409
Iteration  736 => Loss: 0.4113959352
Iteration  737 => Loss: 0.4113448374
Iteration  738 => Loss: 0.4112938472
Iteration  739 => Loss: 0.4112429642
Iteration  740 => Loss: 0.4111921880
Iteration  741 => Loss: 0.4111415184
Iteration  742 => Loss: 0.4110909548
Iteration  743 => Loss: 0.4110404970
Iteration  744 => Loss: 0.4109901445
Iteration  745 => Loss: 0.4109398971
Iteration  746 => Loss: 0.4108897544
Iteration  747 => Loss: 0.4108397159
Iteration  748 => Loss: 0.4107897815
Iteration  749 => Loss: 0.4107399506
Iteration  750 => Loss: 0.4106902229
Iteration  751 => Loss: 0.4106405982
Iteration  752 => Loss: 0.4105910760
Iteration  753 => Loss: 0.4105416560
Iteration  754 => Loss: 0.4104923379
Iteration  755 => Loss: 0.4104431213
Iteration  756 => Loss: 0.4103940059
Iteration  757 => Loss: 0.4103449913
Iteration  758 => Loss: 0.4102960772
Iteration  759 => Loss: 0.4102472632
Iteration  760 => Loss: 0.4101985491
Iteration  761 => Loss: 0.4101499345
Iteration  762 => Loss: 0.4101014190
Iteration  763 => Loss: 0.4100530024
Iteration  764 => Loss: 0.4100046843
Iteration  765 => Loss: 0.4099564644
Iteration  766 => Loss: 0.4099083423
Iteration  767 => Loss: 0.4098603177
Iteration  768 => Loss: 0.4098123903
Iteration  769 => Loss: 0.4097645598
Iteration  770 => Loss: 0.4097168259
Iteration  771 => Loss: 0.4096691882
Iteration  772 => Loss: 0.4096216465
Iteration  773 => Loss: 0.4095742004
Iteration  774 => Loss: 0.4095268495
Iteration  775 => Loss: 0.4094795937
Iteration  776 => Loss: 0.4094324326
Iteration  777 => Loss: 0.4093853658
Iteration  778 => Loss: 0.4093383931
Iteration  779 => Loss: 0.4092915141
Iteration  780 => Loss: 0.4092447286
Iteration  781 => Loss: 0.4091980362
Iteration  782 => Loss: 0.4091514367
Iteration  783 => Loss: 0.4091049298
Iteration  784 => Loss: 0.4090585151
Iteration  785 => Loss: 0.4090121923
Iteration  786 => Loss: 0.4089659613
Iteration  787 => Loss: 0.4089198215
Iteration  788 => Loss: 0.4088737729
Iteration  789 => Loss: 0.4088278150
Iteration  790 => Loss: 0.4087819476
Iteration  791 => Loss: 0.4087361704
Iteration  792 => Loss: 0.4086904831
Iteration  793 => Loss: 0.4086448854
Iteration  794 => Loss: 0.4085993771
Iteration  795 => Loss: 0.4085539579
Iteration  796 => Loss: 0.4085086274
Iteration  797 => Loss: 0.4084633854
Iteration  798 => Loss: 0.4084182316
Iteration  799 => Loss: 0.4083731657
Iteration  800 => Loss: 0.4083281875
Iteration  801 => Loss: 0.4082832967
Iteration  802 => Loss: 0.4082384929
Iteration  803 => Loss: 0.4081937760
Iteration  804 => Loss: 0.4081491457
Iteration  805 => Loss: 0.4081046016
Iteration  806 => Loss: 0.4080601436
Iteration  807 => Loss: 0.4080157713
Iteration  808 => Loss: 0.4079714845
Iteration  809 => Loss: 0.4079272829
Iteration  810 => Loss: 0.4078831663
Iteration  811 => Loss: 0.4078391343
Iteration  812 => Loss: 0.4077951868
Iteration  813 => Loss: 0.4077513234
Iteration  814 => Loss: 0.4077075439
Iteration  815 => Loss: 0.4076638481
Iteration  816 => Loss: 0.4076202356
Iteration  817 => Loss: 0.4075767063
Iteration  818 => Loss: 0.4075332598
Iteration  819 => Loss: 0.4074898960
Iteration  820 => Loss: 0.4074466145
Iteration  821 => Loss: 0.4074034152
Iteration  822 => Loss: 0.4073602977
Iteration  823 => Loss: 0.4073172618
Iteration  824 => Loss: 0.4072743072
Iteration  825 => Loss: 0.4072314338
Iteration  826 => Loss: 0.4071886413
Iteration  827 => Loss: 0.4071459293
Iteration  828 => Loss: 0.4071032978
Iteration  829 => Loss: 0.4070607463
Iteration  830 => Loss: 0.4070182748
Iteration  831 => Loss: 0.4069758829
Iteration  832 => Loss: 0.4069335704
Iteration  833 => Loss: 0.4068913371
Iteration  834 => Loss: 0.4068491827
Iteration  835 => Loss: 0.4068071070
Iteration  836 => Loss: 0.4067651098
Iteration  837 => Loss: 0.4067231908
Iteration  838 => Loss: 0.4066813498
Iteration  839 => Loss: 0.4066395865
Iteration  840 => Loss: 0.4065979008
Iteration  841 => Loss: 0.4065562924
Iteration  842 => Loss: 0.4065147610
Iteration  843 => Loss: 0.4064733064
Iteration  844 => Loss: 0.4064319285
Iteration  845 => Loss: 0.4063906269
Iteration  846 => Loss: 0.4063494015
Iteration  847 => Loss: 0.4063082520
Iteration  848 => Loss: 0.4062671783
Iteration  849 => Loss: 0.4062261800
Iteration  850 => Loss: 0.4061852569
Iteration  851 => Loss: 0.4061444089
Iteration  852 => Loss: 0.4061036357
Iteration  853 => Loss: 0.4060629372
Iteration  854 => Loss: 0.4060223130
Iteration  855 => Loss: 0.4059817629
Iteration  856 => Loss: 0.4059412868
Iteration  857 => Loss: 0.4059008844
Iteration  858 => Loss: 0.4058605556
Iteration  859 => Loss: 0.4058203000
Iteration  860 => Loss: 0.4057801176
Iteration  861 => Loss: 0.4057400080
Iteration  862 => Loss: 0.4056999711
Iteration  863 => Loss: 0.4056600066
Iteration  864 => Loss: 0.4056201144
Iteration  865 => Loss: 0.4055802942
Iteration  866 => Loss: 0.4055405459
Iteration  867 => Loss: 0.4055008691
Iteration  868 => Loss: 0.4054612638
Iteration  869 => Loss: 0.4054217297
Iteration  870 => Loss: 0.4053822667
Iteration  871 => Loss: 0.4053428744
Iteration  872 => Loss: 0.4053035527
Iteration  873 => Loss: 0.4052643014
Iteration  874 => Loss: 0.4052251204
Iteration  875 => Loss: 0.4051860093
Iteration  876 => Loss: 0.4051469680
Iteration  877 => Loss: 0.4051079964
Iteration  878 => Loss: 0.4050690941
Iteration  879 => Loss: 0.4050302611
Iteration  880 => Loss: 0.4049914970
Iteration  881 => Loss: 0.4049528018
Iteration  882 => Loss: 0.4049141753
Iteration  883 => Loss: 0.4048756171
Iteration  884 => Loss: 0.4048371272
Iteration  885 => Loss: 0.4047987053
Iteration  886 => Loss: 0.4047603513
Iteration  887 => Loss: 0.4047220650
Iteration  888 => Loss: 0.4046838461
Iteration  889 => Loss: 0.4046456946
Iteration  890 => Loss: 0.4046076101
Iteration  891 => Loss: 0.4045695926
Iteration  892 => Loss: 0.4045316418
Iteration  893 => Loss: 0.4044937575
Iteration  894 => Loss: 0.4044559396
Iteration  895 => Loss: 0.4044181878
Iteration  896 => Loss: 0.4043805021
Iteration  897 => Loss: 0.4043428821
Iteration  898 => Loss: 0.4043053278
Iteration  899 => Loss: 0.4042678390
Iteration  900 => Loss: 0.4042304154
Iteration  901 => Loss: 0.4041930568
Iteration  902 => Loss: 0.4041557632
Iteration  903 => Loss: 0.4041185344
Iteration  904 => Loss: 0.4040813700
Iteration  905 => Loss: 0.4040442701
Iteration  906 => Loss: 0.4040072343
Iteration  907 => Loss: 0.4039702626
Iteration  908 => Loss: 0.4039333547
Iteration  909 => Loss: 0.4038965105
Iteration  910 => Loss: 0.4038597298
Iteration  911 => Loss: 0.4038230125
Iteration  912 => Loss: 0.4037863583
Iteration  913 => Loss: 0.4037497670
Iteration  914 => Loss: 0.4037132386
Iteration  915 => Loss: 0.4036767729
Iteration  916 => Loss: 0.4036403696
Iteration  917 => Loss: 0.4036040286
Iteration  918 => Loss: 0.4035677498
Iteration  919 => Loss: 0.4035315329
Iteration  920 => Loss: 0.4034953779
Iteration  921 => Loss: 0.4034592845
Iteration  922 => Loss: 0.4034232526
Iteration  923 => Loss: 0.4033872820
Iteration  924 => Loss: 0.4033513725
Iteration  925 => Loss: 0.4033155240
Iteration  926 => Loss: 0.4032797364
Iteration  927 => Loss: 0.4032440094
Iteration  928 => Loss: 0.4032083429
Iteration  929 => Loss: 0.4031727367
Iteration  930 => Loss: 0.4031371907
Iteration  931 => Loss: 0.4031017048
Iteration  932 => Loss: 0.4030662787
Iteration  933 => Loss: 0.4030309123
Iteration  934 => Loss: 0.4029956055
Iteration  935 => Loss: 0.4029603580
Iteration  936 => Loss: 0.4029251698
Iteration  937 => Loss: 0.4028900407
Iteration  938 => Loss: 0.4028549704
Iteration  939 => Loss: 0.4028199590
Iteration  940 => Loss: 0.4027850061
Iteration  941 => Loss: 0.4027501118
Iteration  942 => Loss: 0.4027152757
Iteration  943 => Loss: 0.4026804978
Iteration  944 => Loss: 0.4026457778
Iteration  945 => Loss: 0.4026111158
Iteration  946 => Loss: 0.4025765114
Iteration  947 => Loss: 0.4025419646
Iteration  948 => Loss: 0.4025074752
Iteration  949 => Loss: 0.4024730431
Iteration  950 => Loss: 0.4024386680
Iteration  951 => Loss: 0.4024043499
Iteration  952 => Loss: 0.4023700886
Iteration  953 => Loss: 0.4023358840
Iteration  954 => Loss: 0.4023017359
Iteration  955 => Loss: 0.4022676442
Iteration  956 => Loss: 0.4022336087
Iteration  957 => Loss: 0.4021996293
Iteration  958 => Loss: 0.4021657059
Iteration  959 => Loss: 0.4021318382
Iteration  960 => Loss: 0.4020980262
Iteration  961 => Loss: 0.4020642697
Iteration  962 => Loss: 0.4020305686
Iteration  963 => Loss: 0.4019969227
Iteration  964 => Loss: 0.4019633319
Iteration  965 => Loss: 0.4019297960
Iteration  966 => Loss: 0.4018963150
Iteration  967 => Loss: 0.4018628886
Iteration  968 => Loss: 0.4018295168
Iteration  969 => Loss: 0.4017961994
Iteration  970 => Loss: 0.4017629362
Iteration  971 => Loss: 0.4017297271
Iteration  972 => Loss: 0.4016965720
Iteration  973 => Loss: 0.4016634708
Iteration  974 => Loss: 0.4016304233
Iteration  975 => Loss: 0.4015974294
Iteration  976 => Loss: 0.4015644889
Iteration  977 => Loss: 0.4015316017
Iteration  978 => Loss: 0.4014987677
Iteration  979 => Loss: 0.4014659867
Iteration  980 => Loss: 0.4014332587
Iteration  981 => Loss: 0.4014005834
Iteration  982 => Loss: 0.4013679608
Iteration  983 => Loss: 0.4013353907
Iteration  984 => Loss: 0.4013028730
Iteration  985 => Loss: 0.4012704076
Iteration  986 => Loss: 0.4012379942
Iteration  987 => Loss: 0.4012056329
Iteration  988 => Loss: 0.4011733234
Iteration  989 => Loss: 0.4011410657
Iteration  990 => Loss: 0.4011088596
Iteration  991 => Loss: 0.4010767050
Iteration  992 => Loss: 0.4010446018
Iteration  993 => Loss: 0.4010125497
Iteration  994 => Loss: 0.4009805488
Iteration  995 => Loss: 0.4009485989
Iteration  996 => Loss: 0.4009166998
Iteration  997 => Loss: 0.4008848515
Iteration  998 => Loss: 0.4008530538
Iteration  999 => Loss: 0.4008213065
Iteration 1000 => Loss: 0.4007896097
Iteration 1001 => Loss: 0.4007579630
Iteration 1002 => Loss: 0.4007263665
Iteration 1003 => Loss: 0.4006948200
Iteration 1004 => Loss: 0.4006633234
Iteration 1005 => Loss: 0.4006318765
Iteration 1006 => Loss: 0.4006004792
Iteration 1007 => Loss: 0.4005691315
Iteration 1008 => Loss: 0.4005378331
Iteration 1009 => Loss: 0.4005065840
Iteration 1010 => Loss: 0.4004753841
Iteration 1011 => Loss: 0.4004442332
Iteration 1012 => Loss: 0.4004131313
Iteration 1013 => Loss: 0.4003820781
Iteration 1014 => Loss: 0.4003510736
Iteration 1015 => Loss: 0.4003201177
Iteration 1016 => Loss: 0.4002892103
Iteration 1017 => Loss: 0.4002583512
Iteration 1018 => Loss: 0.4002275403
Iteration 1019 => Loss: 0.4001967775
Iteration 1020 => Loss: 0.4001660627
Iteration 1021 => Loss: 0.4001353957
Iteration 1022 => Loss: 0.4001047766
Iteration 1023 => Loss: 0.4000742051
Iteration 1024 => Loss: 0.4000436811
Iteration 1025 => Loss: 0.4000132045
Iteration 1026 => Loss: 0.3999827753
Iteration 1027 => Loss: 0.3999523933
Iteration 1028 => Loss: 0.3999220583
Iteration 1029 => Loss: 0.3998917703
Iteration 1030 => Loss: 0.3998615292
Iteration 1031 => Loss: 0.3998313349
Iteration 1032 => Loss: 0.3998011871
Iteration 1033 => Loss: 0.3997710860
Iteration 1034 => Loss: 0.3997410312
Iteration 1035 => Loss: 0.3997110228
Iteration 1036 => Loss: 0.3996810606
Iteration 1037 => Loss: 0.3996511444
Iteration 1038 => Loss: 0.3996212743
Iteration 1039 => Loss: 0.3995914501
Iteration 1040 => Loss: 0.3995616716
Iteration 1041 => Loss: 0.3995319388
Iteration 1042 => Loss: 0.3995022516
Iteration 1043 => Loss: 0.3994726098
Iteration 1044 => Loss: 0.3994430134
Iteration 1045 => Loss: 0.3994134623
Iteration 1046 => Loss: 0.3993839563
Iteration 1047 => Loss: 0.3993544953
Iteration 1048 => Loss: 0.3993250793
Iteration 1049 => Loss: 0.3992957081
Iteration 1050 => Loss: 0.3992663816
Iteration 1051 => Loss: 0.3992370997
Iteration 1052 => Loss: 0.3992078624
Iteration 1053 => Loss: 0.3991786695
Iteration 1054 => Loss: 0.3991495209
Iteration 1055 => Loss: 0.3991204166
Iteration 1056 => Loss: 0.3990913563
Iteration 1057 => Loss: 0.3990623401
Iteration 1058 => Loss: 0.3990333678
Iteration 1059 => Loss: 0.3990044392
Iteration 1060 => Loss: 0.3989755545
Iteration 1061 => Loss: 0.3989467133
Iteration 1062 => Loss: 0.3989179156
Iteration 1063 => Loss: 0.3988891614
Iteration 1064 => Loss: 0.3988604504
Iteration 1065 => Loss: 0.3988317827
Iteration 1066 => Loss: 0.3988031581
Iteration 1067 => Loss: 0.3987745766
Iteration 1068 => Loss: 0.3987460379
Iteration 1069 => Loss: 0.3987175421
Iteration 1070 => Loss: 0.3986890891
Iteration 1071 => Loss: 0.3986606786
Iteration 1072 => Loss: 0.3986323107
Iteration 1073 => Loss: 0.3986039853
Iteration 1074 => Loss: 0.3985757022
Iteration 1075 => Loss: 0.3985474613
Iteration 1076 => Loss: 0.3985192626
Iteration 1077 => Loss: 0.3984911060
Iteration 1078 => Loss: 0.3984629913
Iteration 1079 => Loss: 0.3984349185
Iteration 1080 => Loss: 0.3984068875
Iteration 1081 => Loss: 0.3983788982
Iteration 1082 => Loss: 0.3983509505
Iteration 1083 => Loss: 0.3983230443
Iteration 1084 => Loss: 0.3982951795
Iteration 1085 => Loss: 0.3982673560
Iteration 1086 => Loss: 0.3982395738
Iteration 1087 => Loss: 0.3982118327
Iteration 1088 => Loss: 0.3981841326
Iteration 1089 => Loss: 0.3981564735
Iteration 1090 => Loss: 0.3981288552
Iteration 1091 => Loss: 0.3981012778
Iteration 1092 => Loss: 0.3980737410
Iteration 1093 => Loss: 0.3980462448
Iteration 1094 => Loss: 0.3980187891
Iteration 1095 => Loss: 0.3979913738
Iteration 1096 => Loss: 0.3979639988
Iteration 1097 => Loss: 0.3979366641
Iteration 1098 => Loss: 0.3979093696
Iteration 1099 => Loss: 0.3978821151
Iteration 1100 => Loss: 0.3978549005
Iteration 1101 => Loss: 0.3978277259
Iteration 1102 => Loss: 0.3978005910
Iteration 1103 => Loss: 0.3977734959
Iteration 1104 => Loss: 0.3977464404
Iteration 1105 => Loss: 0.3977194244
Iteration 1106 => Loss: 0.3976924479
Iteration 1107 => Loss: 0.3976655108
Iteration 1108 => Loss: 0.3976386129
Iteration 1109 => Loss: 0.3976117543
Iteration 1110 => Loss: 0.3975849347
Iteration 1111 => Loss: 0.3975581542
Iteration 1112 => Loss: 0.3975314126
Iteration 1113 => Loss: 0.3975047099
Iteration 1114 => Loss: 0.3974780459
Iteration 1115 => Loss: 0.3974514207
Iteration 1116 => Loss: 0.3974248340
Iteration 1117 => Loss: 0.3973982859
Iteration 1118 => Loss: 0.3973717762
Iteration 1119 => Loss: 0.3973453049
Iteration 1120 => Loss: 0.3973188719
Iteration 1121 => Loss: 0.3972924770
Iteration 1122 => Loss: 0.3972661203
Iteration 1123 => Loss: 0.3972398016
Iteration 1124 => Loss: 0.3972135208
Iteration 1125 => Loss: 0.3971872780
Iteration 1126 => Loss: 0.3971610729
Iteration 1127 => Loss: 0.3971349055
Iteration 1128 => Loss: 0.3971087757
Iteration 1129 => Loss: 0.3970826835
Iteration 1130 => Loss: 0.3970566288
Iteration 1131 => Loss: 0.3970306114
Iteration 1132 => Loss: 0.3970046314
Iteration 1133 => Loss: 0.3969786886
Iteration 1134 => Loss: 0.3969527829
Iteration 1135 => Loss: 0.3969269143
Iteration 1136 => Loss: 0.3969010827
Iteration 1137 => Loss: 0.3968752881
Iteration 1138 => Loss: 0.3968495302
Iteration 1139 => Loss: 0.3968238092
Iteration 1140 => Loss: 0.3967981248
Iteration 1141 => Loss: 0.3967724770
Iteration 1142 => Loss: 0.3967468657
Iteration 1143 => Loss: 0.3967212909
Iteration 1144 => Loss: 0.3966957525
Iteration 1145 => Loss: 0.3966702504
Iteration 1146 => Loss: 0.3966447845
Iteration 1147 => Loss: 0.3966193547
Iteration 1148 => Loss: 0.3965939610
Iteration 1149 => Loss: 0.3965686033
Iteration 1150 => Loss: 0.3965432816
Iteration 1151 => Loss: 0.3965179957
Iteration 1152 => Loss: 0.3964927455
Iteration 1153 => Loss: 0.3964675311
Iteration 1154 => Loss: 0.3964423523
Iteration 1155 => Loss: 0.3964172090
Iteration 1156 => Loss: 0.3963921012
Iteration 1157 => Loss: 0.3963670288
Iteration 1158 => Loss: 0.3963419918
Iteration 1159 => Loss: 0.3963169900
Iteration 1160 => Loss: 0.3962920234
Iteration 1161 => Loss: 0.3962670919
Iteration 1162 => Loss: 0.3962421954
Iteration 1163 => Loss: 0.3962173339
Iteration 1164 => Loss: 0.3961925074
Iteration 1165 => Loss: 0.3961677156
Iteration 1166 => Loss: 0.3961429586
Iteration 1167 => Loss: 0.3961182362
Iteration 1168 => Loss: 0.3960935485
Iteration 1169 => Loss: 0.3960688953
Iteration 1170 => Loss: 0.3960442766
Iteration 1171 => Loss: 0.3960196923
Iteration 1172 => Loss: 0.3959951423
Iteration 1173 => Loss: 0.3959706265
Iteration 1174 => Loss: 0.3959461450
Iteration 1175 => Loss: 0.3959216976
Iteration 1176 => Loss: 0.3958972842
Iteration 1177 => Loss: 0.3958729048
Iteration 1178 => Loss: 0.3958485593
Iteration 1179 => Loss: 0.3958242476
Iteration 1180 => Loss: 0.3957999697
Iteration 1181 => Loss: 0.3957757256
Iteration 1182 => Loss: 0.3957515150
Iteration 1183 => Loss: 0.3957273381
Iteration 1184 => Loss: 0.3957031946
Iteration 1185 => Loss: 0.3956790845
Iteration 1186 => Loss: 0.3956550079
Iteration 1187 => Loss: 0.3956309645
Iteration 1188 => Loss: 0.3956069544
Iteration 1189 => Loss: 0.3955829774
Iteration 1190 => Loss: 0.3955590335
Iteration 1191 => Loss: 0.3955351227
Iteration 1192 => Loss: 0.3955112448
Iteration 1193 => Loss: 0.3954873998
Iteration 1194 => Loss: 0.3954635876
Iteration 1195 => Loss: 0.3954398082
Iteration 1196 => Loss: 0.3954160616
Iteration 1197 => Loss: 0.3953923475
Iteration 1198 => Loss: 0.3953686660
Iteration 1199 => Loss: 0.3953450171
Iteration 1200 => Loss: 0.3953214005
Iteration 1201 => Loss: 0.3952978164
Iteration 1202 => Loss: 0.3952742645
Iteration 1203 => Loss: 0.3952507449
Iteration 1204 => Loss: 0.3952272575
Iteration 1205 => Loss: 0.3952038023
Iteration 1206 => Loss: 0.3951803790
Iteration 1207 => Loss: 0.3951569878
Iteration 1208 => Loss: 0.3951336285
Iteration 1209 => Loss: 0.3951103010
Iteration 1210 => Loss: 0.3950870054
Iteration 1211 => Loss: 0.3950637415
Iteration 1212 => Loss: 0.3950405093
Iteration 1213 => Loss: 0.3950173087
Iteration 1214 => Loss: 0.3949941397
Iteration 1215 => Loss: 0.3949710021
Iteration 1216 => Loss: 0.3949478960
Iteration 1217 => Loss: 0.3949248212
Iteration 1218 => Loss: 0.3949017778
Iteration 1219 => Loss: 0.3948787656
Iteration 1220 => Loss: 0.3948557846
Iteration 1221 => Loss: 0.3948328347
Iteration 1222 => Loss: 0.3948099158
Iteration 1223 => Loss: 0.3947870280
Iteration 1224 => Loss: 0.3947641711
Iteration 1225 => Loss: 0.3947413451
Iteration 1226 => Loss: 0.3947185499
Iteration 1227 => Loss: 0.3946957855
Iteration 1228 => Loss: 0.3946730518
Iteration 1229 => Loss: 0.3946503487
Iteration 1230 => Loss: 0.3946276762
Iteration 1231 => Loss: 0.3946050342
Iteration 1232 => Loss: 0.3945824227
Iteration 1233 => Loss: 0.3945598416
Iteration 1234 => Loss: 0.3945372909
Iteration 1235 => Loss: 0.3945147704
Iteration 1236 => Loss: 0.3944922802
Iteration 1237 => Loss: 0.3944698201
Iteration 1238 => Loss: 0.3944473901
Iteration 1239 => Loss: 0.3944249902
Iteration 1240 => Loss: 0.3944026203
Iteration 1241 => Loss: 0.3943802803
Iteration 1242 => Loss: 0.3943579702
Iteration 1243 => Loss: 0.3943356900
Iteration 1244 => Loss: 0.3943134395
Iteration 1245 => Loss: 0.3942912187
Iteration 1246 => Loss: 0.3942690275
Iteration 1247 => Loss: 0.3942468660
Iteration 1248 => Loss: 0.3942247340
Iteration 1249 => Loss: 0.3942026314
Iteration 1250 => Loss: 0.3941805583
Iteration 1251 => Loss: 0.3941585146
Iteration 1252 => Loss: 0.3941365002
Iteration 1253 => Loss: 0.3941145151
Iteration 1254 => Loss: 0.3940925591
Iteration 1255 => Loss: 0.3940706323
Iteration 1256 => Loss: 0.3940487346
Iteration 1257 => Loss: 0.3940268659
Iteration 1258 => Loss: 0.3940050262
Iteration 1259 => Loss: 0.3939832154
Iteration 1260 => Loss: 0.3939614335
Iteration 1261 => Loss: 0.3939396805
Iteration 1262 => Loss: 0.3939179562
Iteration 1263 => Loss: 0.3938962605
Iteration 1264 => Loss: 0.3938745936
Iteration 1265 => Loss: 0.3938529552
Iteration 1266 => Loss: 0.3938313454
Iteration 1267 => Loss: 0.3938097641
Iteration 1268 => Loss: 0.3937882112
Iteration 1269 => Loss: 0.3937666867
Iteration 1270 => Loss: 0.3937451906
Iteration 1271 => Loss: 0.3937237227
Iteration 1272 => Loss: 0.3937022830
Iteration 1273 => Loss: 0.3936808716
Iteration 1274 => Loss: 0.3936594882
Iteration 1275 => Loss: 0.3936381329
Iteration 1276 => Loss: 0.3936168056
Iteration 1277 => Loss: 0.3935955063
Iteration 1278 => Loss: 0.3935742349
Iteration 1279 => Loss: 0.3935529913
Iteration 1280 => Loss: 0.3935317756
Iteration 1281 => Loss: 0.3935105876
Iteration 1282 => Loss: 0.3934894273
Iteration 1283 => Loss: 0.3934682947
Iteration 1284 => Loss: 0.3934471896
Iteration 1285 => Loss: 0.3934261122
Iteration 1286 => Loss: 0.3934050622
Iteration 1287 => Loss: 0.3933840396
Iteration 1288 => Loss: 0.3933630445
Iteration 1289 => Loss: 0.3933420767
Iteration 1290 => Loss: 0.3933211362
Iteration 1291 => Loss: 0.3933002229
Iteration 1292 => Loss: 0.3932793368
Iteration 1293 => Loss: 0.3932584779
Iteration 1294 => Loss: 0.3932376461
Iteration 1295 => Loss: 0.3932168413
Iteration 1296 => Loss: 0.3931960635
Iteration 1297 => Loss: 0.3931753126
Iteration 1298 => Loss: 0.3931545887
Iteration 1299 => Loss: 0.3931338916
Iteration 1300 => Loss: 0.3931132212
Iteration 1301 => Loss: 0.3930925777
Iteration 1302 => Loss: 0.3930719608
Iteration 1303 => Loss: 0.3930513706
Iteration 1304 => Loss: 0.3930308069
Iteration 1305 => Loss: 0.3930102699
Iteration 1306 => Loss: 0.3929897593
Iteration 1307 => Loss: 0.3929692752
Iteration 1308 => Loss: 0.3929488175
Iteration 1309 => Loss: 0.3929283861
Iteration 1310 => Loss: 0.3929079811
Iteration 1311 => Loss: 0.3928876023
Iteration 1312 => Loss: 0.3928672497
Iteration 1313 => Loss: 0.3928469233
Iteration 1314 => Loss: 0.3928266231
Iteration 1315 => Loss: 0.3928063489
Iteration 1316 => Loss: 0.3927861007
Iteration 1317 => Loss: 0.3927658785
Iteration 1318 => Loss: 0.3927456822
Iteration 1319 => Loss: 0.3927255118
Iteration 1320 => Loss: 0.3927053672
Iteration 1321 => Loss: 0.3926852485
Iteration 1322 => Loss: 0.3926651554
Iteration 1323 => Loss: 0.3926450881
Iteration 1324 => Loss: 0.3926250464
Iteration 1325 => Loss: 0.3926050304
Iteration 1326 => Loss: 0.3925850399
Iteration 1327 => Loss: 0.3925650749
Iteration 1328 => Loss: 0.3925451353
Iteration 1329 => Loss: 0.3925252212
Iteration 1330 => Loss: 0.3925053325
Iteration 1331 => Loss: 0.3924854691
Iteration 1332 => Loss: 0.3924656309
Iteration 1333 => Loss: 0.3924458180
Iteration 1334 => Loss: 0.3924260303
Iteration 1335 => Loss: 0.3924062678
Iteration 1336 => Loss: 0.3923865303
Iteration 1337 => Loss: 0.3923668180
Iteration 1338 => Loss: 0.3923471306
Iteration 1339 => Loss: 0.3923274682
Iteration 1340 => Loss: 0.3923078307
Iteration 1341 => Loss: 0.3922882181
Iteration 1342 => Loss: 0.3922686303
Iteration 1343 => Loss: 0.3922490674
Iteration 1344 => Loss: 0.3922295292
Iteration 1345 => Loss: 0.3922100156
Iteration 1346 => Loss: 0.3921905268
Iteration 1347 => Loss: 0.3921710625
Iteration 1348 => Loss: 0.3921516229
Iteration 1349 => Loss: 0.3921322077
Iteration 1350 => Loss: 0.3921128171
Iteration 1351 => Loss: 0.3920934509
Iteration 1352 => Loss: 0.3920741090
Iteration 1353 => Loss: 0.3920547916
Iteration 1354 => Loss: 0.3920354984
Iteration 1355 => Loss: 0.3920162296
Iteration 1356 => Loss: 0.3919969849
Iteration 1357 => Loss: 0.3919777645
Iteration 1358 => Loss: 0.3919585681
Iteration 1359 => Loss: 0.3919393959
Iteration 1360 => Loss: 0.3919202478
Iteration 1361 => Loss: 0.3919011236
Iteration 1362 => Loss: 0.3918820234
Iteration 1363 => Loss: 0.3918629472
Iteration 1364 => Loss: 0.3918438948
Iteration 1365 => Loss: 0.3918248663
Iteration 1366 => Loss: 0.3918058616
Iteration 1367 => Loss: 0.3917868807
Iteration 1368 => Loss: 0.3917679235
Iteration 1369 => Loss: 0.3917489899
Iteration 1370 => Loss: 0.3917300800
Iteration 1371 => Loss: 0.3917111937
Iteration 1372 => Loss: 0.3916923310
Iteration 1373 => Loss: 0.3916734918
Iteration 1374 => Loss: 0.3916546760
Iteration 1375 => Loss: 0.3916358837
Iteration 1376 => Loss: 0.3916171148
Iteration 1377 => Loss: 0.3915983692
Iteration 1378 => Loss: 0.3915796470
Iteration 1379 => Loss: 0.3915609480
Iteration 1380 => Loss: 0.3915422722
Iteration 1381 => Loss: 0.3915236197
Iteration 1382 => Loss: 0.3915049903
Iteration 1383 => Loss: 0.3914863840
Iteration 1384 => Loss: 0.3914678007
Iteration 1385 => Loss: 0.3914492405
Iteration 1386 => Loss: 0.3914307033
Iteration 1387 => Loss: 0.3914121891
Iteration 1388 => Loss: 0.3913936977
Iteration 1389 => Loss: 0.3913752293
Iteration 1390 => Loss: 0.3913567836
Iteration 1391 => Loss: 0.3913383608
Iteration 1392 => Loss: 0.3913199607
Iteration 1393 => Loss: 0.3913015833
Iteration 1394 => Loss: 0.3912832286
Iteration 1395 => Loss: 0.3912648966
Iteration 1396 => Loss: 0.3912465871
Iteration 1397 => Loss: 0.3912283002
Iteration 1398 => Loss: 0.3912100358
Iteration 1399 => Loss: 0.3911917940
Iteration 1400 => Loss: 0.3911735745
Iteration 1401 => Loss: 0.3911553775
Iteration 1402 => Loss: 0.3911372028
Iteration 1403 => Loss: 0.3911190504
Iteration 1404 => Loss: 0.3911009204
Iteration 1405 => Loss: 0.3910828126
Iteration 1406 => Loss: 0.3910647270
Iteration 1407 => Loss: 0.3910466636
Iteration 1408 => Loss: 0.3910286223
Iteration 1409 => Loss: 0.3910106032
Iteration 1410 => Loss: 0.3909926061
Iteration 1411 => Loss: 0.3909746310
Iteration 1412 => Loss: 0.3909566779
Iteration 1413 => Loss: 0.3909387468
Iteration 1414 => Loss: 0.3909208376
Iteration 1415 => Loss: 0.3909029503
Iteration 1416 => Loss: 0.3908850848
Iteration 1417 => Loss: 0.3908672411
Iteration 1418 => Loss: 0.3908494192
Iteration 1419 => Loss: 0.3908316190
Iteration 1420 => Loss: 0.3908138405
Iteration 1421 => Loss: 0.3907960836
Iteration 1422 => Loss: 0.3907783484
Iteration 1423 => Loss: 0.3907606348
Iteration 1424 => Loss: 0.3907429427
Iteration 1425 => Loss: 0.3907252721
Iteration 1426 => Loss: 0.3907076230
Iteration 1427 => Loss: 0.3906899954
Iteration 1428 => Loss: 0.3906723891
Iteration 1429 => Loss: 0.3906548042
Iteration 1430 => Loss: 0.3906372407
Iteration 1431 => Loss: 0.3906196984
Iteration 1432 => Loss: 0.3906021774
Iteration 1433 => Loss: 0.3905846776
Iteration 1434 => Loss: 0.3905671990
Iteration 1435 => Loss: 0.3905497416
Iteration 1436 => Loss: 0.3905323053
Iteration 1437 => Loss: 0.3905148901
Iteration 1438 => Loss: 0.3904974959
Iteration 1439 => Loss: 0.3904801227
Iteration 1440 => Loss: 0.3904627705
Iteration 1441 => Loss: 0.3904454393
Iteration 1442 => Loss: 0.3904281289
Iteration 1443 => Loss: 0.3904108394
Iteration 1444 => Loss: 0.3903935708
Iteration 1445 => Loss: 0.3903763230
Iteration 1446 => Loss: 0.3903590959
Iteration 1447 => Loss: 0.3903418896
Iteration 1448 => Loss: 0.3903247040
Iteration 1449 => Loss: 0.3903075390
Iteration 1450 => Loss: 0.3902903947
Iteration 1451 => Loss: 0.3902732709
Iteration 1452 => Loss: 0.3902561678
Iteration 1453 => Loss: 0.3902390851
Iteration 1454 => Loss: 0.3902220230
Iteration 1455 => Loss: 0.3902049813
Iteration 1456 => Loss: 0.3901879600
Iteration 1457 => Loss: 0.3901709592
Iteration 1458 => Loss: 0.3901539787
Iteration 1459 => Loss: 0.3901370185
Iteration 1460 => Loss: 0.3901200786
Iteration 1461 => Loss: 0.3901031590
Iteration 1462 => Loss: 0.3900862596
Iteration 1463 => Loss: 0.3900693804
Iteration 1464 => Loss: 0.3900525213
Iteration 1465 => Loss: 0.3900356824
Iteration 1466 => Loss: 0.3900188636
Iteration 1467 => Loss: 0.3900020648
Iteration 1468 => Loss: 0.3899852861
Iteration 1469 => Loss: 0.3899685273
Iteration 1470 => Loss: 0.3899517885
Iteration 1471 => Loss: 0.3899350697
Iteration 1472 => Loss: 0.3899183707
Iteration 1473 => Loss: 0.3899016916
Iteration 1474 => Loss: 0.3898850324
Iteration 1475 => Loss: 0.3898683929
Iteration 1476 => Loss: 0.3898517732
Iteration 1477 => Loss: 0.3898351733
Iteration 1478 => Loss: 0.3898185930
Iteration 1479 => Loss: 0.3898020324
Iteration 1480 => Loss: 0.3897854915
Iteration 1481 => Loss: 0.3897689701
Iteration 1482 => Loss: 0.3897524684
Iteration 1483 => Loss: 0.3897359862
Iteration 1484 => Loss: 0.3897195234
Iteration 1485 => Loss: 0.3897030802
Iteration 1486 => Loss: 0.3896866564
Iteration 1487 => Loss: 0.3896702521
Iteration 1488 => Loss: 0.3896538671
Iteration 1489 => Loss: 0.3896375014
Iteration 1490 => Loss: 0.3896211551
Iteration 1491 => Loss: 0.3896048281
Iteration 1492 => Loss: 0.3895885204
Iteration 1493 => Loss: 0.3895722318
Iteration 1494 => Loss: 0.3895559625
Iteration 1495 => Loss: 0.3895397123
Iteration 1496 => Loss: 0.3895234813
Iteration 1497 => Loss: 0.3895072694
Iteration 1498 => Loss: 0.3894910765
Iteration 1499 => Loss: 0.3894749027
Iteration 1500 => Loss: 0.3894587479
Iteration 1501 => Loss: 0.3894426121
Iteration 1502 => Loss: 0.3894264952
Iteration 1503 => Loss: 0.3894103973
Iteration 1504 => Loss: 0.3893943182
Iteration 1505 => Loss: 0.3893782580
Iteration 1506 => Loss: 0.3893622167
Iteration 1507 => Loss: 0.3893461941
Iteration 1508 => Loss: 0.3893301903
Iteration 1509 => Loss: 0.3893142052
Iteration 1510 => Loss: 0.3892982389
Iteration 1511 => Loss: 0.3892822912
Iteration 1512 => Loss: 0.3892663622
Iteration 1513 => Loss: 0.3892504518
Iteration 1514 => Loss: 0.3892345600
Iteration 1515 => Loss: 0.3892186868
Iteration 1516 => Loss: 0.3892028320
Iteration 1517 => Loss: 0.3891869958
Iteration 1518 => Loss: 0.3891711781
Iteration 1519 => Loss: 0.3891553788
Iteration 1520 => Loss: 0.3891395979
Iteration 1521 => Loss: 0.3891238354
Iteration 1522 => Loss: 0.3891080912
Iteration 1523 => Loss: 0.3890923654
Iteration 1524 => Loss: 0.3890766579
Iteration 1525 => Loss: 0.3890609686
Iteration 1526 => Loss: 0.3890452976
Iteration 1527 => Loss: 0.3890296447
Iteration 1528 => Loss: 0.3890140101
Iteration 1529 => Loss: 0.3889983936
Iteration 1530 => Loss: 0.3889827953
Iteration 1531 => Loss: 0.3889672150
Iteration 1532 => Loss: 0.3889516528
Iteration 1533 => Loss: 0.3889361086
Iteration 1534 => Loss: 0.3889205825
Iteration 1535 => Loss: 0.3889050743
Iteration 1536 => Loss: 0.3888895840
Iteration 1537 => Loss: 0.3888741117
Iteration 1538 => Loss: 0.3888586573
Iteration 1539 => Loss: 0.3888432208
Iteration 1540 => Loss: 0.3888278021
Iteration 1541 => Loss: 0.3888124012
Iteration 1542 => Loss: 0.3887970181
Iteration 1543 => Loss: 0.3887816527
Iteration 1544 => Loss: 0.3887663051
Iteration 1545 => Loss: 0.3887509751
Iteration 1546 => Loss: 0.3887356629
Iteration 1547 => Loss: 0.3887203682
Iteration 1548 => Loss: 0.3887050912
Iteration 1549 => Loss: 0.3886898318
Iteration 1550 => Loss: 0.3886745900
Iteration 1551 => Loss: 0.3886593656
Iteration 1552 => Loss: 0.3886441588
Iteration 1553 => Loss: 0.3886289695
Iteration 1554 => Loss: 0.3886137976
Iteration 1555 => Loss: 0.3885986431
Iteration 1556 => Loss: 0.3885835060
Iteration 1557 => Loss: 0.3885683863
Iteration 1558 => Loss: 0.3885532840
Iteration 1559 => Loss: 0.3885381989
Iteration 1560 => Loss: 0.3885231311
Iteration 1561 => Loss: 0.3885080806
Iteration 1562 => Loss: 0.3884930474
Iteration 1563 => Loss: 0.3884780313
Iteration 1564 => Loss: 0.3884630324
Iteration 1565 => Loss: 0.3884480507
Iteration 1566 => Loss: 0.3884330861
Iteration 1567 => Loss: 0.3884181386
Iteration 1568 => Loss: 0.3884032082
Iteration 1569 => Loss: 0.3883882948
Iteration 1570 => Loss: 0.3883733985
Iteration 1571 => Loss: 0.3883585191
Iteration 1572 => Loss: 0.3883436567
Iteration 1573 => Loss: 0.3883288112
Iteration 1574 => Loss: 0.3883139827
Iteration 1575 => Loss: 0.3882991711
Iteration 1576 => Loss: 0.3882843763
Iteration 1577 => Loss: 0.3882695983
Iteration 1578 => Loss: 0.3882548372
Iteration 1579 => Loss: 0.3882400928
Iteration 1580 => Loss: 0.3882253652
Iteration 1581 => Loss: 0.3882106544
Iteration 1582 => Loss: 0.3881959602
Iteration 1583 => Loss: 0.3881812828
Iteration 1584 => Loss: 0.3881666220
Iteration 1585 => Loss: 0.3881519778
Iteration 1586 => Loss: 0.3881373502
Iteration 1587 => Loss: 0.3881227392
Iteration 1588 => Loss: 0.3881081448
Iteration 1589 => Loss: 0.3880935668
Iteration 1590 => Loss: 0.3880790054
Iteration 1591 => Loss: 0.3880644605
Iteration 1592 => Loss: 0.3880499320
Iteration 1593 => Loss: 0.3880354200
Iteration 1594 => Loss: 0.3880209243
Iteration 1595 => Loss: 0.3880064450
Iteration 1596 => Loss: 0.3879919821
Iteration 1597 => Loss: 0.3879775355
Iteration 1598 => Loss: 0.3879631052
Iteration 1599 => Loss: 0.3879486912
Iteration 1600 => Loss: 0.3879342934
Iteration 1601 => Loss: 0.3879199119
Iteration 1602 => Loss: 0.3879055466
Iteration 1603 => Loss: 0.3878911974
Iteration 1604 => Loss: 0.3878768644
Iteration 1605 => Loss: 0.3878625475
Iteration 1606 => Loss: 0.3878482468
Iteration 1607 => Loss: 0.3878339621
Iteration 1608 => Loss: 0.3878196934
Iteration 1609 => Loss: 0.3878054408
Iteration 1610 => Loss: 0.3877912042
Iteration 1611 => Loss: 0.3877769836
Iteration 1612 => Loss: 0.3877627789
Iteration 1613 => Loss: 0.3877485902
Iteration 1614 => Loss: 0.3877344174
Iteration 1615 => Loss: 0.3877202605
Iteration 1616 => Loss: 0.3877061194
Iteration 1617 => Loss: 0.3876919942
Iteration 1618 => Loss: 0.3876778847
Iteration 1619 => Loss: 0.3876637911
Iteration 1620 => Loss: 0.3876497132
Iteration 1621 => Loss: 0.3876356511
Iteration 1622 => Loss: 0.3876216047
Iteration 1623 => Loss: 0.3876075740
Iteration 1624 => Loss: 0.3875935589
Iteration 1625 => Loss: 0.3875795595
Iteration 1626 => Loss: 0.3875655758
Iteration 1627 => Loss: 0.3875516076
Iteration 1628 => Loss: 0.3875376550
Iteration 1629 => Loss: 0.3875237179
Iteration 1630 => Loss: 0.3875097964
Iteration 1631 => Loss: 0.3874958904
Iteration 1632 => Loss: 0.3874819999
Iteration 1633 => Loss: 0.3874681248
Iteration 1634 => Loss: 0.3874542651
Iteration 1635 => Loss: 0.3874404209
Iteration 1636 => Loss: 0.3874265921
Iteration 1637 => Loss: 0.3874127786
Iteration 1638 => Loss: 0.3873989805
Iteration 1639 => Loss: 0.3873851977
Iteration 1640 => Loss: 0.3873714302
Iteration 1641 => Loss: 0.3873576779
Iteration 1642 => Loss: 0.3873439409
Iteration 1643 => Loss: 0.3873302192
Iteration 1644 => Loss: 0.3873165126
Iteration 1645 => Loss: 0.3873028212
Iteration 1646 => Loss: 0.3872891450
Iteration 1647 => Loss: 0.3872754840
Iteration 1648 => Loss: 0.3872618380
Iteration 1649 => Loss: 0.3872482071
Iteration 1650 => Loss: 0.3872345913
Iteration 1651 => Loss: 0.3872209906
Iteration 1652 => Loss: 0.3872074049
Iteration 1653 => Loss: 0.3871938341
Iteration 1654 => Loss: 0.3871802784
Iteration 1655 => Loss: 0.3871667376
Iteration 1656 => Loss: 0.3871532118
Iteration 1657 => Loss: 0.3871397008
Iteration 1658 => Loss: 0.3871262048
Iteration 1659 => Loss: 0.3871127236
Iteration 1660 => Loss: 0.3870992573
Iteration 1661 => Loss: 0.3870858058
Iteration 1662 => Loss: 0.3870723691
Iteration 1663 => Loss: 0.3870589472
Iteration 1664 => Loss: 0.3870455400
Iteration 1665 => Loss: 0.3870321476
Iteration 1666 => Loss: 0.3870187699
Iteration 1667 => Loss: 0.3870054068
Iteration 1668 => Loss: 0.3869920585
Iteration 1669 => Loss: 0.3869787248
Iteration 1670 => Loss: 0.3869654057
Iteration 1671 => Loss: 0.3869521013
Iteration 1672 => Loss: 0.3869388114
Iteration 1673 => Loss: 0.3869255361
Iteration 1674 => Loss: 0.3869122753
Iteration 1675 => Loss: 0.3868990291
Iteration 1676 => Loss: 0.3868857973
Iteration 1677 => Loss: 0.3868725801
Iteration 1678 => Loss: 0.3868593772
Iteration 1679 => Loss: 0.3868461889
Iteration 1680 => Loss: 0.3868330149
Iteration 1681 => Loss: 0.3868198553
Iteration 1682 => Loss: 0.3868067101
Iteration 1683 => Loss: 0.3867935793
Iteration 1684 => Loss: 0.3867804627
Iteration 1685 => Loss: 0.3867673605
Iteration 1686 => Loss: 0.3867542726
Iteration 1687 => Loss: 0.3867411989
Iteration 1688 => Loss: 0.3867281395
Iteration 1689 => Loss: 0.3867150943
Iteration 1690 => Loss: 0.3867020633
Iteration 1691 => Loss: 0.3866890465
Iteration 1692 => Loss: 0.3866760439
Iteration 1693 => Loss: 0.3866630554
Iteration 1694 => Loss: 0.3866500810
Iteration 1695 => Loss: 0.3866371207
Iteration 1696 => Loss: 0.3866241745
Iteration 1697 => Loss: 0.3866112424
Iteration 1698 => Loss: 0.3865983243
Iteration 1699 => Loss: 0.3865854202
Iteration 1700 => Loss: 0.3865725301
Iteration 1701 => Loss: 0.3865596540
Iteration 1702 => Loss: 0.3865467918
Iteration 1703 => Loss: 0.3865339436
Iteration 1704 => Loss: 0.3865211093
Iteration 1705 => Loss: 0.3865082889
Iteration 1706 => Loss: 0.3864954823
Iteration 1707 => Loss: 0.3864826896
Iteration 1708 => Loss: 0.3864699108
Iteration 1709 => Loss: 0.3864571458
Iteration 1710 => Loss: 0.3864443945
Iteration 1711 => Loss: 0.3864316570
Iteration 1712 => Loss: 0.3864189333
Iteration 1713 => Loss: 0.3864062234
Iteration 1714 => Loss: 0.3863935271
Iteration 1715 => Loss: 0.3863808445
Iteration 1716 => Loss: 0.3863681756
Iteration 1717 => Loss: 0.3863555204
Iteration 1718 => Loss: 0.3863428788
Iteration 1719 => Loss: 0.3863302508
Iteration 1720 => Loss: 0.3863176364
Iteration 1721 => Loss: 0.3863050356
Iteration 1722 => Loss: 0.3862924483
Iteration 1723 => Loss: 0.3862798746
Iteration 1724 => Loss: 0.3862673144
Iteration 1725 => Loss: 0.3862547677
Iteration 1726 => Loss: 0.3862422345
Iteration 1727 => Loss: 0.3862297147
Iteration 1728 => Loss: 0.3862172084
Iteration 1729 => Loss: 0.3862047155
Iteration 1730 => Loss: 0.3861922359
Iteration 1731 => Loss: 0.3861797698
Iteration 1732 => Loss: 0.3861673170
Iteration 1733 => Loss: 0.3861548776
Iteration 1734 => Loss: 0.3861424515
Iteration 1735 => Loss: 0.3861300387
Iteration 1736 => Loss: 0.3861176392
Iteration 1737 => Loss: 0.3861052529
Iteration 1738 => Loss: 0.3860928799
Iteration 1739 => Loss: 0.3860805202
Iteration 1740 => Loss: 0.3860681736
Iteration 1741 => Loss: 0.3860558402
Iteration 1742 => Loss: 0.3860435200
Iteration 1743 => Loss: 0.3860312130
Iteration 1744 => Loss: 0.3860189191
Iteration 1745 => Loss: 0.3860066383
Iteration 1746 => Loss: 0.3859943706
Iteration 1747 => Loss: 0.3859821159
Iteration 1748 => Loss: 0.3859698744
Iteration 1749 => Loss: 0.3859576458
Iteration 1750 => Loss: 0.3859454303
Iteration 1751 => Loss: 0.3859332278
Iteration 1752 => Loss: 0.3859210383
Iteration 1753 => Loss: 0.3859088617
Iteration 1754 => Loss: 0.3858966981
Iteration 1755 => Loss: 0.3858845474
Iteration 1756 => Loss: 0.3858724096
Iteration 1757 => Loss: 0.3858602847
Iteration 1758 => Loss: 0.3858481727
Iteration 1759 => Loss: 0.3858360736
Iteration 1760 => Loss: 0.3858239873
Iteration 1761 => Loss: 0.3858119137
Iteration 1762 => Loss: 0.3857998530
Iteration 1763 => Loss: 0.3857878051
Iteration 1764 => Loss: 0.3857757700
Iteration 1765 => Loss: 0.3857637475
Iteration 1766 => Loss: 0.3857517379
Iteration 1767 => Loss: 0.3857397409
Iteration 1768 => Loss: 0.3857277566
Iteration 1769 => Loss: 0.3857157850
Iteration 1770 => Loss: 0.3857038260
Iteration 1771 => Loss: 0.3856918797
Iteration 1772 => Loss: 0.3856799460
Iteration 1773 => Loss: 0.3856680249
Iteration 1774 => Loss: 0.3856561164
Iteration 1775 => Loss: 0.3856442204
Iteration 1776 => Loss: 0.3856323370
Iteration 1777 => Loss: 0.3856204661
Iteration 1778 => Loss: 0.3856086078
Iteration 1779 => Loss: 0.3855967619
Iteration 1780 => Loss: 0.3855849285
Iteration 1781 => Loss: 0.3855731076
Iteration 1782 => Loss: 0.3855612991
Iteration 1783 => Loss: 0.3855495030
Iteration 1784 => Loss: 0.3855377193
Iteration 1785 => Loss: 0.3855259481
Iteration 1786 => Loss: 0.3855141891
Iteration 1787 => Loss: 0.3855024426
Iteration 1788 => Loss: 0.3854907084
Iteration 1789 => Loss: 0.3854789865
Iteration 1790 => Loss: 0.3854672769
Iteration 1791 => Loss: 0.3854555796
Iteration 1792 => Loss: 0.3854438946
Iteration 1793 => Loss: 0.3854322218
Iteration 1794 => Loss: 0.3854205612
Iteration 1795 => Loss: 0.3854089129
Iteration 1796 => Loss: 0.3853972767
Iteration 1797 => Loss: 0.3853856528
Iteration 1798 => Loss: 0.3853740410
Iteration 1799 => Loss: 0.3853624413
Iteration 1800 => Loss: 0.3853508538
Iteration 1801 => Loss: 0.3853392784
Iteration 1802 => Loss: 0.3853277151
Iteration 1803 => Loss: 0.3853161638
Iteration 1804 => Loss: 0.3853046247
Iteration 1805 => Loss: 0.3852930975
Iteration 1806 => Loss: 0.3852815824
Iteration 1807 => Loss: 0.3852700794
Iteration 1808 => Loss: 0.3852585883
Iteration 1809 => Loss: 0.3852471091
Iteration 1810 => Loss: 0.3852356420
Iteration 1811 => Loss: 0.3852241868
Iteration 1812 => Loss: 0.3852127435
Iteration 1813 => Loss: 0.3852013121
Iteration 1814 => Loss: 0.3851898927
Iteration 1815 => Loss: 0.3851784851
Iteration 1816 => Loss: 0.3851670893
Iteration 1817 => Loss: 0.3851557054
Iteration 1818 => Loss: 0.3851443334
Iteration 1819 => Loss: 0.3851329731
Iteration 1820 => Loss: 0.3851216247
Iteration 1821 => Loss: 0.3851102880
Iteration 1822 => Loss: 0.3850989631
Iteration 1823 => Loss: 0.3850876499
Iteration 1824 => Loss: 0.3850763485
Iteration 1825 => Loss: 0.3850650588
Iteration 1826 => Loss: 0.3850537807
Iteration 1827 => Loss: 0.3850425144
Iteration 1828 => Loss: 0.3850312597
Iteration 1829 => Loss: 0.3850200167
Iteration 1830 => Loss: 0.3850087853
Iteration 1831 => Loss: 0.3849975655
Iteration 1832 => Loss: 0.3849863573
Iteration 1833 => Loss: 0.3849751607
Iteration 1834 => Loss: 0.3849639757
Iteration 1835 => Loss: 0.3849528022
Iteration 1836 => Loss: 0.3849416403
Iteration 1837 => Loss: 0.3849304898
Iteration 1838 => Loss: 0.3849193509
Iteration 1839 => Loss: 0.3849082235
Iteration 1840 => Loss: 0.3848971075
Iteration 1841 => Loss: 0.3848860030
Iteration 1842 => Loss: 0.3848749100
Iteration 1843 => Loss: 0.3848638283
Iteration 1844 => Loss: 0.3848527581
Iteration 1845 => Loss: 0.3848416993
Iteration 1846 => Loss: 0.3848306518
Iteration 1847 => Loss: 0.3848196157
Iteration 1848 => Loss: 0.3848085910
Iteration 1849 => Loss: 0.3847975775
Iteration 1850 => Loss: 0.3847865754
Iteration 1851 => Loss: 0.3847755846
Iteration 1852 => Loss: 0.3847646051
Iteration 1853 => Loss: 0.3847536368
Iteration 1854 => Loss: 0.3847426798
Iteration 1855 => Loss: 0.3847317341
Iteration 1856 => Loss: 0.3847207995
Iteration 1857 => Loss: 0.3847098762
Iteration 1858 => Loss: 0.3846989641
Iteration 1859 => Loss: 0.3846880631
Iteration 1860 => Loss: 0.3846771733
Iteration 1861 => Loss: 0.3846662946
Iteration 1862 => Loss: 0.3846554271
Iteration 1863 => Loss: 0.3846445707
Iteration 1864 => Loss: 0.3846337254
Iteration 1865 => Loss: 0.3846228911
Iteration 1866 => Loss: 0.3846120680
Iteration 1867 => Loss: 0.3846012558
Iteration 1868 => Loss: 0.3845904548
Iteration 1869 => Loss: 0.3845796647
Iteration 1870 => Loss: 0.3845688857
Iteration 1871 => Loss: 0.3845581176
Iteration 1872 => Loss: 0.3845473605
Iteration 1873 => Loss: 0.3845366144
Iteration 1874 => Loss: 0.3845258793
Iteration 1875 => Loss: 0.3845151550
Iteration 1876 => Loss: 0.3845044417
Iteration 1877 => Loss: 0.3844937393
Iteration 1878 => Loss: 0.3844830478
Iteration 1879 => Loss: 0.3844723672
Iteration 1880 => Loss: 0.3844616974
Iteration 1881 => Loss: 0.3844510384
Iteration 1882 => Loss: 0.3844403903
Iteration 1883 => Loss: 0.3844297530
Iteration 1884 => Loss: 0.3844191265
Iteration 1885 => Loss: 0.3844085108
Iteration 1886 => Loss: 0.3843979059
Iteration 1887 => Loss: 0.3843873117
Iteration 1888 => Loss: 0.3843767282
Iteration 1889 => Loss: 0.3843661555
Iteration 1890 => Loss: 0.3843555935
Iteration 1891 => Loss: 0.3843450422
Iteration 1892 => Loss: 0.3843345016
Iteration 1893 => Loss: 0.3843239716
Iteration 1894 => Loss: 0.3843134523
Iteration 1895 => Loss: 0.3843029436
Iteration 1896 => Loss: 0.3842924456
Iteration 1897 => Loss: 0.3842819582
Iteration 1898 => Loss: 0.3842714813
Iteration 1899 => Loss: 0.3842610151
Iteration 1900 => Loss: 0.3842505594
Iteration 1901 => Loss: 0.3842401142
Iteration 1902 => Loss: 0.3842296796
Iteration 1903 => Loss: 0.3842192556
Iteration 1904 => Loss: 0.3842088420
Iteration 1905 => Loss: 0.3841984390
Iteration 1906 => Loss: 0.3841880464
Iteration 1907 => Loss: 0.3841776643
Iteration 1908 => Loss: 0.3841672926
Iteration 1909 => Loss: 0.3841569314
Iteration 1910 => Loss: 0.3841465806
Iteration 1911 => Loss: 0.3841362402
Iteration 1912 => Loss: 0.3841259102
Iteration 1913 => Loss: 0.3841155906
Iteration 1914 => Loss: 0.3841052814
Iteration 1915 => Loss: 0.3840949825
Iteration 1916 => Loss: 0.3840846939
Iteration 1917 => Loss: 0.3840744157
Iteration 1918 => Loss: 0.3840641478
Iteration 1919 => Loss: 0.3840538902
Iteration 1920 => Loss: 0.3840436429
Iteration 1921 => Loss: 0.3840334059
Iteration 1922 => Loss: 0.3840231791
Iteration 1923 => Loss: 0.3840129625
Iteration 1924 => Loss: 0.3840027562
Iteration 1925 => Loss: 0.3839925601
Iteration 1926 => Loss: 0.3839823743
Iteration 1927 => Loss: 0.3839721986
Iteration 1928 => Loss: 0.3839620330
Iteration 1929 => Loss: 0.3839518777
Iteration 1930 => Loss: 0.3839417325
Iteration 1931 => Loss: 0.3839315974
Iteration 1932 => Loss: 0.3839214724
Iteration 1933 => Loss: 0.3839113576
Iteration 1934 => Loss: 0.3839012528
Iteration 1935 => Loss: 0.3838911581
Iteration 1936 => Loss: 0.3838810735
Iteration 1937 => Loss: 0.3838709990
Iteration 1938 => Loss: 0.3838609344
Iteration 1939 => Loss: 0.3838508800
Iteration 1940 => Loss: 0.3838408355
Iteration 1941 => Loss: 0.3838308010
Iteration 1942 => Loss: 0.3838207765
Iteration 1943 => Loss: 0.3838107620
Iteration 1944 => Loss: 0.3838007574
Iteration 1945 => Loss: 0.3837907628
Iteration 1946 => Loss: 0.3837807781
Iteration 1947 => Loss: 0.3837708034
Iteration 1948 => Loss: 0.3837608385
Iteration 1949 => Loss: 0.3837508836
Iteration 1950 => Loss: 0.3837409385
Iteration 1951 => Loss: 0.3837310033
Iteration 1952 => Loss: 0.3837210779
Iteration 1953 => Loss: 0.3837111624
Iteration 1954 => Loss: 0.3837012567
Iteration 1955 => Loss: 0.3836913609
Iteration 1956 => Loss: 0.3836814748
Iteration 1957 => Loss: 0.3836715985
Iteration 1958 => Loss: 0.3836617320
Iteration 1959 => Loss: 0.3836518753
Iteration 1960 => Loss: 0.3836420283
Iteration 1961 => Loss: 0.3836321910
Iteration 1962 => Loss: 0.3836223635
Iteration 1963 => Loss: 0.3836125456
Iteration 1964 => Loss: 0.3836027375
Iteration 1965 => Loss: 0.3835929391
Iteration 1966 => Loss: 0.3835831503
Iteration 1967 => Loss: 0.3835733712
Iteration 1968 => Loss: 0.3835636017
Iteration 1969 => Loss: 0.3835538419
Iteration 1970 => Loss: 0.3835440917
Iteration 1971 => Loss: 0.3835343511
Iteration 1972 => Loss: 0.3835246201
Iteration 1973 => Loss: 0.3835148987
Iteration 1974 => Loss: 0.3835051868
Iteration 1975 => Loss: 0.3834954845
Iteration 1976 => Loss: 0.3834857918
Iteration 1977 => Loss: 0.3834761086
Iteration 1978 => Loss: 0.3834664349
Iteration 1979 => Loss: 0.3834567707
Iteration 1980 => Loss: 0.3834471160
Iteration 1981 => Loss: 0.3834374708
Iteration 1982 => Loss: 0.3834278350
Iteration 1983 => Loss: 0.3834182087
Iteration 1984 => Loss: 0.3834085919
Iteration 1985 => Loss: 0.3833989845
Iteration 1986 => Loss: 0.3833893865
Iteration 1987 => Loss: 0.3833797979
Iteration 1988 => Loss: 0.3833702187
Iteration 1989 => Loss: 0.3833606489
Iteration 1990 => Loss: 0.3833510885
Iteration 1991 => Loss: 0.3833415374
Iteration 1992 => Loss: 0.3833319956
Iteration 1993 => Loss: 0.3833224632
Iteration 1994 => Loss: 0.3833129402
Iteration 1995 => Loss: 0.3833034264
Iteration 1996 => Loss: 0.3832939219
Iteration 1997 => Loss: 0.3832844267
Iteration 1998 => Loss: 0.3832749408
Iteration 1999 => Loss: 0.3832654641
Iteration 2000 => Loss: 0.3832559967
Iteration 2001 => Loss: 0.3832465386
Iteration 2002 => Loss: 0.3832370896
Iteration 2003 => Loss: 0.3832276499
Iteration 2004 => Loss: 0.3832182193
Iteration 2005 => Loss: 0.3832087980
Iteration 2006 => Loss: 0.3831993858
Iteration 2007 => Loss: 0.3831899828
Iteration 2008 => Loss: 0.3831805889
Iteration 2009 => Loss: 0.3831712042
Iteration 2010 => Loss: 0.3831618286
Iteration 2011 => Loss: 0.3831524621
Iteration 2012 => Loss: 0.3831431047
Iteration 2013 => Loss: 0.3831337564
Iteration 2014 => Loss: 0.3831244172
Iteration 2015 => Loss: 0.3831150870
Iteration 2016 => Loss: 0.3831057659
Iteration 2017 => Loss: 0.3830964539
Iteration 2018 => Loss: 0.3830871509
Iteration 2019 => Loss: 0.3830778569
Iteration 2020 => Loss: 0.3830685719
Iteration 2021 => Loss: 0.3830592959
Iteration 2022 => Loss: 0.3830500289
Iteration 2023 => Loss: 0.3830407709
Iteration 2024 => Loss: 0.3830315218
Iteration 2025 => Loss: 0.3830222817
Iteration 2026 => Loss: 0.3830130505
Iteration 2027 => Loss: 0.3830038283
Iteration 2028 => Loss: 0.3829946149
Iteration 2029 => Loss: 0.3829854105
Iteration 2030 => Loss: 0.3829762149
Iteration 2031 => Loss: 0.3829670283
Iteration 2032 => Loss: 0.3829578505
Iteration 2033 => Loss: 0.3829486816
Iteration 2034 => Loss: 0.3829395215
Iteration 2035 => Loss: 0.3829303702
Iteration 2036 => Loss: 0.3829212278
Iteration 2037 => Loss: 0.3829120941
Iteration 2038 => Loss: 0.3829029693
Iteration 2039 => Loss: 0.3828938533
Iteration 2040 => Loss: 0.3828847460
Iteration 2041 => Loss: 0.3828756475
Iteration 2042 => Loss: 0.3828665578
Iteration 2043 => Loss: 0.3828574768
Iteration 2044 => Loss: 0.3828484045
Iteration 2045 => Loss: 0.3828393410
Iteration 2046 => Loss: 0.3828302861
Iteration 2047 => Loss: 0.3828212400
Iteration 2048 => Loss: 0.3828122025
Iteration 2049 => Loss: 0.3828031738
Iteration 2050 => Loss: 0.3827941536
Iteration 2051 => Loss: 0.3827851422
Iteration 2052 => Loss: 0.3827761394
Iteration 2053 => Loss: 0.3827671452
Iteration 2054 => Loss: 0.3827581596
Iteration 2055 => Loss: 0.3827491826
Iteration 2056 => Loss: 0.3827402143
Iteration 2057 => Loss: 0.3827312545
Iteration 2058 => Loss: 0.3827223033
Iteration 2059 => Loss: 0.3827133606
Iteration 2060 => Loss: 0.3827044265
Iteration 2061 => Loss: 0.3826955010
Iteration 2062 => Loss: 0.3826865840
Iteration 2063 => Loss: 0.3826776755
Iteration 2064 => Loss: 0.3826687755
Iteration 2065 => Loss: 0.3826598840
Iteration 2066 => Loss: 0.3826510010
Iteration 2067 => Loss: 0.3826421265
Iteration 2068 => Loss: 0.3826332604
Iteration 2069 => Loss: 0.3826244028
Iteration 2070 => Loss: 0.3826155536
Iteration 2071 => Loss: 0.3826067129
Iteration 2072 => Loss: 0.3825978805
Iteration 2073 => Loss: 0.3825890566
Iteration 2074 => Loss: 0.3825802411
Iteration 2075 => Loss: 0.3825714340
Iteration 2076 => Loss: 0.3825626353
Iteration 2077 => Loss: 0.3825538449
Iteration 2078 => Loss: 0.3825450629
Iteration 2079 => Loss: 0.3825362892
Iteration 2080 => Loss: 0.3825275239
Iteration 2081 => Loss: 0.3825187669
Iteration 2082 => Loss: 0.3825100182
Iteration 2083 => Loss: 0.3825012778
Iteration 2084 => Loss: 0.3824925457
Iteration 2085 => Loss: 0.3824838219
Iteration 2086 => Loss: 0.3824751063
Iteration 2087 => Loss: 0.3824663990
Iteration 2088 => Loss: 0.3824577000
Iteration 2089 => Loss: 0.3824490092
Iteration 2090 => Loss: 0.3824403266
Iteration 2091 => Loss: 0.3824316523
Iteration 2092 => Loss: 0.3824229861
Iteration 2093 => Loss: 0.3824143282
Iteration 2094 => Loss: 0.3824056784
Iteration 2095 => Loss: 0.3823970368
Iteration 2096 => Loss: 0.3823884034
Iteration 2097 => Loss: 0.3823797781
Iteration 2098 => Loss: 0.3823711610
Iteration 2099 => Loss: 0.3823625520
Iteration 2100 => Loss: 0.3823539512
Iteration 2101 => Loss: 0.3823453584
Iteration 2102 => Loss: 0.3823367738
Iteration 2103 => Loss: 0.3823281972
Iteration 2104 => Loss: 0.3823196288
Iteration 2105 => Loss: 0.3823110684
Iteration 2106 => Loss: 0.3823025160
Iteration 2107 => Loss: 0.3822939718
Iteration 2108 => Loss: 0.3822854355
Iteration 2109 => Loss: 0.3822769073
Iteration 2110 => Loss: 0.3822683871
Iteration 2111 => Loss: 0.3822598750
Iteration 2112 => Loss: 0.3822513708
Iteration 2113 => Loss: 0.3822428746
Iteration 2114 => Loss: 0.3822343864
Iteration 2115 => Loss: 0.3822259062
Iteration 2116 => Loss: 0.3822174339
Iteration 2117 => Loss: 0.3822089696
Iteration 2118 => Loss: 0.3822005132
Iteration 2119 => Loss: 0.3821920648
Iteration 2120 => Loss: 0.3821836242
Iteration 2121 => Loss: 0.3821751916
Iteration 2122 => Loss: 0.3821667669
Iteration 2123 => Loss: 0.3821583501
Iteration 2124 => Loss: 0.3821499411
Iteration 2125 => Loss: 0.3821415400
Iteration 2126 => Loss: 0.3821331468
Iteration 2127 => Loss: 0.3821247614
Iteration 2128 => Loss: 0.3821163839
Iteration 2129 => Loss: 0.3821080142
Iteration 2130 => Loss: 0.3820996523
Iteration 2131 => Loss: 0.3820912983
Iteration 2132 => Loss: 0.3820829520
Iteration 2133 => Loss: 0.3820746135
Iteration 2134 => Loss: 0.3820662828
Iteration 2135 => Loss: 0.3820579599
Iteration 2136 => Loss: 0.3820496447
Iteration 2137 => Loss: 0.3820413373
Iteration 2138 => Loss: 0.3820330376
Iteration 2139 => Loss: 0.3820247457
Iteration 2140 => Loss: 0.3820164615
Iteration 2141 => Loss: 0.3820081849
Iteration 2142 => Loss: 0.3819999161
Iteration 2143 => Loss: 0.3819916550
Iteration 2144 => Loss: 0.3819834016
Iteration 2145 => Loss: 0.3819751558
Iteration 2146 => Loss: 0.3819669177
Iteration 2147 => Loss: 0.3819586873
Iteration 2148 => Loss: 0.3819504645
Iteration 2149 => Loss: 0.3819422493
Iteration 2150 => Loss: 0.3819340418
Iteration 2151 => Loss: 0.3819258419
Iteration 2152 => Loss: 0.3819176496
Iteration 2153 => Loss: 0.3819094648
Iteration 2154 => Loss: 0.3819012877
Iteration 2155 => Loss: 0.3818931181
Iteration 2156 => Loss: 0.3818849561
Iteration 2157 => Loss: 0.3818768017
Iteration 2158 => Loss: 0.3818686548
Iteration 2159 => Loss: 0.3818605155
Iteration 2160 => Loss: 0.3818523837
Iteration 2161 => Loss: 0.3818442594
Iteration 2162 => Loss: 0.3818361426
Iteration 2163 => Loss: 0.3818280333
Iteration 2164 => Loss: 0.3818199315
Iteration 2165 => Loss: 0.3818118372
Iteration 2166 => Loss: 0.3818037504
Iteration 2167 => Loss: 0.3817956710
Iteration 2168 => Loss: 0.3817875991
Iteration 2169 => Loss: 0.3817795346
Iteration 2170 => Loss: 0.3817714776
Iteration 2171 => Loss: 0.3817634280
Iteration 2172 => Loss: 0.3817553858
Iteration 2173 => Loss: 0.3817473510
Iteration 2174 => Loss: 0.3817393236
Iteration 2175 => Loss: 0.3817313036
Iteration 2176 => Loss: 0.3817232910
Iteration 2177 => Loss: 0.3817152857
Iteration 2178 => Loss: 0.3817072878
Iteration 2179 => Loss: 0.3816992973
Iteration 2180 => Loss: 0.3816913141
Iteration 2181 => Loss: 0.3816833382
Iteration 2182 => Loss: 0.3816753697
Iteration 2183 => Loss: 0.3816674085
Iteration 2184 => Loss: 0.3816594546
Iteration 2185 => Loss: 0.3816515080
Iteration 2186 => Loss: 0.3816435686
Iteration 2187 => Loss: 0.3816356366
Iteration 2188 => Loss: 0.3816277118
Iteration 2189 => Loss: 0.3816197943
Iteration 2190 => Loss: 0.3816118840
Iteration 2191 => Loss: 0.3816039810
Iteration 2192 => Loss: 0.3815960852
Iteration 2193 => Loss: 0.3815881967
Iteration 2194 => Loss: 0.3815803153
Iteration 2195 => Loss: 0.3815724412
Iteration 2196 => Loss: 0.3815645742
Iteration 2197 => Loss: 0.3815567145
Iteration 2198 => Loss: 0.3815488619
Iteration 2199 => Loss: 0.3815410165
Iteration 2200 => Loss: 0.3815331783
Iteration 2201 => Loss: 0.3815253472
Iteration 2202 => Loss: 0.3815175232
Iteration 2203 => Loss: 0.3815097064
Iteration 2204 => Loss: 0.3815018967
Iteration 2205 => Loss: 0.3814940942
Iteration 2206 => Loss: 0.3814862987
Iteration 2207 => Loss: 0.3814785104
Iteration 2208 => Loss: 0.3814707291
Iteration 2209 => Loss: 0.3814629549
Iteration 2210 => Loss: 0.3814551878
Iteration 2211 => Loss: 0.3814474278
Iteration 2212 => Loss: 0.3814396748
Iteration 2213 => Loss: 0.3814319288
Iteration 2214 => Loss: 0.3814241899
Iteration 2215 => Loss: 0.3814164581
Iteration 2216 => Loss: 0.3814087332
Iteration 2217 => Loss: 0.3814010154
Iteration 2218 => Loss: 0.3813933045
Iteration 2219 => Loss: 0.3813856007
Iteration 2220 => Loss: 0.3813779039
Iteration 2221 => Loss: 0.3813702140
Iteration 2222 => Loss: 0.3813625311
Iteration 2223 => Loss: 0.3813548551
Iteration 2224 => Loss: 0.3813471861
Iteration 2225 => Loss: 0.3813395241
Iteration 2226 => Loss: 0.3813318690
Iteration 2227 => Loss: 0.3813242208
Iteration 2228 => Loss: 0.3813165795
Iteration 2229 => Loss: 0.3813089451
Iteration 2230 => Loss: 0.3813013177
Iteration 2231 => Loss: 0.3812936971
Iteration 2232 => Loss: 0.3812860834
Iteration 2233 => Loss: 0.3812784766
Iteration 2234 => Loss: 0.3812708767
Iteration 2235 => Loss: 0.3812632836
Iteration 2236 => Loss: 0.3812556973
Iteration 2237 => Loss: 0.3812481179
Iteration 2238 => Loss: 0.3812405454
Iteration 2239 => Loss: 0.3812329796
Iteration 2240 => Loss: 0.3812254207
Iteration 2241 => Loss: 0.3812178686
Iteration 2242 => Loss: 0.3812103233
Iteration 2243 => Loss: 0.3812027847
Iteration 2244 => Loss: 0.3811952530
Iteration 2245 => Loss: 0.3811877280
Iteration 2246 => Loss: 0.3811802098
Iteration 2247 => Loss: 0.3811726984
Iteration 2248 => Loss: 0.3811651937
Iteration 2249 => Loss: 0.3811576957
Iteration 2250 => Loss: 0.3811502045
Iteration 2251 => Loss: 0.3811427200
Iteration 2252 => Loss: 0.3811352422
Iteration 2253 => Loss: 0.3811277711
Iteration 2254 => Loss: 0.3811203067
Iteration 2255 => Loss: 0.3811128491
Iteration 2256 => Loss: 0.3811053980
Iteration 2257 => Loss: 0.3810979537
Iteration 2258 => Loss: 0.3810905161
Iteration 2259 => Loss: 0.3810830851
Iteration 2260 => Loss: 0.3810756607
Iteration 2261 => Loss: 0.3810682430
Iteration 2262 => Loss: 0.3810608319
Iteration 2263 => Loss: 0.3810534275
Iteration 2264 => Loss: 0.3810460296
Iteration 2265 => Loss: 0.3810386384
Iteration 2266 => Loss: 0.3810312538
Iteration 2267 => Loss: 0.3810238757
Iteration 2268 => Loss: 0.3810165043
Iteration 2269 => Loss: 0.3810091394
Iteration 2270 => Loss: 0.3810017811
Iteration 2271 => Loss: 0.3809944294
Iteration 2272 => Loss: 0.3809870842
Iteration 2273 => Loss: 0.3809797456
Iteration 2274 => Loss: 0.3809724135
Iteration 2275 => Loss: 0.3809650879
Iteration 2276 => Loss: 0.3809577688
Iteration 2277 => Loss: 0.3809504563
Iteration 2278 => Loss: 0.3809431503
Iteration 2279 => Loss: 0.3809358507
Iteration 2280 => Loss: 0.3809285577
Iteration 2281 => Loss: 0.3809212711
Iteration 2282 => Loss: 0.3809139910
Iteration 2283 => Loss: 0.3809067174
Iteration 2284 => Loss: 0.3808994502
Iteration 2285 => Loss: 0.3808921895
Iteration 2286 => Loss: 0.3808849352
Iteration 2287 => Loss: 0.3808776874
Iteration 2288 => Loss: 0.3808704460
Iteration 2289 => Loss: 0.3808632110
Iteration 2290 => Loss: 0.3808559824
Iteration 2291 => Loss: 0.3808487602
Iteration 2292 => Loss: 0.3808415444
Iteration 2293 => Loss: 0.3808343350
Iteration 2294 => Loss: 0.3808271320
Iteration 2295 => Loss: 0.3808199354
Iteration 2296 => Loss: 0.3808127451
Iteration 2297 => Loss: 0.3808055611
Iteration 2298 => Loss: 0.3807983836
Iteration 2299 => Loss: 0.3807912123
Iteration 2300 => Loss: 0.3807840474
Iteration 2301 => Loss: 0.3807768888
Iteration 2302 => Loss: 0.3807697366
Iteration 2303 => Loss: 0.3807625906
Iteration 2304 => Loss: 0.3807554510
Iteration 2305 => Loss: 0.3807483176
Iteration 2306 => Loss: 0.3807411905
Iteration 2307 => Loss: 0.3807340698
Iteration 2308 => Loss: 0.3807269552
Iteration 2309 => Loss: 0.3807198470
Iteration 2310 => Loss: 0.3807127450
Iteration 2311 => Loss: 0.3807056492
Iteration 2312 => Loss: 0.3806985597
Iteration 2313 => Loss: 0.3806914765
Iteration 2314 => Loss: 0.3806843994
Iteration 2315 => Loss: 0.3806773286
Iteration 2316 => Loss: 0.3806702640
Iteration 2317 => Loss: 0.3806632056
Iteration 2318 => Loss: 0.3806561534
Iteration 2319 => Loss: 0.3806491073
Iteration 2320 => Loss: 0.3806420675
Iteration 2321 => Loss: 0.3806350338
Iteration 2322 => Loss: 0.3806280063
Iteration 2323 => Loss: 0.3806209850
Iteration 2324 => Loss: 0.3806139698
Iteration 2325 => Loss: 0.3806069607
Iteration 2326 => Loss: 0.3805999578
Iteration 2327 => Loss: 0.3805929610
Iteration 2328 => Loss: 0.3805859704
Iteration 2329 => Loss: 0.3805789858
Iteration 2330 => Loss: 0.3805720074
Iteration 2331 => Loss: 0.3805650351
Iteration 2332 => Loss: 0.3805580688
Iteration 2333 => Loss: 0.3805511087
Iteration 2334 => Loss: 0.3805441546
Iteration 2335 => Loss: 0.3805372066
Iteration 2336 => Loss: 0.3805302646
Iteration 2337 => Loss: 0.3805233287
Iteration 2338 => Loss: 0.3805163989
Iteration 2339 => Loss: 0.3805094751
Iteration 2340 => Loss: 0.3805025573
Iteration 2341 => Loss: 0.3804956456
Iteration 2342 => Loss: 0.3804887398
Iteration 2343 => Loss: 0.3804818401
Iteration 2344 => Loss: 0.3804749464
Iteration 2345 => Loss: 0.3804680587
Iteration 2346 => Loss: 0.3804611770
Iteration 2347 => Loss: 0.3804543012
Iteration 2348 => Loss: 0.3804474315
Iteration 2349 => Loss: 0.3804405677
Iteration 2350 => Loss: 0.3804337099
Iteration 2351 => Loss: 0.3804268580
Iteration 2352 => Loss: 0.3804200121
Iteration 2353 => Loss: 0.3804131721
Iteration 2354 => Loss: 0.3804063380
Iteration 2355 => Loss: 0.3803995099
Iteration 2356 => Loss: 0.3803926877
Iteration 2357 => Loss: 0.3803858714
Iteration 2358 => Loss: 0.3803790610
Iteration 2359 => Loss: 0.3803722565
Iteration 2360 => Loss: 0.3803654579
Iteration 2361 => Loss: 0.3803586652
Iteration 2362 => Loss: 0.3803518783
Iteration 2363 => Loss: 0.3803450974
Iteration 2364 => Loss: 0.3803383222
Iteration 2365 => Loss: 0.3803315530
Iteration 2366 => Loss: 0.3803247896
Iteration 2367 => Loss: 0.3803180320
Iteration 2368 => Loss: 0.3803112803
Iteration 2369 => Loss: 0.3803045344
Iteration 2370 => Loss: 0.3802977943
Iteration 2371 => Loss: 0.3802910600
Iteration 2372 => Loss: 0.3802843315
Iteration 2373 => Loss: 0.3802776089
Iteration 2374 => Loss: 0.3802708920
Iteration 2375 => Loss: 0.3802641809
Iteration 2376 => Loss: 0.3802574756
Iteration 2377 => Loss: 0.3802507761
Iteration 2378 => Loss: 0.3802440823
Iteration 2379 => Loss: 0.3802373943
Iteration 2380 => Loss: 0.3802307120
Iteration 2381 => Loss: 0.3802240355
Iteration 2382 => Loss: 0.3802173647
Iteration 2383 => Loss: 0.3802106997
Iteration 2384 => Loss: 0.3802040404
Iteration 2385 => Loss: 0.3801973867
Iteration 2386 => Loss: 0.3801907388
Iteration 2387 => Loss: 0.3801840967
Iteration 2388 => Loss: 0.3801774602
Iteration 2389 => Loss: 0.3801708293
Iteration 2390 => Loss: 0.3801642042
Iteration 2391 => Loss: 0.3801575848
Iteration 2392 => Loss: 0.3801509710
Iteration 2393 => Loss: 0.3801443629
Iteration 2394 => Loss: 0.3801377604
Iteration 2395 => Loss: 0.3801311636
Iteration 2396 => Loss: 0.3801245724
Iteration 2397 => Loss: 0.3801179869
Iteration 2398 => Loss: 0.3801114070
Iteration 2399 => Loss: 0.3801048327
Iteration 2400 => Loss: 0.3800982640
Iteration 2401 => Loss: 0.3800917010
Iteration 2402 => Loss: 0.3800851435
Iteration 2403 => Loss: 0.3800785917
Iteration 2404 => Loss: 0.3800720454
Iteration 2405 => Loss: 0.3800655047
Iteration 2406 => Loss: 0.3800589696
Iteration 2407 => Loss: 0.3800524401
Iteration 2408 => Loss: 0.3800459161
Iteration 2409 => Loss: 0.3800393977
Iteration 2410 => Loss: 0.3800328848
Iteration 2411 => Loss: 0.3800263775
Iteration 2412 => Loss: 0.3800198757
Iteration 2413 => Loss: 0.3800133794
Iteration 2414 => Loss: 0.3800068886
Iteration 2415 => Loss: 0.3800004034
Iteration 2416 => Loss: 0.3799939237
Iteration 2417 => Loss: 0.3799874495
Iteration 2418 => Loss: 0.3799809808
Iteration 2419 => Loss: 0.3799745176
Iteration 2420 => Loss: 0.3799680598
Iteration 2421 => Loss: 0.3799616076
Iteration 2422 => Loss: 0.3799551608
Iteration 2423 => Loss: 0.3799487194
Iteration 2424 => Loss: 0.3799422836
Iteration 2425 => Loss: 0.3799358532
Iteration 2426 => Loss: 0.3799294282
Iteration 2427 => Loss: 0.3799230086
Iteration 2428 => Loss: 0.3799165945
Iteration 2429 => Loss: 0.3799101859
Iteration 2430 => Loss: 0.3799037826
Iteration 2431 => Loss: 0.3798973848
Iteration 2432 => Loss: 0.3798909923
Iteration 2433 => Loss: 0.3798846053
Iteration 2434 => Loss: 0.3798782237
Iteration 2435 => Loss: 0.3798718474
Iteration 2436 => Loss: 0.3798654765
Iteration 2437 => Loss: 0.3798591110
Iteration 2438 => Loss: 0.3798527509
Iteration 2439 => Loss: 0.3798463961
Iteration 2440 => Loss: 0.3798400467
Iteration 2441 => Loss: 0.3798337027
Iteration 2442 => Loss: 0.3798273640
Iteration 2443 => Loss: 0.3798210306
Iteration 2444 => Loss: 0.3798147025
Iteration 2445 => Loss: 0.3798083798
Iteration 2446 => Loss: 0.3798020624
Iteration 2447 => Loss: 0.3797957503
Iteration 2448 => Loss: 0.3797894435
Iteration 2449 => Loss: 0.3797831420
Iteration 2450 => Loss: 0.3797768458
Iteration 2451 => Loss: 0.3797705549
Iteration 2452 => Loss: 0.3797642693
Iteration 2453 => Loss: 0.3797579889
Iteration 2454 => Loss: 0.3797517138
Iteration 2455 => Loss: 0.3797454440
Iteration 2456 => Loss: 0.3797391795
Iteration 2457 => Loss: 0.3797329201
Iteration 2458 => Loss: 0.3797266661
Iteration 2459 => Loss: 0.3797204172
Iteration 2460 => Loss: 0.3797141736
Iteration 2461 => Loss: 0.3797079352
Iteration 2462 => Loss: 0.3797017021
Iteration 2463 => Loss: 0.3796954741
Iteration 2464 => Loss: 0.3796892514
Iteration 2465 => Loss: 0.3796830339
Iteration 2466 => Loss: 0.3796768215
Iteration 2467 => Loss: 0.3796706143
Iteration 2468 => Loss: 0.3796644124
Iteration 2469 => Loss: 0.3796582156
Iteration 2470 => Loss: 0.3796520239
Iteration 2471 => Loss: 0.3796458375
Iteration 2472 => Loss: 0.3796396562
Iteration 2473 => Loss: 0.3796334800
Iteration 2474 => Loss: 0.3796273090
Iteration 2475 => Loss: 0.3796211431
Iteration 2476 => Loss: 0.3796149824
Iteration 2477 => Loss: 0.3796088268
Iteration 2478 => Loss: 0.3796026763
Iteration 2479 => Loss: 0.3795965310
Iteration 2480 => Loss: 0.3795903907
Iteration 2481 => Loss: 0.3795842555
Iteration 2482 => Loss: 0.3795781255
Iteration 2483 => Loss: 0.3795720005
Iteration 2484 => Loss: 0.3795658807
Iteration 2485 => Loss: 0.3795597659
Iteration 2486 => Loss: 0.3795536561
Iteration 2487 => Loss: 0.3795475515
Iteration 2488 => Loss: 0.3795414519
Iteration 2489 => Loss: 0.3795353574
Iteration 2490 => Loss: 0.3795292679
Iteration 2491 => Loss: 0.3795231834
Iteration 2492 => Loss: 0.3795171040
Iteration 2493 => Loss: 0.3795110297
Iteration 2494 => Loss: 0.3795049603
Iteration 2495 => Loss: 0.3794988960
Iteration 2496 => Loss: 0.3794928367
Iteration 2497 => Loss: 0.3794867824
Iteration 2498 => Loss: 0.3794807331
Iteration 2499 => Loss: 0.3794746888
Iteration 2500 => Loss: 0.3794686495
Iteration 2501 => Loss: 0.3794626152
Iteration 2502 => Loss: 0.3794565859
Iteration 2503 => Loss: 0.3794505615
Iteration 2504 => Loss: 0.3794445422
Iteration 2505 => Loss: 0.3794385277
Iteration 2506 => Loss: 0.3794325183
Iteration 2507 => Loss: 0.3794265137
Iteration 2508 => Loss: 0.3794205142
Iteration 2509 => Loss: 0.3794145195
Iteration 2510 => Loss: 0.3794085299
Iteration 2511 => Loss: 0.3794025451
Iteration 2512 => Loss: 0.3793965652
Iteration 2513 => Loss: 0.3793905903
Iteration 2514 => Loss: 0.3793846203
Iteration 2515 => Loss: 0.3793786552
Iteration 2516 => Loss: 0.3793726950
Iteration 2517 => Loss: 0.3793667397
Iteration 2518 => Loss: 0.3793607892
Iteration 2519 => Loss: 0.3793548437
Iteration 2520 => Loss: 0.3793489030
Iteration 2521 => Loss: 0.3793429672
Iteration 2522 => Loss: 0.3793370363
Iteration 2523 => Loss: 0.3793311102
Iteration 2524 => Loss: 0.3793251890
Iteration 2525 => Loss: 0.3793192727
Iteration 2526 => Loss: 0.3793133612
Iteration 2527 => Loss: 0.3793074545
Iteration 2528 => Loss: 0.3793015526
Iteration 2529 => Loss: 0.3792956556
Iteration 2530 => Loss: 0.3792897634
Iteration 2531 => Loss: 0.3792838760
Iteration 2532 => Loss: 0.3792779934
Iteration 2533 => Loss: 0.3792721157
Iteration 2534 => Loss: 0.3792662427
Iteration 2535 => Loss: 0.3792603745
Iteration 2536 => Loss: 0.3792545111
Iteration 2537 => Loss: 0.3792486525
Iteration 2538 => Loss: 0.3792427987
Iteration 2539 => Loss: 0.3792369496
Iteration 2540 => Loss: 0.3792311053
Iteration 2541 => Loss: 0.3792252658
Iteration 2542 => Loss: 0.3792194310
Iteration 2543 => Loss: 0.3792136010
Iteration 2544 => Loss: 0.3792077757
Iteration 2545 => Loss: 0.3792019552
Iteration 2546 => Loss: 0.3791961393
Iteration 2547 => Loss: 0.3791903282
Iteration 2548 => Loss: 0.3791845219
Iteration 2549 => Loss: 0.3791787202
Iteration 2550 => Loss: 0.3791729233
Iteration 2551 => Loss: 0.3791671311
Iteration 2552 => Loss: 0.3791613435
Iteration 2553 => Loss: 0.3791555607
Iteration 2554 => Loss: 0.3791497825
Iteration 2555 => Loss: 0.3791440091
Iteration 2556 => Loss: 0.3791382403
Iteration 2557 => Loss: 0.3791324762
Iteration 2558 => Loss: 0.3791267167
Iteration 2559 => Loss: 0.3791209619
Iteration 2560 => Loss: 0.3791152118
Iteration 2561 => Loss: 0.3791094663
Iteration 2562 => Loss: 0.3791037255
Iteration 2563 => Loss: 0.3790979893
Iteration 2564 => Loss: 0.3790922578
Iteration 2565 => Loss: 0.3790865308
Iteration 2566 => Loss: 0.3790808085
Iteration 2567 => Loss: 0.3790750909
Iteration 2568 => Loss: 0.3790693778
Iteration 2569 => Loss: 0.3790636694
Iteration 2570 => Loss: 0.3790579655
Iteration 2571 => Loss: 0.3790522663
Iteration 2572 => Loss: 0.3790465716
Iteration 2573 => Loss: 0.3790408815
Iteration 2574 => Loss: 0.3790351960
Iteration 2575 => Loss: 0.3790295151
Iteration 2576 => Loss: 0.3790238388
Iteration 2577 => Loss: 0.3790181670
Iteration 2578 => Loss: 0.3790124998
Iteration 2579 => Loss: 0.3790068371
Iteration 2580 => Loss: 0.3790011790
Iteration 2581 => Loss: 0.3789955255
Iteration 2582 => Loss: 0.3789898765
Iteration 2583 => Loss: 0.3789842320
Iteration 2584 => Loss: 0.3789785920
Iteration 2585 => Loss: 0.3789729566
Iteration 2586 => Loss: 0.3789673257
Iteration 2587 => Loss: 0.3789616993
Iteration 2588 => Loss: 0.3789560774
Iteration 2589 => Loss: 0.3789504601
Iteration 2590 => Loss: 0.3789448472
Iteration 2591 => Loss: 0.3789392388
Iteration 2592 => Loss: 0.3789336349
Iteration 2593 => Loss: 0.3789280355
Iteration 2594 => Loss: 0.3789224406
Iteration 2595 => Loss: 0.3789168501
Iteration 2596 => Loss: 0.3789112641
Iteration 2597 => Loss: 0.3789056826
Iteration 2598 => Loss: 0.3789001055
Iteration 2599 => Loss: 0.3788945329
Iteration 2600 => Loss: 0.3788889647
Iteration 2601 => Loss: 0.3788834010
Iteration 2602 => Loss: 0.3788778417
Iteration 2603 => Loss: 0.3788722869
Iteration 2604 => Loss: 0.3788667365
Iteration 2605 => Loss: 0.3788611904
Iteration 2606 => Loss: 0.3788556489
Iteration 2607 => Loss: 0.3788501117
Iteration 2608 => Loss: 0.3788445789
Iteration 2609 => Loss: 0.3788390506
Iteration 2610 => Loss: 0.3788335266
Iteration 2611 => Loss: 0.3788280070
Iteration 2612 => Loss: 0.3788224918
Iteration 2613 => Loss: 0.3788169810
Iteration 2614 => Loss: 0.3788114746
Iteration 2615 => Loss: 0.3788059726
Iteration 2616 => Loss: 0.3788004749
Iteration 2617 => Loss: 0.3787949816
Iteration 2618 => Loss: 0.3787894926
Iteration 2619 => Loss: 0.3787840080
Iteration 2620 => Loss: 0.3787785277
Iteration 2621 => Loss: 0.3787730518
Iteration 2622 => Loss: 0.3787675802
Iteration 2623 => Loss: 0.3787621130
Iteration 2624 => Loss: 0.3787566501
Iteration 2625 => Loss: 0.3787511915
Iteration 2626 => Loss: 0.3787457372
Iteration 2627 => Loss: 0.3787402872
Iteration 2628 => Loss: 0.3787348416
Iteration 2629 => Loss: 0.3787294002
Iteration 2630 => Loss: 0.3787239631
Iteration 2631 => Loss: 0.3787185304
Iteration 2632 => Loss: 0.3787131019
Iteration 2633 => Loss: 0.3787076777
Iteration 2634 => Loss: 0.3787022578
Iteration 2635 => Loss: 0.3786968422
Iteration 2636 => Loss: 0.3786914308
Iteration 2637 => Loss: 0.3786860237
Iteration 2638 => Loss: 0.3786806209
Iteration 2639 => Loss: 0.3786752223
Iteration 2640 => Loss: 0.3786698279
Iteration 2641 => Loss: 0.3786644378
Iteration 2642 => Loss: 0.3786590520
Iteration 2643 => Loss: 0.3786536704
Iteration 2644 => Loss: 0.3786482930
Iteration 2645 => Loss: 0.3786429198
Iteration 2646 => Loss: 0.3786375509
Iteration 2647 => Loss: 0.3786321862
Iteration 2648 => Loss: 0.3786268257
Iteration 2649 => Loss: 0.3786214694
Iteration 2650 => Loss: 0.3786161173
Iteration 2651 => Loss: 0.3786107694
Iteration 2652 => Loss: 0.3786054256
Iteration 2653 => Loss: 0.3786000861
Iteration 2654 => Loss: 0.3785947508
Iteration 2655 => Loss: 0.3785894196
Iteration 2656 => Loss: 0.3785840926
Iteration 2657 => Loss: 0.3785787698
Iteration 2658 => Loss: 0.3785734512
Iteration 2659 => Loss: 0.3785681367
Iteration 2660 => Loss: 0.3785628263
Iteration 2661 => Loss: 0.3785575201
Iteration 2662 => Loss: 0.3785522181
Iteration 2663 => Loss: 0.3785469202
Iteration 2664 => Loss: 0.3785416264
Iteration 2665 => Loss: 0.3785363368
Iteration 2666 => Loss: 0.3785310513
Iteration 2667 => Loss: 0.3785257699
Iteration 2668 => Loss: 0.3785204926
Iteration 2669 => Loss: 0.3785152194
Iteration 2670 => Loss: 0.3785099504
Iteration 2671 => Loss: 0.3785046855
Iteration 2672 => Loss: 0.3784994246
Iteration 2673 => Loss: 0.3784941679
Iteration 2674 => Loss: 0.3784889152
Iteration 2675 => Loss: 0.3784836666
Iteration 2676 => Loss: 0.3784784221
Iteration 2677 => Loss: 0.3784731817
Iteration 2678 => Loss: 0.3784679453
Iteration 2679 => Loss: 0.3784627131
Iteration 2680 => Loss: 0.3784574848
Iteration 2681 => Loss: 0.3784522607
Iteration 2682 => Loss: 0.3784470406
Iteration 2683 => Loss: 0.3784418245
Iteration 2684 => Loss: 0.3784366125
Iteration 2685 => Loss: 0.3784314045
Iteration 2686 => Loss: 0.3784262006
Iteration 2687 => Loss: 0.3784210007
Iteration 2688 => Loss: 0.3784158048
Iteration 2689 => Loss: 0.3784106129
Iteration 2690 => Loss: 0.3784054250
Iteration 2691 => Loss: 0.3784002412
Iteration 2692 => Loss: 0.3783950614
Iteration 2693 => Loss: 0.3783898856
Iteration 2694 => Loss: 0.3783847137
Iteration 2695 => Loss: 0.3783795459
Iteration 2696 => Loss: 0.3783743820
Iteration 2697 => Loss: 0.3783692222
Iteration 2698 => Loss: 0.3783640663
Iteration 2699 => Loss: 0.3783589144
Iteration 2700 => Loss: 0.3783537665
Iteration 2701 => Loss: 0.3783486225
Iteration 2702 => Loss: 0.3783434825
Iteration 2703 => Loss: 0.3783383465
Iteration 2704 => Loss: 0.3783332144
Iteration 2705 => Loss: 0.3783280862
Iteration 2706 => Loss: 0.3783229621
Iteration 2707 => Loss: 0.3783178418
Iteration 2708 => Loss: 0.3783127255
Iteration 2709 => Loss: 0.3783076131
Iteration 2710 => Loss: 0.3783025046
Iteration 2711 => Loss: 0.3782974001
Iteration 2712 => Loss: 0.3782922995
Iteration 2713 => Loss: 0.3782872028
Iteration 2714 => Loss: 0.3782821100
Iteration 2715 => Loss: 0.3782770211
Iteration 2716 => Loss: 0.3782719361
Iteration 2717 => Loss: 0.3782668550
Iteration 2718 => Loss: 0.3782617779
Iteration 2719 => Loss: 0.3782567045
Iteration 2720 => Loss: 0.3782516351
Iteration 2721 => Loss: 0.3782465696
Iteration 2722 => Loss: 0.3782415079
Iteration 2723 => Loss: 0.3782364501
Iteration 2724 => Loss: 0.3782313962
Iteration 2725 => Loss: 0.3782263461
Iteration 2726 => Loss: 0.3782212999
Iteration 2727 => Loss: 0.3782162576
Iteration 2728 => Loss: 0.3782112190
Iteration 2729 => Loss: 0.3782061844
Iteration 2730 => Loss: 0.3782011536
Iteration 2731 => Loss: 0.3781961266
Iteration 2732 => Loss: 0.3781911034
Iteration 2733 => Loss: 0.3781860841
Iteration 2734 => Loss: 0.3781810686
Iteration 2735 => Loss: 0.3781760569
Iteration 2736 => Loss: 0.3781710490
Iteration 2737 => Loss: 0.3781660450
Iteration 2738 => Loss: 0.3781610447
Iteration 2739 => Loss: 0.3781560483
Iteration 2740 => Loss: 0.3781510556
Iteration 2741 => Loss: 0.3781460668
Iteration 2742 => Loss: 0.3781410817
Iteration 2743 => Loss: 0.3781361004
Iteration 2744 => Loss: 0.3781311229
Iteration 2745 => Loss: 0.3781261492
Iteration 2746 => Loss: 0.3781211793
Iteration 2747 => Loss: 0.3781162131
Iteration 2748 => Loss: 0.3781112507
Iteration 2749 => Loss: 0.3781062920
Iteration 2750 => Loss: 0.3781013371
Iteration 2751 => Loss: 0.3780963859
Iteration 2752 => Loss: 0.3780914385
Iteration 2753 => Loss: 0.3780864949
Iteration 2754 => Loss: 0.3780815550
Iteration 2755 => Loss: 0.3780766188
Iteration 2756 => Loss: 0.3780716863
Iteration 2757 => Loss: 0.3780667576
Iteration 2758 => Loss: 0.3780618326
Iteration 2759 => Loss: 0.3780569113
Iteration 2760 => Loss: 0.3780519937
Iteration 2761 => Loss: 0.3780470799
Iteration 2762 => Loss: 0.3780421697
Iteration 2763 => Loss: 0.3780372633
Iteration 2764 => Loss: 0.3780323605
Iteration 2765 => Loss: 0.3780274615
Iteration 2766 => Loss: 0.3780225661
Iteration 2767 => Loss: 0.3780176744
Iteration 2768 => Loss: 0.3780127864
Iteration 2769 => Loss: 0.3780079021
Iteration 2770 => Loss: 0.3780030214
Iteration 2771 => Loss: 0.3779981444
Iteration 2772 => Loss: 0.3779932711
Iteration 2773 => Loss: 0.3779884015
Iteration 2774 => Loss: 0.3779835355
Iteration 2775 => Loss: 0.3779786731
Iteration 2776 => Loss: 0.3779738144
Iteration 2777 => Loss: 0.3779689594
Iteration 2778 => Loss: 0.3779641080
Iteration 2779 => Loss: 0.3779592602
Iteration 2780 => Loss: 0.3779544161
Iteration 2781 => Loss: 0.3779495755
Iteration 2782 => Loss: 0.3779447387
Iteration 2783 => Loss: 0.3779399054
Iteration 2784 => Loss: 0.3779350757
Iteration 2785 => Loss: 0.3779302497
Iteration 2786 => Loss: 0.3779254273
Iteration 2787 => Loss: 0.3779206085
Iteration 2788 => Loss: 0.3779157932
Iteration 2789 => Loss: 0.3779109816
Iteration 2790 => Loss: 0.3779061736
Iteration 2791 => Loss: 0.3779013691
Iteration 2792 => Loss: 0.3778965683
Iteration 2793 => Loss: 0.3778917710
Iteration 2794 => Loss: 0.3778869773
Iteration 2795 => Loss: 0.3778821872
Iteration 2796 => Loss: 0.3778774006
Iteration 2797 => Loss: 0.3778726176
Iteration 2798 => Loss: 0.3778678382
Iteration 2799 => Loss: 0.3778630623
Iteration 2800 => Loss: 0.3778582900
Iteration 2801 => Loss: 0.3778535213
Iteration 2802 => Loss: 0.3778487560
Iteration 2803 => Loss: 0.3778439944
Iteration 2804 => Loss: 0.3778392362
Iteration 2805 => Loss: 0.3778344816
Iteration 2806 => Loss: 0.3778297305
Iteration 2807 => Loss: 0.3778249830
Iteration 2808 => Loss: 0.3778202389
Iteration 2809 => Loss: 0.3778154984
Iteration 2810 => Loss: 0.3778107614
Iteration 2811 => Loss: 0.3778060280
Iteration 2812 => Loss: 0.3778012980
Iteration 2813 => Loss: 0.3777965715
Iteration 2814 => Loss: 0.3777918485
Iteration 2815 => Loss: 0.3777871290
Iteration 2816 => Loss: 0.3777824130
Iteration 2817 => Loss: 0.3777777005
Iteration 2818 => Loss: 0.3777729915
Iteration 2819 => Loss: 0.3777682860
Iteration 2820 => Loss: 0.3777635839
Iteration 2821 => Loss: 0.3777588853
Iteration 2822 => Loss: 0.3777541902
Iteration 2823 => Loss: 0.3777494986
Iteration 2824 => Loss: 0.3777448104
Iteration 2825 => Loss: 0.3777401256
Iteration 2826 => Loss: 0.3777354443
Iteration 2827 => Loss: 0.3777307665
Iteration 2828 => Loss: 0.3777260921
Iteration 2829 => Loss: 0.3777214212
Iteration 2830 => Loss: 0.3777167537
Iteration 2831 => Loss: 0.3777120896
Iteration 2832 => Loss: 0.3777074289
Iteration 2833 => Loss: 0.3777027717
Iteration 2834 => Loss: 0.3776981179
Iteration 2835 => Loss: 0.3776934676
Iteration 2836 => Loss: 0.3776888206
Iteration 2837 => Loss: 0.3776841770
Iteration 2838 => Loss: 0.3776795369
Iteration 2839 => Loss: 0.3776749002
Iteration 2840 => Loss: 0.3776702668
Iteration 2841 => Loss: 0.3776656369
Iteration 2842 => Loss: 0.3776610104
Iteration 2843 => Loss: 0.3776563872
Iteration 2844 => Loss: 0.3776517674
Iteration 2845 => Loss: 0.3776471510
Iteration 2846 => Loss: 0.3776425380
Iteration 2847 => Loss: 0.3776379284
Iteration 2848 => Loss: 0.3776333221
Iteration 2849 => Loss: 0.3776287192
Iteration 2850 => Loss: 0.3776241197
Iteration 2851 => Loss: 0.3776195235
Iteration 2852 => Loss: 0.3776149307
Iteration 2853 => Loss: 0.3776103413
Iteration 2854 => Loss: 0.3776057552
Iteration 2855 => Loss: 0.3776011724
Iteration 2856 => Loss: 0.3775965930
Iteration 2857 => Loss: 0.3775920169
Iteration 2858 => Loss: 0.3775874441
Iteration 2859 => Loss: 0.3775828747
Iteration 2860 => Loss: 0.3775783086
Iteration 2861 => Loss: 0.3775737458
Iteration 2862 => Loss: 0.3775691864
Iteration 2863 => Loss: 0.3775646302
Iteration 2864 => Loss: 0.3775600774
Iteration 2865 => Loss: 0.3775555279
Iteration 2866 => Loss: 0.3775509817
Iteration 2867 => Loss: 0.3775464388
Iteration 2868 => Loss: 0.3775418992
Iteration 2869 => Loss: 0.3775373628
Iteration 2870 => Loss: 0.3775328298
Iteration 2871 => Loss: 0.3775283001
Iteration 2872 => Loss: 0.3775237736
Iteration 2873 => Loss: 0.3775192505
Iteration 2874 => Loss: 0.3775147306
Iteration 2875 => Loss: 0.3775102139
Iteration 2876 => Loss: 0.3775057006
Iteration 2877 => Loss: 0.3775011905
Iteration 2878 => Loss: 0.3774966837
Iteration 2879 => Loss: 0.3774921801
Iteration 2880 => Loss: 0.3774876798
Iteration 2881 => Loss: 0.3774831827
Iteration 2882 => Loss: 0.3774786889
Iteration 2883 => Loss: 0.3774741984
Iteration 2884 => Loss: 0.3774697110
Iteration 2885 => Loss: 0.3774652269
Iteration 2886 => Loss: 0.3774607461
Iteration 2887 => Loss: 0.3774562685
Iteration 2888 => Loss: 0.3774517941
Iteration 2889 => Loss: 0.3774473229
Iteration 2890 => Loss: 0.3774428550
Iteration 2891 => Loss: 0.3774383902
Iteration 2892 => Loss: 0.3774339287
Iteration 2893 => Loss: 0.3774294704
Iteration 2894 => Loss: 0.3774250153
Iteration 2895 => Loss: 0.3774205634
Iteration 2896 => Loss: 0.3774161147
Iteration 2897 => Loss: 0.3774116692
Iteration 2898 => Loss: 0.3774072268
Iteration 2899 => Loss: 0.3774027877
Iteration 2900 => Loss: 0.3773983518
Iteration 2901 => Loss: 0.3773939190
Iteration 2902 => Loss: 0.3773894894
Iteration 2903 => Loss: 0.3773850630
Iteration 2904 => Loss: 0.3773806398
Iteration 2905 => Loss: 0.3773762197
Iteration 2906 => Loss: 0.3773718028
Iteration 2907 => Loss: 0.3773673891
Iteration 2908 => Loss: 0.3773629785
Iteration 2909 => Loss: 0.3773585711
Iteration 2910 => Loss: 0.3773541668
Iteration 2911 => Loss: 0.3773497656
Iteration 2912 => Loss: 0.3773453677
Iteration 2913 => Loss: 0.3773409728
Iteration 2914 => Loss: 0.3773365811
Iteration 2915 => Loss: 0.3773321925
Iteration 2916 => Loss: 0.3773278071
Iteration 2917 => Loss: 0.3773234248
Iteration 2918 => Loss: 0.3773190456
Iteration 2919 => Loss: 0.3773146695
Iteration 2920 => Loss: 0.3773102965
Iteration 2921 => Loss: 0.3773059267
Iteration 2922 => Loss: 0.3773015600
Iteration 2923 => Loss: 0.3772971963
Iteration 2924 => Loss: 0.3772928358
Iteration 2925 => Loss: 0.3772884784
Iteration 2926 => Loss: 0.3772841241
Iteration 2927 => Loss: 0.3772797729
Iteration 2928 => Loss: 0.3772754247
Iteration 2929 => Loss: 0.3772710797
Iteration 2930 => Loss: 0.3772667377
Iteration 2931 => Loss: 0.3772623988
Iteration 2932 => Loss: 0.3772580630
Iteration 2933 => Loss: 0.3772537302
Iteration 2934 => Loss: 0.3772494006
Iteration 2935 => Loss: 0.3772450740
Iteration 2936 => Loss: 0.3772407504
Iteration 2937 => Loss: 0.3772364300
Iteration 2938 => Loss: 0.3772321125
Iteration 2939 => Loss: 0.3772277982
Iteration 2940 => Loss: 0.3772234869
Iteration 2941 => Loss: 0.3772191786
Iteration 2942 => Loss: 0.3772148734
Iteration 2943 => Loss: 0.3772105712
Iteration 2944 => Loss: 0.3772062720
Iteration 2945 => Loss: 0.3772019759
Iteration 2946 => Loss: 0.3771976828
Iteration 2947 => Loss: 0.3771933928
Iteration 2948 => Loss: 0.3771891057
Iteration 2949 => Loss: 0.3771848217
Iteration 2950 => Loss: 0.3771805407
Iteration 2951 => Loss: 0.3771762628
Iteration 2952 => Loss: 0.3771719878
Iteration 2953 => Loss: 0.3771677158
Iteration 2954 => Loss: 0.3771634469
Iteration 2955 => Loss: 0.3771591809
Iteration 2956 => Loss: 0.3771549180
Iteration 2957 => Loss: 0.3771506580
Iteration 2958 => Loss: 0.3771464010
Iteration 2959 => Loss: 0.3771421471
Iteration 2960 => Loss: 0.3771378961
Iteration 2961 => Loss: 0.3771336481
Iteration 2962 => Loss: 0.3771294030
Iteration 2963 => Loss: 0.3771251610
Iteration 2964 => Loss: 0.3771209219
Iteration 2965 => Loss: 0.3771166858
Iteration 2966 => Loss: 0.3771124526
Iteration 2967 => Loss: 0.3771082224
Iteration 2968 => Loss: 0.3771039952
Iteration 2969 => Loss: 0.3770997710
Iteration 2970 => Loss: 0.3770955496
Iteration 2971 => Loss: 0.3770913313
Iteration 2972 => Loss: 0.3770871159
Iteration 2973 => Loss: 0.3770829034
Iteration 2974 => Loss: 0.3770786939
Iteration 2975 => Loss: 0.3770744873
Iteration 2976 => Loss: 0.3770702836
Iteration 2977 => Loss: 0.3770660829
Iteration 2978 => Loss: 0.3770618851
Iteration 2979 => Loss: 0.3770576902
Iteration 2980 => Loss: 0.3770534983
Iteration 2981 => Loss: 0.3770493092
Iteration 2982 => Loss: 0.3770451231
Iteration 2983 => Loss: 0.3770409399
Iteration 2984 => Loss: 0.3770367596
Iteration 2985 => Loss: 0.3770325822
Iteration 2986 => Loss: 0.3770284077
Iteration 2987 => Loss: 0.3770242361
Iteration 2988 => Loss: 0.3770200675
Iteration 2989 => Loss: 0.3770159017
Iteration 2990 => Loss: 0.3770117388
Iteration 2991 => Loss: 0.3770075788
Iteration 2992 => Loss: 0.3770034216
Iteration 2993 => Loss: 0.3769992674
Iteration 2994 => Loss: 0.3769951160
Iteration 2995 => Loss: 0.3769909675
Iteration 2996 => Loss: 0.3769868219
Iteration 2997 => Loss: 0.3769826791
Iteration 2998 => Loss: 0.3769785393
Iteration 2999 => Loss: 0.3769744022
Iteration 3000 => Loss: 0.3769702681
Iteration 3001 => Loss: 0.3769661368
Iteration 3002 => Loss: 0.3769620083
Iteration 3003 => Loss: 0.3769578827
Iteration 3004 => Loss: 0.3769537600
Iteration 3005 => Loss: 0.3769496401
Iteration 3006 => Loss: 0.3769455230
Iteration 3007 => Loss: 0.3769414088
Iteration 3008 => Loss: 0.3769372974
Iteration 3009 => Loss: 0.3769331888
Iteration 3010 => Loss: 0.3769290831
Iteration 3011 => Loss: 0.3769249802
Iteration 3012 => Loss: 0.3769208801
Iteration 3013 => Loss: 0.3769167829
Iteration 3014 => Loss: 0.3769126884
Iteration 3015 => Loss: 0.3769085968
Iteration 3016 => Loss: 0.3769045080
Iteration 3017 => Loss: 0.3769004220
Iteration 3018 => Loss: 0.3768963388
Iteration 3019 => Loss: 0.3768922584
Iteration 3020 => Loss: 0.3768881808
Iteration 3021 => Loss: 0.3768841060
Iteration 3022 => Loss: 0.3768800340
Iteration 3023 => Loss: 0.3768759648
Iteration 3024 => Loss: 0.3768718984
Iteration 3025 => Loss: 0.3768678347
Iteration 3026 => Loss: 0.3768637739
Iteration 3027 => Loss: 0.3768597158
Iteration 3028 => Loss: 0.3768556605
Iteration 3029 => Loss: 0.3768516080
Iteration 3030 => Loss: 0.3768475582
Iteration 3031 => Loss: 0.3768435112
Iteration 3032 => Loss: 0.3768394670
Iteration 3033 => Loss: 0.3768354255
Iteration 3034 => Loss: 0.3768313868
Iteration 3035 => Loss: 0.3768273509
Iteration 3036 => Loss: 0.3768233177
Iteration 3037 => Loss: 0.3768192872
Iteration 3038 => Loss: 0.3768152595
Iteration 3039 => Loss: 0.3768112345
Iteration 3040 => Loss: 0.3768072123
Iteration 3041 => Loss: 0.3768031928
Iteration 3042 => Loss: 0.3767991761
Iteration 3043 => Loss: 0.3767951621
Iteration 3044 => Loss: 0.3767911508
Iteration 3045 => Loss: 0.3767871422
Iteration 3046 => Loss: 0.3767831364
Iteration 3047 => Loss: 0.3767791333
Iteration 3048 => Loss: 0.3767751329
Iteration 3049 => Loss: 0.3767711352
Iteration 3050 => Loss: 0.3767671403
Iteration 3051 => Loss: 0.3767631480
Iteration 3052 => Loss: 0.3767591584
Iteration 3053 => Loss: 0.3767551716
Iteration 3054 => Loss: 0.3767511875
Iteration 3055 => Loss: 0.3767472060
Iteration 3056 => Loss: 0.3767432272
Iteration 3057 => Loss: 0.3767392512
Iteration 3058 => Loss: 0.3767352778
Iteration 3059 => Loss: 0.3767313071
Iteration 3060 => Loss: 0.3767273391
Iteration 3061 => Loss: 0.3767233738
Iteration 3062 => Loss: 0.3767194111
Iteration 3063 => Loss: 0.3767154512
Iteration 3064 => Loss: 0.3767114939
Iteration 3065 => Loss: 0.3767075392
Iteration 3066 => Loss: 0.3767035873
Iteration 3067 => Loss: 0.3766996380
Iteration 3068 => Loss: 0.3766956913
Iteration 3069 => Loss: 0.3766917474
Iteration 3070 => Loss: 0.3766878060
Iteration 3071 => Loss: 0.3766838674
Iteration 3072 => Loss: 0.3766799313
Iteration 3073 => Loss: 0.3766759980
Iteration 3074 => Loss: 0.3766720672
Iteration 3075 => Loss: 0.3766681391
Iteration 3076 => Loss: 0.3766642137
Iteration 3077 => Loss: 0.3766602909
Iteration 3078 => Loss: 0.3766563707
Iteration 3079 => Loss: 0.3766524531
Iteration 3080 => Loss: 0.3766485382
Iteration 3081 => Loss: 0.3766446259
Iteration 3082 => Loss: 0.3766407162
Iteration 3083 => Loss: 0.3766368092
Iteration 3084 => Loss: 0.3766329047
Iteration 3085 => Loss: 0.3766290029
Iteration 3086 => Loss: 0.3766251037
Iteration 3087 => Loss: 0.3766212070
Iteration 3088 => Loss: 0.3766173130
Iteration 3089 => Loss: 0.3766134216
Iteration 3090 => Loss: 0.3766095328
Iteration 3091 => Loss: 0.3766056466
Iteration 3092 => Loss: 0.3766017630
Iteration 3093 => Loss: 0.3765978820
Iteration 3094 => Loss: 0.3765940035
Iteration 3095 => Loss: 0.3765901277
Iteration 3096 => Loss: 0.3765862544
Iteration 3097 => Loss: 0.3765823837
Iteration 3098 => Loss: 0.3765785156
Iteration 3099 => Loss: 0.3765746501
Iteration 3100 => Loss: 0.3765707872
Iteration 3101 => Loss: 0.3765669268
Iteration 3102 => Loss: 0.3765630689
Iteration 3103 => Loss: 0.3765592137
Iteration 3104 => Loss: 0.3765553610
Iteration 3105 => Loss: 0.3765515109
Iteration 3106 => Loss: 0.3765476633
Iteration 3107 => Loss: 0.3765438182
Iteration 3108 => Loss: 0.3765399758
Iteration 3109 => Loss: 0.3765361358
Iteration 3110 => Loss: 0.3765322985
Iteration 3111 => Loss: 0.3765284636
Iteration 3112 => Loss: 0.3765246313
Iteration 3113 => Loss: 0.3765208016
Iteration 3114 => Loss: 0.3765169743
Iteration 3115 => Loss: 0.3765131497
Iteration 3116 => Loss: 0.3765093275
Iteration 3117 => Loss: 0.3765055079
Iteration 3118 => Loss: 0.3765016907
Iteration 3119 => Loss: 0.3764978762
Iteration 3120 => Loss: 0.3764940641
Iteration 3121 => Loss: 0.3764902545
Iteration 3122 => Loss: 0.3764864475
Iteration 3123 => Loss: 0.3764826430
Iteration 3124 => Loss: 0.3764788409
Iteration 3125 => Loss: 0.3764750414
Iteration 3126 => Loss: 0.3764712444
Iteration 3127 => Loss: 0.3764674499
Iteration 3128 => Loss: 0.3764636579
Iteration 3129 => Loss: 0.3764598684
Iteration 3130 => Loss: 0.3764560813
Iteration 3131 => Loss: 0.3764522968
Iteration 3132 => Loss: 0.3764485148
Iteration 3133 => Loss: 0.3764447352
Iteration 3134 => Loss: 0.3764409581
Iteration 3135 => Loss: 0.3764371835
Iteration 3136 => Loss: 0.3764334114
Iteration 3137 => Loss: 0.3764296417
Iteration 3138 => Loss: 0.3764258746
Iteration 3139 => Loss: 0.3764221099
Iteration 3140 => Loss: 0.3764183476
Iteration 3141 => Loss: 0.3764145878
Iteration 3142 => Loss: 0.3764108305
Iteration 3143 => Loss: 0.3764070757
Iteration 3144 => Loss: 0.3764033233
Iteration 3145 => Loss: 0.3763995733
Iteration 3146 => Loss: 0.3763958258
Iteration 3147 => Loss: 0.3763920808
Iteration 3148 => Loss: 0.3763883382
Iteration 3149 => Loss: 0.3763845980
Iteration 3150 => Loss: 0.3763808603
Iteration 3151 => Loss: 0.3763771251
Iteration 3152 => Loss: 0.3763733922
Iteration 3153 => Loss: 0.3763696618
Iteration 3154 => Loss: 0.3763659338
Iteration 3155 => Loss: 0.3763622083
Iteration 3156 => Loss: 0.3763584852
Iteration 3157 => Loss: 0.3763547645
Iteration 3158 => Loss: 0.3763510462
Iteration 3159 => Loss: 0.3763473303
Iteration 3160 => Loss: 0.3763436169
Iteration 3161 => Loss: 0.3763399059
Iteration 3162 => Loss: 0.3763361973
Iteration 3163 => Loss: 0.3763324910
Iteration 3164 => Loss: 0.3763287872
Iteration 3165 => Loss: 0.3763250858
Iteration 3166 => Loss: 0.3763213868
Iteration 3167 => Loss: 0.3763176902
Iteration 3168 => Loss: 0.3763139960
Iteration 3169 => Loss: 0.3763103042
Iteration 3170 => Loss: 0.3763066148
Iteration 3171 => Loss: 0.3763029278
Iteration 3172 => Loss: 0.3762992431
Iteration 3173 => Loss: 0.3762955609
Iteration 3174 => Loss: 0.3762918810
Iteration 3175 => Loss: 0.3762882035
Iteration 3176 => Loss: 0.3762845283
Iteration 3177 => Loss: 0.3762808556
Iteration 3178 => Loss: 0.3762771852
Iteration 3179 => Loss: 0.3762735172
Iteration 3180 => Loss: 0.3762698515
Iteration 3181 => Loss: 0.3762661883
Iteration 3182 => Loss: 0.3762625273
Iteration 3183 => Loss: 0.3762588688
Iteration 3184 => Loss: 0.3762552126
Iteration 3185 => Loss: 0.3762515587
Iteration 3186 => Loss: 0.3762479072
Iteration 3187 => Loss: 0.3762442580
Iteration 3188 => Loss: 0.3762406112
Iteration 3189 => Loss: 0.3762369668
Iteration 3190 => Loss: 0.3762333246
Iteration 3191 => Loss: 0.3762296849
Iteration 3192 => Loss: 0.3762260474
Iteration 3193 => Loss: 0.3762224123
Iteration 3194 => Loss: 0.3762187795
Iteration 3195 => Loss: 0.3762151491
Iteration 3196 => Loss: 0.3762115209
Iteration 3197 => Loss: 0.3762078951
Iteration 3198 => Loss: 0.3762042717
Iteration 3199 => Loss: 0.3762006505
Iteration 3200 => Loss: 0.3761970317
Iteration 3201 => Loss: 0.3761934151
Iteration 3202 => Loss: 0.3761898009
Iteration 3203 => Loss: 0.3761861890
Iteration 3204 => Loss: 0.3761825794
Iteration 3205 => Loss: 0.3761789721
Iteration 3206 => Loss: 0.3761753672
Iteration 3207 => Loss: 0.3761717645
Iteration 3208 => Loss: 0.3761681641
Iteration 3209 => Loss: 0.3761645660
Iteration 3210 => Loss: 0.3761609702
Iteration 3211 => Loss: 0.3761573767
Iteration 3212 => Loss: 0.3761537855
Iteration 3213 => Loss: 0.3761501965
Iteration 3214 => Loss: 0.3761466099
Iteration 3215 => Loss: 0.3761430255
Iteration 3216 => Loss: 0.3761394434
Iteration 3217 => Loss: 0.3761358636
Iteration 3218 => Loss: 0.3761322861
Iteration 3219 => Loss: 0.3761287108
Iteration 3220 => Loss: 0.3761251378
Iteration 3221 => Loss: 0.3761215671
Iteration 3222 => Loss: 0.3761179986
Iteration 3223 => Loss: 0.3761144324
Iteration 3224 => Loss: 0.3761108685
Iteration 3225 => Loss: 0.3761073068
Iteration 3226 => Loss: 0.3761037474
Iteration 3227 => Loss: 0.3761001902
Iteration 3228 => Loss: 0.3760966353
Iteration 3229 => Loss: 0.3760930826
Iteration 3230 => Loss: 0.3760895322
Iteration 3231 => Loss: 0.3760859840
Iteration 3232 => Loss: 0.3760824381
Iteration 3233 => Loss: 0.3760788944
Iteration 3234 => Loss: 0.3760753530
Iteration 3235 => Loss: 0.3760718137
Iteration 3236 => Loss: 0.3760682767
Iteration 3237 => Loss: 0.3760647420
Iteration 3238 => Loss: 0.3760612094
Iteration 3239 => Loss: 0.3760576791
Iteration 3240 => Loss: 0.3760541511
Iteration 3241 => Loss: 0.3760506252
Iteration 3242 => Loss: 0.3760471015
Iteration 3243 => Loss: 0.3760435801
Iteration 3244 => Loss: 0.3760400609
Iteration 3245 => Loss: 0.3760365439
Iteration 3246 => Loss: 0.3760330291
Iteration 3247 => Loss: 0.3760295165
Iteration 3248 => Loss: 0.3760260062
Iteration 3249 => Loss: 0.3760224980
Iteration 3250 => Loss: 0.3760189920
Iteration 3251 => Loss: 0.3760154882
Iteration 3252 => Loss: 0.3760119866
Iteration 3253 => Loss: 0.3760084873
Iteration 3254 => Loss: 0.3760049901
Iteration 3255 => Loss: 0.3760014951
Iteration 3256 => Loss: 0.3759980022
Iteration 3257 => Loss: 0.3759945116
Iteration 3258 => Loss: 0.3759910232
Iteration 3259 => Loss: 0.3759875369
Iteration 3260 => Loss: 0.3759840528
Iteration 3261 => Loss: 0.3759805709
Iteration 3262 => Loss: 0.3759770911
Iteration 3263 => Loss: 0.3759736136
Iteration 3264 => Loss: 0.3759701382
Iteration 3265 => Loss: 0.3759666649
Iteration 3266 => Loss: 0.3759631939
Iteration 3267 => Loss: 0.3759597250
Iteration 3268 => Loss: 0.3759562582
Iteration 3269 => Loss: 0.3759527936
Iteration 3270 => Loss: 0.3759493312
Iteration 3271 => Loss: 0.3759458709
Iteration 3272 => Loss: 0.3759424128
Iteration 3273 => Loss: 0.3759389568
Iteration 3274 => Loss: 0.3759355030
Iteration 3275 => Loss: 0.3759320513
Iteration 3276 => Loss: 0.3759286018
Iteration 3277 => Loss: 0.3759251544
Iteration 3278 => Loss: 0.3759217091
Iteration 3279 => Loss: 0.3759182660
Iteration 3280 => Loss: 0.3759148250
Iteration 3281 => Loss: 0.3759113861
Iteration 3282 => Loss: 0.3759079494
Iteration 3283 => Loss: 0.3759045148
Iteration 3284 => Loss: 0.3759010823
Iteration 3285 => Loss: 0.3758976519
Iteration 3286 => Loss: 0.3758942237
Iteration 3287 => Loss: 0.3758907976
Iteration 3288 => Loss: 0.3758873736
Iteration 3289 => Loss: 0.3758839517
Iteration 3290 => Loss: 0.3758805319
Iteration 3291 => Loss: 0.3758771143
Iteration 3292 => Loss: 0.3758736987
Iteration 3293 => Loss: 0.3758702853
Iteration 3294 => Loss: 0.3758668739
Iteration 3295 => Loss: 0.3758634647
Iteration 3296 => Loss: 0.3758600575
Iteration 3297 => Loss: 0.3758566525
Iteration 3298 => Loss: 0.3758532495
Iteration 3299 => Loss: 0.3758498487
Iteration 3300 => Loss: 0.3758464499
Iteration 3301 => Loss: 0.3758430532
Iteration 3302 => Loss: 0.3758396586
Iteration 3303 => Loss: 0.3758362661
Iteration 3304 => Loss: 0.3758328757
Iteration 3305 => Loss: 0.3758294873
Iteration 3306 => Loss: 0.3758261010
Iteration 3307 => Loss: 0.3758227168
Iteration 3308 => Loss: 0.3758193347
Iteration 3309 => Loss: 0.3758159547
Iteration 3310 => Loss: 0.3758125767
Iteration 3311 => Loss: 0.3758092008
Iteration 3312 => Loss: 0.3758058269
Iteration 3313 => Loss: 0.3758024551
Iteration 3314 => Loss: 0.3757990854
Iteration 3315 => Loss: 0.3757957178
Iteration 3316 => Loss: 0.3757923521
Iteration 3317 => Loss: 0.3757889886
Iteration 3318 => Loss: 0.3757856271
Iteration 3319 => Loss: 0.3757822676
Iteration 3320 => Loss: 0.3757789102
Iteration 3321 => Loss: 0.3757755549
Iteration 3322 => Loss: 0.3757722016
Iteration 3323 => Loss: 0.3757688503
Iteration 3324 => Loss: 0.3757655011
Iteration 3325 => Loss: 0.3757621539
Iteration 3326 => Loss: 0.3757588087
Iteration 3327 => Loss: 0.3757554656
Iteration 3328 => Loss: 0.3757521245
Iteration 3329 => Loss: 0.3757487854
Iteration 3330 => Loss: 0.3757454484
Iteration 3331 => Loss: 0.3757421134
Iteration 3332 => Loss: 0.3757387804
Iteration 3333 => Loss: 0.3757354495
Iteration 3334 => Loss: 0.3757321205
Iteration 3335 => Loss: 0.3757287936
Iteration 3336 => Loss: 0.3757254687
Iteration 3337 => Loss: 0.3757221458
Iteration 3338 => Loss: 0.3757188249
Iteration 3339 => Loss: 0.3757155060
Iteration 3340 => Loss: 0.3757121891
Iteration 3341 => Loss: 0.3757088743
Iteration 3342 => Loss: 0.3757055614
Iteration 3343 => Loss: 0.3757022506
Iteration 3344 => Loss: 0.3756989417
Iteration 3345 => Loss: 0.3756956348
Iteration 3346 => Loss: 0.3756923300
Iteration 3347 => Loss: 0.3756890271
Iteration 3348 => Loss: 0.3756857262
Iteration 3349 => Loss: 0.3756824273
Iteration 3350 => Loss: 0.3756791304
Iteration 3351 => Loss: 0.3756758355
Iteration 3352 => Loss: 0.3756725425
Iteration 3353 => Loss: 0.3756692516
Iteration 3354 => Loss: 0.3756659626
Iteration 3355 => Loss: 0.3756626756
Iteration 3356 => Loss: 0.3756593905
Iteration 3357 => Loss: 0.3756561075
Iteration 3358 => Loss: 0.3756528264
Iteration 3359 => Loss: 0.3756495473
Iteration 3360 => Loss: 0.3756462701
Iteration 3361 => Loss: 0.3756429949
Iteration 3362 => Loss: 0.3756397217
Iteration 3363 => Loss: 0.3756364504
Iteration 3364 => Loss: 0.3756331811
Iteration 3365 => Loss: 0.3756299138
Iteration 3366 => Loss: 0.3756266484
Iteration 3367 => Loss: 0.3756233850
Iteration 3368 => Loss: 0.3756201235
Iteration 3369 => Loss: 0.3756168639
Iteration 3370 => Loss: 0.3756136063
Iteration 3371 => Loss: 0.3756103507
Iteration 3372 => Loss: 0.3756070970
Iteration 3373 => Loss: 0.3756038452
Iteration 3374 => Loss: 0.3756005954
Iteration 3375 => Loss: 0.3755973475
Iteration 3376 => Loss: 0.3755941015
Iteration 3377 => Loss: 0.3755908575
Iteration 3378 => Loss: 0.3755876154
Iteration 3379 => Loss: 0.3755843753
Iteration 3380 => Loss: 0.3755811370
Iteration 3381 => Loss: 0.3755779007
Iteration 3382 => Loss: 0.3755746663
Iteration 3383 => Loss: 0.3755714339
Iteration 3384 => Loss: 0.3755682033
Iteration 3385 => Loss: 0.3755649747
Iteration 3386 => Loss: 0.3755617480
Iteration 3387 => Loss: 0.3755585232
Iteration 3388 => Loss: 0.3755553003
Iteration 3389 => Loss: 0.3755520794
Iteration 3390 => Loss: 0.3755488603
Iteration 3391 => Loss: 0.3755456431
Iteration 3392 => Loss: 0.3755424279
Iteration 3393 => Loss: 0.3755392145
Iteration 3394 => Loss: 0.3755360031
Iteration 3395 => Loss: 0.3755327935
Iteration 3396 => Loss: 0.3755295858
Iteration 3397 => Loss: 0.3755263801
Iteration 3398 => Loss: 0.3755231762
Iteration 3399 => Loss: 0.3755199742
Iteration 3400 => Loss: 0.3755167741
Iteration 3401 => Loss: 0.3755135759
Iteration 3402 => Loss: 0.3755103796
Iteration 3403 => Loss: 0.3755071852
Iteration 3404 => Loss: 0.3755039926
Iteration 3405 => Loss: 0.3755008019
Iteration 3406 => Loss: 0.3754976131
Iteration 3407 => Loss: 0.3754944262
Iteration 3408 => Loss: 0.3754912412
Iteration 3409 => Loss: 0.3754880580
Iteration 3410 => Loss: 0.3754848767
Iteration 3411 => Loss: 0.3754816972
Iteration 3412 => Loss: 0.3754785197
Iteration 3413 => Loss: 0.3754753439
Iteration 3414 => Loss: 0.3754721701
Iteration 3415 => Loss: 0.3754689981
Iteration 3416 => Loss: 0.3754658280
Iteration 3417 => Loss: 0.3754626597
Iteration 3418 => Loss: 0.3754594933
Iteration 3419 => Loss: 0.3754563287
Iteration 3420 => Loss: 0.3754531660
Iteration 3421 => Loss: 0.3754500051
Iteration 3422 => Loss: 0.3754468461
Iteration 3423 => Loss: 0.3754436890
Iteration 3424 => Loss: 0.3754405336
Iteration 3425 => Loss: 0.3754373801
Iteration 3426 => Loss: 0.3754342285
Iteration 3427 => Loss: 0.3754310787
Iteration 3428 => Loss: 0.3754279307
Iteration 3429 => Loss: 0.3754247846
Iteration 3430 => Loss: 0.3754216403
Iteration 3431 => Loss: 0.3754184978
Iteration 3432 => Loss: 0.3754153572
Iteration 3433 => Loss: 0.3754122183
Iteration 3434 => Loss: 0.3754090813
Iteration 3435 => Loss: 0.3754059462
Iteration 3436 => Loss: 0.3754028128
Iteration 3437 => Loss: 0.3753996813
Iteration 3438 => Loss: 0.3753965516
Iteration 3439 => Loss: 0.3753934237
Iteration 3440 => Loss: 0.3753902976
Iteration 3441 => Loss: 0.3753871733
Iteration 3442 => Loss: 0.3753840509
Iteration 3443 => Loss: 0.3753809302
Iteration 3444 => Loss: 0.3753778114
Iteration 3445 => Loss: 0.3753746944
Iteration 3446 => Loss: 0.3753715791
Iteration 3447 => Loss: 0.3753684657
Iteration 3448 => Loss: 0.3753653541
Iteration 3449 => Loss: 0.3753622442
Iteration 3450 => Loss: 0.3753591362
Iteration 3451 => Loss: 0.3753560300
Iteration 3452 => Loss: 0.3753529255
Iteration 3453 => Loss: 0.3753498228
Iteration 3454 => Loss: 0.3753467220
Iteration 3455 => Loss: 0.3753436229
Iteration 3456 => Loss: 0.3753405256
Iteration 3457 => Loss: 0.3753374301
Iteration 3458 => Loss: 0.3753343363
Iteration 3459 => Loss: 0.3753312444
Iteration 3460 => Loss: 0.3753281542
Iteration 3461 => Loss: 0.3753250658
Iteration 3462 => Loss: 0.3753219792
Iteration 3463 => Loss: 0.3753188944
Iteration 3464 => Loss: 0.3753158113
Iteration 3465 => Loss: 0.3753127300
Iteration 3466 => Loss: 0.3753096504
Iteration 3467 => Loss: 0.3753065726
Iteration 3468 => Loss: 0.3753034966
Iteration 3469 => Loss: 0.3753004224
Iteration 3470 => Loss: 0.3752973499
Iteration 3471 => Loss: 0.3752942792
Iteration 3472 => Loss: 0.3752912102
Iteration 3473 => Loss: 0.3752881430
Iteration 3474 => Loss: 0.3752850775
Iteration 3475 => Loss: 0.3752820138
Iteration 3476 => Loss: 0.3752789518
Iteration 3477 => Loss: 0.3752758916
Iteration 3478 => Loss: 0.3752728332
Iteration 3479 => Loss: 0.3752697764
Iteration 3480 => Loss: 0.3752667215
Iteration 3481 => Loss: 0.3752636682
Iteration 3482 => Loss: 0.3752606167
Iteration 3483 => Loss: 0.3752575670
Iteration 3484 => Loss: 0.3752545189
Iteration 3485 => Loss: 0.3752514726
Iteration 3486 => Loss: 0.3752484281
Iteration 3487 => Loss: 0.3752453853
Iteration 3488 => Loss: 0.3752423442
Iteration 3489 => Loss: 0.3752393048
Iteration 3490 => Loss: 0.3752362672
Iteration 3491 => Loss: 0.3752332312
Iteration 3492 => Loss: 0.3752301970
Iteration 3493 => Loss: 0.3752271646
Iteration 3494 => Loss: 0.3752241338
Iteration 3495 => Loss: 0.3752211048
Iteration 3496 => Loss: 0.3752180774
Iteration 3497 => Loss: 0.3752150518
Iteration 3498 => Loss: 0.3752120279
Iteration 3499 => Loss: 0.3752090057
Iteration 3500 => Loss: 0.3752059853
Iteration 3501 => Loss: 0.3752029665
Iteration 3502 => Loss: 0.3751999494
Iteration 3503 => Loss: 0.3751969341
Iteration 3504 => Loss: 0.3751939204
Iteration 3505 => Loss: 0.3751909084
Iteration 3506 => Loss: 0.3751878982
Iteration 3507 => Loss: 0.3751848896
Iteration 3508 => Loss: 0.3751818827
Iteration 3509 => Loss: 0.3751788775
Iteration 3510 => Loss: 0.3751758741
Iteration 3511 => Loss: 0.3751728723
Iteration 3512 => Loss: 0.3751698722
Iteration 3513 => Loss: 0.3751668737
Iteration 3514 => Loss: 0.3751638770
Iteration 3515 => Loss: 0.3751608819
Iteration 3516 => Loss: 0.3751578886
Iteration 3517 => Loss: 0.3751548969
Iteration 3518 => Loss: 0.3751519069
Iteration 3519 => Loss: 0.3751489185
Iteration 3520 => Loss: 0.3751459319
Iteration 3521 => Loss: 0.3751429469
Iteration 3522 => Loss: 0.3751399636
Iteration 3523 => Loss: 0.3751369819
Iteration 3524 => Loss: 0.3751340019
Iteration 3525 => Loss: 0.3751310236
Iteration 3526 => Loss: 0.3751280470
Iteration 3527 => Loss: 0.3751250720
Iteration 3528 => Loss: 0.3751220987
Iteration 3529 => Loss: 0.3751191270
Iteration 3530 => Loss: 0.3751161570
Iteration 3531 => Loss: 0.3751131887
Iteration 3532 => Loss: 0.3751102220
Iteration 3533 => Loss: 0.3751072569
Iteration 3534 => Loss: 0.3751042936
Iteration 3535 => Loss: 0.3751013318
Iteration 3536 => Loss: 0.3750983717
Iteration 3537 => Loss: 0.3750954133
Iteration 3538 => Loss: 0.3750924565
Iteration 3539 => Loss: 0.3750895014
Iteration 3540 => Loss: 0.3750865479
Iteration 3541 => Loss: 0.3750835960
Iteration 3542 => Loss: 0.3750806458
Iteration 3543 => Loss: 0.3750776972
Iteration 3544 => Loss: 0.3750747502
Iteration 3545 => Loss: 0.3750718049
Iteration 3546 => Loss: 0.3750688612
Iteration 3547 => Loss: 0.3750659191
Iteration 3548 => Loss: 0.3750629787
Iteration 3549 => Loss: 0.3750600399
Iteration 3550 => Loss: 0.3750571027
Iteration 3551 => Loss: 0.3750541672
Iteration 3552 => Loss: 0.3750512333
Iteration 3553 => Loss: 0.3750483009
Iteration 3554 => Loss: 0.3750453703
Iteration 3555 => Loss: 0.3750424412
Iteration 3556 => Loss: 0.3750395137
Iteration 3557 => Loss: 0.3750365879
Iteration 3558 => Loss: 0.3750336637
Iteration 3559 => Loss: 0.3750307411
Iteration 3560 => Loss: 0.3750278201
Iteration 3561 => Loss: 0.3750249007
Iteration 3562 => Loss: 0.3750219829
Iteration 3563 => Loss: 0.3750190667
Iteration 3564 => Loss: 0.3750161521
Iteration 3565 => Loss: 0.3750132391
Iteration 3566 => Loss: 0.3750103278
Iteration 3567 => Loss: 0.3750074180
Iteration 3568 => Loss: 0.3750045098
Iteration 3569 => Loss: 0.3750016032
Iteration 3570 => Loss: 0.3749986982
Iteration 3571 => Loss: 0.3749957948
Iteration 3572 => Loss: 0.3749928930
Iteration 3573 => Loss: 0.3749899928
Iteration 3574 => Loss: 0.3749870942
Iteration 3575 => Loss: 0.3749841971
Iteration 3576 => Loss: 0.3749813017
Iteration 3577 => Loss: 0.3749784078
Iteration 3578 => Loss: 0.3749755155
Iteration 3579 => Loss: 0.3749726248
Iteration 3580 => Loss: 0.3749697356
Iteration 3581 => Loss: 0.3749668481
Iteration 3582 => Loss: 0.3749639621
Iteration 3583 => Loss: 0.3749610777
Iteration 3584 => Loss: 0.3749581948
Iteration 3585 => Loss: 0.3749553136
Iteration 3586 => Loss: 0.3749524339
Iteration 3587 => Loss: 0.3749495557
Iteration 3588 => Loss: 0.3749466792
Iteration 3589 => Loss: 0.3749438042
Iteration 3590 => Loss: 0.3749409307
Iteration 3591 => Loss: 0.3749380589
Iteration 3592 => Loss: 0.3749351886
Iteration 3593 => Loss: 0.3749323198
Iteration 3594 => Loss: 0.3749294526
Iteration 3595 => Loss: 0.3749265869
Iteration 3596 => Loss: 0.3749237229
Iteration 3597 => Loss: 0.3749208603
Iteration 3598 => Loss: 0.3749179993
Iteration 3599 => Loss: 0.3749151399
Iteration 3600 => Loss: 0.3749122820
Iteration 3601 => Loss: 0.3749094257
Iteration 3602 => Loss: 0.3749065709
Iteration 3603 => Loss: 0.3749037176
Iteration 3604 => Loss: 0.3749008659
Iteration 3605 => Loss: 0.3748980157
Iteration 3606 => Loss: 0.3748951671
Iteration 3607 => Loss: 0.3748923200
Iteration 3608 => Loss: 0.3748894744
Iteration 3609 => Loss: 0.3748866304
Iteration 3610 => Loss: 0.3748837879
Iteration 3611 => Loss: 0.3748809469
Iteration 3612 => Loss: 0.3748781075
Iteration 3613 => Loss: 0.3748752696
Iteration 3614 => Loss: 0.3748724332
Iteration 3615 => Loss: 0.3748695983
Iteration 3616 => Loss: 0.3748667650
Iteration 3617 => Loss: 0.3748639332
Iteration 3618 => Loss: 0.3748611029
Iteration 3619 => Loss: 0.3748582741
Iteration 3620 => Loss: 0.3748554469
Iteration 3621 => Loss: 0.3748526211
Iteration 3622 => Loss: 0.3748497969
Iteration 3623 => Loss: 0.3748469742
Iteration 3624 => Loss: 0.3748441530
Iteration 3625 => Loss: 0.3748413333
Iteration 3626 => Loss: 0.3748385151
Iteration 3627 => Loss: 0.3748356985
Iteration 3628 => Loss: 0.3748328833
Iteration 3629 => Loss: 0.3748300696
Iteration 3630 => Loss: 0.3748272575
Iteration 3631 => Loss: 0.3748244468
Iteration 3632 => Loss: 0.3748216377
Iteration 3633 => Loss: 0.3748188300
Iteration 3634 => Loss: 0.3748160238
Iteration 3635 => Loss: 0.3748132192
Iteration 3636 => Loss: 0.3748104160
Iteration 3637 => Loss: 0.3748076143
Iteration 3638 => Loss: 0.3748048141
Iteration 3639 => Loss: 0.3748020154
Iteration 3640 => Loss: 0.3747992182
Iteration 3641 => Loss: 0.3747964225
Iteration 3642 => Loss: 0.3747936283
Iteration 3643 => Loss: 0.3747908355
Iteration 3644 => Loss: 0.3747880442
Iteration 3645 => Loss: 0.3747852544
Iteration 3646 => Loss: 0.3747824661
Iteration 3647 => Loss: 0.3747796793
Iteration 3648 => Loss: 0.3747768939
Iteration 3649 => Loss: 0.3747741100
Iteration 3650 => Loss: 0.3747713276
Iteration 3651 => Loss: 0.3747685467
Iteration 3652 => Loss: 0.3747657672
Iteration 3653 => Loss: 0.3747629892
Iteration 3654 => Loss: 0.3747602127
Iteration 3655 => Loss: 0.3747574376
Iteration 3656 => Loss: 0.3747546640
Iteration 3657 => Loss: 0.3747518919
Iteration 3658 => Loss: 0.3747491212
Iteration 3659 => Loss: 0.3747463520
Iteration 3660 => Loss: 0.3747435843
Iteration 3661 => Loss: 0.3747408180
Iteration 3662 => Loss: 0.3747380531
Iteration 3663 => Loss: 0.3747352898
Iteration 3664 => Loss: 0.3747325278
Iteration 3665 => Loss: 0.3747297674
Iteration 3666 => Loss: 0.3747270083
Iteration 3667 => Loss: 0.3747242507
Iteration 3668 => Loss: 0.3747214946
Iteration 3669 => Loss: 0.3747187399
Iteration 3670 => Loss: 0.3747159867
Iteration 3671 => Loss: 0.3747132349
Iteration 3672 => Loss: 0.3747104846
Iteration 3673 => Loss: 0.3747077357
Iteration 3674 => Loss: 0.3747049882
Iteration 3675 => Loss: 0.3747022422
Iteration 3676 => Loss: 0.3746994976
Iteration 3677 => Loss: 0.3746967544
Iteration 3678 => Loss: 0.3746940127
Iteration 3679 => Loss: 0.3746912724
Iteration 3680 => Loss: 0.3746885335
Iteration 3681 => Loss: 0.3746857961
Iteration 3682 => Loss: 0.3746830601
Iteration 3683 => Loss: 0.3746803255
Iteration 3684 => Loss: 0.3746775924
Iteration 3685 => Loss: 0.3746748606
Iteration 3686 => Loss: 0.3746721303
Iteration 3687 => Loss: 0.3746694015
Iteration 3688 => Loss: 0.3746666740
Iteration 3689 => Loss: 0.3746639479
Iteration 3690 => Loss: 0.3746612233
Iteration 3691 => Loss: 0.3746585001
Iteration 3692 => Loss: 0.3746557783
Iteration 3693 => Loss: 0.3746530579
Iteration 3694 => Loss: 0.3746503390
Iteration 3695 => Loss: 0.3746476214
Iteration 3696 => Loss: 0.3746449053
Iteration 3697 => Loss: 0.3746421905
Iteration 3698 => Loss: 0.3746394772
Iteration 3699 => Loss: 0.3746367652
Iteration 3700 => Loss: 0.3746340547
Iteration 3701 => Loss: 0.3746313456
Iteration 3702 => Loss: 0.3746286379
Iteration 3703 => Loss: 0.3746259315
Iteration 3704 => Loss: 0.3746232266
Iteration 3705 => Loss: 0.3746205231
Iteration 3706 => Loss: 0.3746178210
Iteration 3707 => Loss: 0.3746151202
Iteration 3708 => Loss: 0.3746124209
Iteration 3709 => Loss: 0.3746097229
Iteration 3710 => Loss: 0.3746070263
Iteration 3711 => Loss: 0.3746043312
Iteration 3712 => Loss: 0.3746016374
Iteration 3713 => Loss: 0.3745989450
Iteration 3714 => Loss: 0.3745962540
Iteration 3715 => Loss: 0.3745935643
Iteration 3716 => Loss: 0.3745908761
Iteration 3717 => Loss: 0.3745881892
Iteration 3718 => Loss: 0.3745855037
Iteration 3719 => Loss: 0.3745828196
Iteration 3720 => Loss: 0.3745801368
Iteration 3721 => Loss: 0.3745774555
Iteration 3722 => Loss: 0.3745747755
Iteration 3723 => Loss: 0.3745720969
Iteration 3724 => Loss: 0.3745694196
Iteration 3725 => Loss: 0.3745667438
Iteration 3726 => Loss: 0.3745640693
Iteration 3727 => Loss: 0.3745613961
Iteration 3728 => Loss: 0.3745587243
Iteration 3729 => Loss: 0.3745560539
Iteration 3730 => Loss: 0.3745533849
Iteration 3731 => Loss: 0.3745507172
Iteration 3732 => Loss: 0.3745480509
Iteration 3733 => Loss: 0.3745453859
Iteration 3734 => Loss: 0.3745427223
Iteration 3735 => Loss: 0.3745400601
Iteration 3736 => Loss: 0.3745373992
Iteration 3737 => Loss: 0.3745347396
Iteration 3738 => Loss: 0.3745320814
Iteration 3739 => Loss: 0.3745294246
Iteration 3740 => Loss: 0.3745267691
Iteration 3741 => Loss: 0.3745241150
Iteration 3742 => Loss: 0.3745214622
Iteration 3743 => Loss: 0.3745188108
Iteration 3744 => Loss: 0.3745161607
Iteration 3745 => Loss: 0.3745135119
Iteration 3746 => Loss: 0.3745108645
Iteration 3747 => Loss: 0.3745082184
Iteration 3748 => Loss: 0.3745055737
Iteration 3749 => Loss: 0.3745029303
Iteration 3750 => Loss: 0.3745002883
Iteration 3751 => Loss: 0.3744976476
Iteration 3752 => Loss: 0.3744950082
Iteration 3753 => Loss: 0.3744923701
Iteration 3754 => Loss: 0.3744897334
Iteration 3755 => Loss: 0.3744870980
Iteration 3756 => Loss: 0.3744844640
Iteration 3757 => Loss: 0.3744818312
Iteration 3758 => Loss: 0.3744791998
Iteration 3759 => Loss: 0.3744765698
Iteration 3760 => Loss: 0.3744739410
Iteration 3761 => Loss: 0.3744713136
Iteration 3762 => Loss: 0.3744686875
Iteration 3763 => Loss: 0.3744660627
Iteration 3764 => Loss: 0.3744634392
Iteration 3765 => Loss: 0.3744608171
Iteration 3766 => Loss: 0.3744581963
Iteration 3767 => Loss: 0.3744555768
Iteration 3768 => Loss: 0.3744529586
Iteration 3769 => Loss: 0.3744503417
Iteration 3770 => Loss: 0.3744477261
Iteration 3771 => Loss: 0.3744451118
Iteration 3772 => Loss: 0.3744424989
Iteration 3773 => Loss: 0.3744398872
Iteration 3774 => Loss: 0.3744372769
Iteration 3775 => Loss: 0.3744346678
Iteration 3776 => Loss: 0.3744320601
Iteration 3777 => Loss: 0.3744294537
Iteration 3778 => Loss: 0.3744268486
Iteration 3779 => Loss: 0.3744242447
Iteration 3780 => Loss: 0.3744216422
Iteration 3781 => Loss: 0.3744190410
Iteration 3782 => Loss: 0.3744164410
Iteration 3783 => Loss: 0.3744138424
Iteration 3784 => Loss: 0.3744112451
Iteration 3785 => Loss: 0.3744086490
Iteration 3786 => Loss: 0.3744060543
Iteration 3787 => Loss: 0.3744034608
Iteration 3788 => Loss: 0.3744008686
Iteration 3789 => Loss: 0.3743982777
Iteration 3790 => Loss: 0.3743956881
Iteration 3791 => Loss: 0.3743930998
Iteration 3792 => Loss: 0.3743905128
Iteration 3793 => Loss: 0.3743879270
Iteration 3794 => Loss: 0.3743853425
Iteration 3795 => Loss: 0.3743827594
Iteration 3796 => Loss: 0.3743801775
Iteration 3797 => Loss: 0.3743775968
Iteration 3798 => Loss: 0.3743750175
Iteration 3799 => Loss: 0.3743724394
Iteration 3800 => Loss: 0.3743698626
Iteration 3801 => Loss: 0.3743672871
Iteration 3802 => Loss: 0.3743647128
Iteration 3803 => Loss: 0.3743621398
Iteration 3804 => Loss: 0.3743595681
Iteration 3805 => Loss: 0.3743569976
Iteration 3806 => Loss: 0.3743544285
Iteration 3807 => Loss: 0.3743518605
Iteration 3808 => Loss: 0.3743492939
Iteration 3809 => Loss: 0.3743467285
Iteration 3810 => Loss: 0.3743441644
Iteration 3811 => Loss: 0.3743416015
Iteration 3812 => Loss: 0.3743390399
Iteration 3813 => Loss: 0.3743364796
Iteration 3814 => Loss: 0.3743339205
Iteration 3815 => Loss: 0.3743313626
Iteration 3816 => Loss: 0.3743288061
Iteration 3817 => Loss: 0.3743262507
Iteration 3818 => Loss: 0.3743236967
Iteration 3819 => Loss: 0.3743211438
Iteration 3820 => Loss: 0.3743185923
Iteration 3821 => Loss: 0.3743160420
Iteration 3822 => Loss: 0.3743134929
Iteration 3823 => Loss: 0.3743109451
Iteration 3824 => Loss: 0.3743083985
Iteration 3825 => Loss: 0.3743058531
Iteration 3826 => Loss: 0.3743033091
Iteration 3827 => Loss: 0.3743007662
Iteration 3828 => Loss: 0.3742982246
Iteration 3829 => Loss: 0.3742956842
Iteration 3830 => Loss: 0.3742931451
Iteration 3831 => Loss: 0.3742906072
Iteration 3832 => Loss: 0.3742880705
Iteration 3833 => Loss: 0.3742855351
Iteration 3834 => Loss: 0.3742830009
Iteration 3835 => Loss: 0.3742804680
Iteration 3836 => Loss: 0.3742779362
Iteration 3837 => Loss: 0.3742754057
Iteration 3838 => Loss: 0.3742728765
Iteration 3839 => Loss: 0.3742703484
Iteration 3840 => Loss: 0.3742678216
Iteration 3841 => Loss: 0.3742652960
Iteration 3842 => Loss: 0.3742627717
Iteration 3843 => Loss: 0.3742602485
Iteration 3844 => Loss: 0.3742577266
Iteration 3845 => Loss: 0.3742552059
Iteration 3846 => Loss: 0.3742526864
Iteration 3847 => Loss: 0.3742501682
Iteration 3848 => Loss: 0.3742476511
Iteration 3849 => Loss: 0.3742451353
Iteration 3850 => Loss: 0.3742426207
Iteration 3851 => Loss: 0.3742401073
Iteration 3852 => Loss: 0.3742375951
Iteration 3853 => Loss: 0.3742350841
Iteration 3854 => Loss: 0.3742325744
Iteration 3855 => Loss: 0.3742300658
Iteration 3856 => Loss: 0.3742275585
Iteration 3857 => Loss: 0.3742250523
Iteration 3858 => Loss: 0.3742225474
Iteration 3859 => Loss: 0.3742200437
Iteration 3860 => Loss: 0.3742175411
Iteration 3861 => Loss: 0.3742150398
Iteration 3862 => Loss: 0.3742125397
Iteration 3863 => Loss: 0.3742100408
Iteration 3864 => Loss: 0.3742075430
Iteration 3865 => Loss: 0.3742050465
Iteration 3866 => Loss: 0.3742025512
Iteration 3867 => Loss: 0.3742000570
Iteration 3868 => Loss: 0.3741975641
Iteration 3869 => Loss: 0.3741950724
Iteration 3870 => Loss: 0.3741925818
Iteration 3871 => Loss: 0.3741900924
Iteration 3872 => Loss: 0.3741876043
Iteration 3873 => Loss: 0.3741851173
Iteration 3874 => Loss: 0.3741826315
Iteration 3875 => Loss: 0.3741801469
Iteration 3876 => Loss: 0.3741776634
Iteration 3877 => Loss: 0.3741751812
Iteration 3878 => Loss: 0.3741727001
Iteration 3879 => Loss: 0.3741702203
Iteration 3880 => Loss: 0.3741677416
Iteration 3881 => Loss: 0.3741652640
Iteration 3882 => Loss: 0.3741627877
Iteration 3883 => Loss: 0.3741603125
Iteration 3884 => Loss: 0.3741578386
Iteration 3885 => Loss: 0.3741553657
Iteration 3886 => Loss: 0.3741528941
Iteration 3887 => Loss: 0.3741504236
Iteration 3888 => Loss: 0.3741479543
Iteration 3889 => Loss: 0.3741454862
Iteration 3890 => Loss: 0.3741430193
Iteration 3891 => Loss: 0.3741405535
Iteration 3892 => Loss: 0.3741380889
Iteration 3893 => Loss: 0.3741356254
Iteration 3894 => Loss: 0.3741331631
Iteration 3895 => Loss: 0.3741307020
Iteration 3896 => Loss: 0.3741282421
Iteration 3897 => Loss: 0.3741257833
Iteration 3898 => Loss: 0.3741233256
Iteration 3899 => Loss: 0.3741208692
Iteration 3900 => Loss: 0.3741184138
Iteration 3901 => Loss: 0.3741159597
Iteration 3902 => Loss: 0.3741135067
Iteration 3903 => Loss: 0.3741110548
Iteration 3904 => Loss: 0.3741086041
Iteration 3905 => Loss: 0.3741061546
Iteration 3906 => Loss: 0.3741037062
Iteration 3907 => Loss: 0.3741012590
Iteration 3908 => Loss: 0.3740988129
Iteration 3909 => Loss: 0.3740963679
Iteration 3910 => Loss: 0.3740939241
Iteration 3911 => Loss: 0.3740914815
Iteration 3912 => Loss: 0.3740890400
Iteration 3913 => Loss: 0.3740865996
Iteration 3914 => Loss: 0.3740841604
Iteration 3915 => Loss: 0.3740817223
Iteration 3916 => Loss: 0.3740792854
Iteration 3917 => Loss: 0.3740768496
Iteration 3918 => Loss: 0.3740744150
Iteration 3919 => Loss: 0.3740719815
Iteration 3920 => Loss: 0.3740695491
Iteration 3921 => Loss: 0.3740671178
Iteration 3922 => Loss: 0.3740646877
Iteration 3923 => Loss: 0.3740622588
Iteration 3924 => Loss: 0.3740598309
Iteration 3925 => Loss: 0.3740574042
Iteration 3926 => Loss: 0.3740549786
Iteration 3927 => Loss: 0.3740525542
Iteration 3928 => Loss: 0.3740501309
Iteration 3929 => Loss: 0.3740477087
Iteration 3930 => Loss: 0.3740452876
Iteration 3931 => Loss: 0.3740428676
Iteration 3932 => Loss: 0.3740404488
Iteration 3933 => Loss: 0.3740380311
Iteration 3934 => Loss: 0.3740356145
Iteration 3935 => Loss: 0.3740331991
Iteration 3936 => Loss: 0.3740307848
Iteration 3937 => Loss: 0.3740283715
Iteration 3938 => Loss: 0.3740259594
Iteration 3939 => Loss: 0.3740235485
Iteration 3940 => Loss: 0.3740211386
Iteration 3941 => Loss: 0.3740187298
Iteration 3942 => Loss: 0.3740163222
Iteration 3943 => Loss: 0.3740139157
Iteration 3944 => Loss: 0.3740115103
Iteration 3945 => Loss: 0.3740091060
Iteration 3946 => Loss: 0.3740067028
Iteration 3947 => Loss: 0.3740043007
Iteration 3948 => Loss: 0.3740018997
Iteration 3949 => Loss: 0.3739994998
Iteration 3950 => Loss: 0.3739971010
Iteration 3951 => Loss: 0.3739947034
Iteration 3952 => Loss: 0.3739923068
Iteration 3953 => Loss: 0.3739899113
Iteration 3954 => Loss: 0.3739875170
Iteration 3955 => Loss: 0.3739851237
Iteration 3956 => Loss: 0.3739827316
Iteration 3957 => Loss: 0.3739803405
Iteration 3958 => Loss: 0.3739779505
Iteration 3959 => Loss: 0.3739755617
Iteration 3960 => Loss: 0.3739731739
Iteration 3961 => Loss: 0.3739707872
Iteration 3962 => Loss: 0.3739684016
Iteration 3963 => Loss: 0.3739660171
Iteration 3964 => Loss: 0.3739636337
Iteration 3965 => Loss: 0.3739612514
Iteration 3966 => Loss: 0.3739588701
Iteration 3967 => Loss: 0.3739564900
Iteration 3968 => Loss: 0.3739541109
Iteration 3969 => Loss: 0.3739517330
Iteration 3970 => Loss: 0.3739493561
Iteration 3971 => Loss: 0.3739469803
Iteration 3972 => Loss: 0.3739446055
Iteration 3973 => Loss: 0.3739422319
Iteration 3974 => Loss: 0.3739398593
Iteration 3975 => Loss: 0.3739374879
Iteration 3976 => Loss: 0.3739351175
Iteration 3977 => Loss: 0.3739327481
Iteration 3978 => Loss: 0.3739303799
Iteration 3979 => Loss: 0.3739280127
Iteration 3980 => Loss: 0.3739256466
Iteration 3981 => Loss: 0.3739232816
Iteration 3982 => Loss: 0.3739209176
Iteration 3983 => Loss: 0.3739185547
Iteration 3984 => Loss: 0.3739161929
Iteration 3985 => Loss: 0.3739138322
Iteration 3986 => Loss: 0.3739114725
Iteration 3987 => Loss: 0.3739091139
Iteration 3988 => Loss: 0.3739067563
Iteration 3989 => Loss: 0.3739043999
Iteration 3990 => Loss: 0.3739020445
Iteration 3991 => Loss: 0.3738996901
Iteration 3992 => Loss: 0.3738973368
Iteration 3993 => Loss: 0.3738949846
Iteration 3994 => Loss: 0.3738926334
Iteration 3995 => Loss: 0.3738902833
Iteration 3996 => Loss: 0.3738879343
Iteration 3997 => Loss: 0.3738855863
Iteration 3998 => Loss: 0.3738832393
Iteration 3999 => Loss: 0.3738808934
Iteration 4000 => Loss: 0.3738785486
Iteration 4001 => Loss: 0.3738762048
Iteration 4002 => Loss: 0.3738738621
Iteration 4003 => Loss: 0.3738715204
Iteration 4004 => Loss: 0.3738691798
Iteration 4005 => Loss: 0.3738668402
Iteration 4006 => Loss: 0.3738645017
Iteration 4007 => Loss: 0.3738621642
Iteration 4008 => Loss: 0.3738598278
Iteration 4009 => Loss: 0.3738574924
Iteration 4010 => Loss: 0.3738551581
Iteration 4011 => Loss: 0.3738528248
Iteration 4012 => Loss: 0.3738504925
Iteration 4013 => Loss: 0.3738481613
Iteration 4014 => Loss: 0.3738458312
Iteration 4015 => Loss: 0.3738435020
Iteration 4016 => Loss: 0.3738411739
Iteration 4017 => Loss: 0.3738388469
Iteration 4018 => Loss: 0.3738365208
Iteration 4019 => Loss: 0.3738341959
Iteration 4020 => Loss: 0.3738318719
Iteration 4021 => Loss: 0.3738295490
Iteration 4022 => Loss: 0.3738272271
Iteration 4023 => Loss: 0.3738249063
Iteration 4024 => Loss: 0.3738225864
Iteration 4025 => Loss: 0.3738202676
Iteration 4026 => Loss: 0.3738179499
Iteration 4027 => Loss: 0.3738156331
Iteration 4028 => Loss: 0.3738133174
Iteration 4029 => Loss: 0.3738110027
Iteration 4030 => Loss: 0.3738086891
Iteration 4031 => Loss: 0.3738063765
Iteration 4032 => Loss: 0.3738040648
Iteration 4033 => Loss: 0.3738017543
Iteration 4034 => Loss: 0.3737994447
Iteration 4035 => Loss: 0.3737971361
Iteration 4036 => Loss: 0.3737948286
Iteration 4037 => Loss: 0.3737925221
Iteration 4038 => Loss: 0.3737902166
Iteration 4039 => Loss: 0.3737879121
Iteration 4040 => Loss: 0.3737856087
Iteration 4041 => Loss: 0.3737833062
Iteration 4042 => Loss: 0.3737810048
Iteration 4043 => Loss: 0.3737787044
Iteration 4044 => Loss: 0.3737764050
Iteration 4045 => Loss: 0.3737741066
Iteration 4046 => Loss: 0.3737718092
Iteration 4047 => Loss: 0.3737695128
Iteration 4048 => Loss: 0.3737672174
Iteration 4049 => Loss: 0.3737649231
Iteration 4050 => Loss: 0.3737626297
Iteration 4051 => Loss: 0.3737603374
Iteration 4052 => Loss: 0.3737580460
Iteration 4053 => Loss: 0.3737557557
Iteration 4054 => Loss: 0.3737534663
Iteration 4055 => Loss: 0.3737511780
Iteration 4056 => Loss: 0.3737488906
Iteration 4057 => Loss: 0.3737466043
Iteration 4058 => Loss: 0.3737443189
Iteration 4059 => Loss: 0.3737420346
Iteration 4060 => Loss: 0.3737397513
Iteration 4061 => Loss: 0.3737374689
Iteration 4062 => Loss: 0.3737351875
Iteration 4063 => Loss: 0.3737329072
Iteration 4064 => Loss: 0.3737306278
Iteration 4065 => Loss: 0.3737283494
Iteration 4066 => Loss: 0.3737260720
Iteration 4067 => Loss: 0.3737237956
Iteration 4068 => Loss: 0.3737215202
Iteration 4069 => Loss: 0.3737192458
Iteration 4070 => Loss: 0.3737169724
Iteration 4071 => Loss: 0.3737146999
Iteration 4072 => Loss: 0.3737124285
Iteration 4073 => Loss: 0.3737101580
Iteration 4074 => Loss: 0.3737078885
Iteration 4075 => Loss: 0.3737056200
Iteration 4076 => Loss: 0.3737033525
Iteration 4077 => Loss: 0.3737010859
Iteration 4078 => Loss: 0.3736988203
Iteration 4079 => Loss: 0.3736965558
Iteration 4080 => Loss: 0.3736942921
Iteration 4081 => Loss: 0.3736920295
Iteration 4082 => Loss: 0.3736897679
Iteration 4083 => Loss: 0.3736875072
Iteration 4084 => Loss: 0.3736852475
Iteration 4085 => Loss: 0.3736829887
Iteration 4086 => Loss: 0.3736807310
Iteration 4087 => Loss: 0.3736784742
Iteration 4088 => Loss: 0.3736762184
Iteration 4089 => Loss: 0.3736739635
Iteration 4090 => Loss: 0.3736717097
Iteration 4091 => Loss: 0.3736694567
Iteration 4092 => Loss: 0.3736672048
Iteration 4093 => Loss: 0.3736649538
Iteration 4094 => Loss: 0.3736627038
Iteration 4095 => Loss: 0.3736604548
Iteration 4096 => Loss: 0.3736582067
Iteration 4097 => Loss: 0.3736559596
Iteration 4098 => Loss: 0.3736537134
Iteration 4099 => Loss: 0.3736514682
Iteration 4100 => Loss: 0.3736492240
Iteration 4101 => Loss: 0.3736469807
Iteration 4102 => Loss: 0.3736447384
Iteration 4103 => Loss: 0.3736424970
Iteration 4104 => Loss: 0.3736402566
Iteration 4105 => Loss: 0.3736380172
Iteration 4106 => Loss: 0.3736357787
Iteration 4107 => Loss: 0.3736335412
Iteration 4108 => Loss: 0.3736313046
Iteration 4109 => Loss: 0.3736290690
Iteration 4110 => Loss: 0.3736268343
Iteration 4111 => Loss: 0.3736246005
Iteration 4112 => Loss: 0.3736223678
Iteration 4113 => Loss: 0.3736201359
Iteration 4114 => Loss: 0.3736179051
Iteration 4115 => Loss: 0.3736156751
Iteration 4116 => Loss: 0.3736134461
Iteration 4117 => Loss: 0.3736112181
Iteration 4118 => Loss: 0.3736089910
Iteration 4119 => Loss: 0.3736067648
Iteration 4120 => Loss: 0.3736045396
Iteration 4121 => Loss: 0.3736023153
Iteration 4122 => Loss: 0.3736000920
Iteration 4123 => Loss: 0.3735978696
Iteration 4124 => Loss: 0.3735956482
Iteration 4125 => Loss: 0.3735934277
Iteration 4126 => Loss: 0.3735912081
Iteration 4127 => Loss: 0.3735889894
Iteration 4128 => Loss: 0.3735867717
Iteration 4129 => Loss: 0.3735845550
Iteration 4130 => Loss: 0.3735823391
Iteration 4131 => Loss: 0.3735801242
Iteration 4132 => Loss: 0.3735779103
Iteration 4133 => Loss: 0.3735756972
Iteration 4134 => Loss: 0.3735734851
Iteration 4135 => Loss: 0.3735712739
Iteration 4136 => Loss: 0.3735690637
Iteration 4137 => Loss: 0.3735668544
Iteration 4138 => Loss: 0.3735646460
Iteration 4139 => Loss: 0.3735624385
Iteration 4140 => Loss: 0.3735602320
Iteration 4141 => Loss: 0.3735580263
Iteration 4142 => Loss: 0.3735558216
Iteration 4143 => Loss: 0.3735536179
Iteration 4144 => Loss: 0.3735514150
Iteration 4145 => Loss: 0.3735492131
Iteration 4146 => Loss: 0.3735470121
Iteration 4147 => Loss: 0.3735448120
Iteration 4148 => Loss: 0.3735426128
Iteration 4149 => Loss: 0.3735404146
Iteration 4150 => Loss: 0.3735382172
Iteration 4151 => Loss: 0.3735360208
Iteration 4152 => Loss: 0.3735338253
Iteration 4153 => Loss: 0.3735316307
Iteration 4154 => Loss: 0.3735294370
Iteration 4155 => Loss: 0.3735272443
Iteration 4156 => Loss: 0.3735250524
Iteration 4157 => Loss: 0.3735228615
Iteration 4158 => Loss: 0.3735206714
Iteration 4159 => Loss: 0.3735184823
Iteration 4160 => Loss: 0.3735162941
Iteration 4161 => Loss: 0.3735141068
Iteration 4162 => Loss: 0.3735119204
Iteration 4163 => Loss: 0.3735097349
Iteration 4164 => Loss: 0.3735075503
Iteration 4165 => Loss: 0.3735053666
Iteration 4166 => Loss: 0.3735031838
Iteration 4167 => Loss: 0.3735010020
Iteration 4168 => Loss: 0.3734988210
Iteration 4169 => Loss: 0.3734966409
Iteration 4170 => Loss: 0.3734944617
Iteration 4171 => Loss: 0.3734922835
Iteration 4172 => Loss: 0.3734901061
Iteration 4173 => Loss: 0.3734879296
Iteration 4174 => Loss: 0.3734857540
Iteration 4175 => Loss: 0.3734835793
Iteration 4176 => Loss: 0.3734814055
Iteration 4177 => Loss: 0.3734792326
Iteration 4178 => Loss: 0.3734770606
Iteration 4179 => Loss: 0.3734748895
Iteration 4180 => Loss: 0.3734727193
Iteration 4181 => Loss: 0.3734705500
Iteration 4182 => Loss: 0.3734683815
Iteration 4183 => Loss: 0.3734662140
Iteration 4184 => Loss: 0.3734640473
Iteration 4185 => Loss: 0.3734618816
Iteration 4186 => Loss: 0.3734597167
Iteration 4187 => Loss: 0.3734575527
Iteration 4188 => Loss: 0.3734553895
Iteration 4189 => Loss: 0.3734532273
Iteration 4190 => Loss: 0.3734510660
Iteration 4191 => Loss: 0.3734489055
Iteration 4192 => Loss: 0.3734467459
Iteration 4193 => Loss: 0.3734445872
Iteration 4194 => Loss: 0.3734424294
Iteration 4195 => Loss: 0.3734402725
Iteration 4196 => Loss: 0.3734381164
Iteration 4197 => Loss: 0.3734359612
Iteration 4198 => Loss: 0.3734338069
Iteration 4199 => Loss: 0.3734316535
Iteration 4200 => Loss: 0.3734295009
Iteration 4201 => Loss: 0.3734273493
Iteration 4202 => Loss: 0.3734251984
Iteration 4203 => Loss: 0.3734230485
Iteration 4204 => Loss: 0.3734208995
Iteration 4205 => Loss: 0.3734187513
Iteration 4206 => Loss: 0.3734166039
Iteration 4207 => Loss: 0.3734144575
Iteration 4208 => Loss: 0.3734123119
Iteration 4209 => Loss: 0.3734101672
Iteration 4210 => Loss: 0.3734080234
Iteration 4211 => Loss: 0.3734058804
Iteration 4212 => Loss: 0.3734037383
Iteration 4213 => Loss: 0.3734015970
Iteration 4214 => Loss: 0.3733994567
Iteration 4215 => Loss: 0.3733973171
Iteration 4216 => Loss: 0.3733951785
Iteration 4217 => Loss: 0.3733930407
Iteration 4218 => Loss: 0.3733909038
Iteration 4219 => Loss: 0.3733887677
Iteration 4220 => Loss: 0.3733866325
Iteration 4221 => Loss: 0.3733844981
Iteration 4222 => Loss: 0.3733823646
Iteration 4223 => Loss: 0.3733802320
Iteration 4224 => Loss: 0.3733781002
Iteration 4225 => Loss: 0.3733759693
Iteration 4226 => Loss: 0.3733738392
Iteration 4227 => Loss: 0.3733717100
Iteration 4228 => Loss: 0.3733695817
Iteration 4229 => Loss: 0.3733674542
Iteration 4230 => Loss: 0.3733653275
Iteration 4231 => Loss: 0.3733632017
Iteration 4232 => Loss: 0.3733610767
Iteration 4233 => Loss: 0.3733589526
Iteration 4234 => Loss: 0.3733568294
Iteration 4235 => Loss: 0.3733547070
Iteration 4236 => Loss: 0.3733525854
Iteration 4237 => Loss: 0.3733504647
Iteration 4238 => Loss: 0.3733483448
Iteration 4239 => Loss: 0.3733462258
Iteration 4240 => Loss: 0.3733441076
Iteration 4241 => Loss: 0.3733419903
Iteration 4242 => Loss: 0.3733398738
Iteration 4243 => Loss: 0.3733377581
Iteration 4244 => Loss: 0.3733356433
Iteration 4245 => Loss: 0.3733335294
Iteration 4246 => Loss: 0.3733314162
Iteration 4247 => Loss: 0.3733293039
Iteration 4248 => Loss: 0.3733271925
Iteration 4249 => Loss: 0.3733250819
Iteration 4250 => Loss: 0.3733229721
Iteration 4251 => Loss: 0.3733208631
Iteration 4252 => Loss: 0.3733187550
Iteration 4253 => Loss: 0.3733166477
Iteration 4254 => Loss: 0.3733145413
Iteration 4255 => Loss: 0.3733124357
Iteration 4256 => Loss: 0.3733103309
Iteration 4257 => Loss: 0.3733082270
Iteration 4258 => Loss: 0.3733061238
Iteration 4259 => Loss: 0.3733040216
Iteration 4260 => Loss: 0.3733019201
Iteration 4261 => Loss: 0.3732998195
Iteration 4262 => Loss: 0.3732977197
Iteration 4263 => Loss: 0.3732956207
Iteration 4264 => Loss: 0.3732935225
Iteration 4265 => Loss: 0.3732914252
Iteration 4266 => Loss: 0.3732893287
Iteration 4267 => Loss: 0.3732872330
Iteration 4268 => Loss: 0.3732851382
Iteration 4269 => Loss: 0.3732830441
Iteration 4270 => Loss: 0.3732809509
Iteration 4271 => Loss: 0.3732788585
Iteration 4272 => Loss: 0.3732767670
Iteration 4273 => Loss: 0.3732746762
Iteration 4274 => Loss: 0.3732725863
Iteration 4275 => Loss: 0.3732704972
Iteration 4276 => Loss: 0.3732684089
Iteration 4277 => Loss: 0.3732663214
Iteration 4278 => Loss: 0.3732642347
Iteration 4279 => Loss: 0.3732621488
Iteration 4280 => Loss: 0.3732600638
Iteration 4281 => Loss: 0.3732579796
Iteration 4282 => Loss: 0.3732558962
Iteration 4283 => Loss: 0.3732538136
Iteration 4284 => Loss: 0.3732517318
Iteration 4285 => Loss: 0.3732496508
Iteration 4286 => Loss: 0.3732475706
Iteration 4287 => Loss: 0.3732454912
Iteration 4288 => Loss: 0.3732434127
Iteration 4289 => Loss: 0.3732413349
Iteration 4290 => Loss: 0.3732392580
Iteration 4291 => Loss: 0.3732371819
Iteration 4292 => Loss: 0.3732351065
Iteration 4293 => Loss: 0.3732330320
Iteration 4294 => Loss: 0.3732309583
Iteration 4295 => Loss: 0.3732288854
Iteration 4296 => Loss: 0.3732268132
Iteration 4297 => Loss: 0.3732247419
Iteration 4298 => Loss: 0.3732226714
Iteration 4299 => Loss: 0.3732206017
Iteration 4300 => Loss: 0.3732185328
Iteration 4301 => Loss: 0.3732164646
Iteration 4302 => Loss: 0.3732143973
Iteration 4303 => Loss: 0.3732123308
Iteration 4304 => Loss: 0.3732102651
Iteration 4305 => Loss: 0.3732082001
Iteration 4306 => Loss: 0.3732061360
Iteration 4307 => Loss: 0.3732040727
Iteration 4308 => Loss: 0.3732020101
Iteration 4309 => Loss: 0.3731999483
Iteration 4310 => Loss: 0.3731978874
Iteration 4311 => Loss: 0.3731958272
Iteration 4312 => Loss: 0.3731937678
Iteration 4313 => Loss: 0.3731917092
Iteration 4314 => Loss: 0.3731896514
Iteration 4315 => Loss: 0.3731875944
Iteration 4316 => Loss: 0.3731855382
Iteration 4317 => Loss: 0.3731834827
Iteration 4318 => Loss: 0.3731814281
Iteration 4319 => Loss: 0.3731793742
Iteration 4320 => Loss: 0.3731773211
Iteration 4321 => Loss: 0.3731752688
Iteration 4322 => Loss: 0.3731732173
Iteration 4323 => Loss: 0.3731711666
Iteration 4324 => Loss: 0.3731691166
Iteration 4325 => Loss: 0.3731670674
Iteration 4326 => Loss: 0.3731650190
Iteration 4327 => Loss: 0.3731629714
Iteration 4328 => Loss: 0.3731609246
Iteration 4329 => Loss: 0.3731588785
Iteration 4330 => Loss: 0.3731568333
Iteration 4331 => Loss: 0.3731547888
Iteration 4332 => Loss: 0.3731527450
Iteration 4333 => Loss: 0.3731507021
Iteration 4334 => Loss: 0.3731486599
Iteration 4335 => Loss: 0.3731466185
Iteration 4336 => Loss: 0.3731445779
Iteration 4337 => Loss: 0.3731425380
Iteration 4338 => Loss: 0.3731404990
Iteration 4339 => Loss: 0.3731384607
Iteration 4340 => Loss: 0.3731364231
Iteration 4341 => Loss: 0.3731343863
Iteration 4342 => Loss: 0.3731323503
Iteration 4343 => Loss: 0.3731303151
Iteration 4344 => Loss: 0.3731282807
Iteration 4345 => Loss: 0.3731262470
Iteration 4346 => Loss: 0.3731242140
Iteration 4347 => Loss: 0.3731221819
Iteration 4348 => Loss: 0.3731201505
Iteration 4349 => Loss: 0.3731181198
Iteration 4350 => Loss: 0.3731160900
Iteration 4351 => Loss: 0.3731140609
Iteration 4352 => Loss: 0.3731120325
Iteration 4353 => Loss: 0.3731100049
Iteration 4354 => Loss: 0.3731079781
Iteration 4355 => Loss: 0.3731059520
Iteration 4356 => Loss: 0.3731039267
Iteration 4357 => Loss: 0.3731019022
Iteration 4358 => Loss: 0.3730998784
Iteration 4359 => Loss: 0.3730978554
Iteration 4360 => Loss: 0.3730958331
Iteration 4361 => Loss: 0.3730938116
Iteration 4362 => Loss: 0.3730917908
Iteration 4363 => Loss: 0.3730897708
Iteration 4364 => Loss: 0.3730877516
Iteration 4365 => Loss: 0.3730857331
Iteration 4366 => Loss: 0.3730837154
Iteration 4367 => Loss: 0.3730816984
Iteration 4368 => Loss: 0.3730796821
Iteration 4369 => Loss: 0.3730776666
Iteration 4370 => Loss: 0.3730756519
Iteration 4371 => Loss: 0.3730736379
Iteration 4372 => Loss: 0.3730716247
Iteration 4373 => Loss: 0.3730696122
Iteration 4374 => Loss: 0.3730676004
Iteration 4375 => Loss: 0.3730655894
Iteration 4376 => Loss: 0.3730635792
Iteration 4377 => Loss: 0.3730615697
Iteration 4378 => Loss: 0.3730595609
Iteration 4379 => Loss: 0.3730575529
Iteration 4380 => Loss: 0.3730555456
Iteration 4381 => Loss: 0.3730535391
Iteration 4382 => Loss: 0.3730515333
Iteration 4383 => Loss: 0.3730495283
Iteration 4384 => Loss: 0.3730475239
Iteration 4385 => Loss: 0.3730455204
Iteration 4386 => Loss: 0.3730435175
Iteration 4387 => Loss: 0.3730415155
Iteration 4388 => Loss: 0.3730395141
Iteration 4389 => Loss: 0.3730375135
Iteration 4390 => Loss: 0.3730355136
Iteration 4391 => Loss: 0.3730335145
Iteration 4392 => Loss: 0.3730315161
Iteration 4393 => Loss: 0.3730295184
Iteration 4394 => Loss: 0.3730275215
Iteration 4395 => Loss: 0.3730255253
Iteration 4396 => Loss: 0.3730235298
Iteration 4397 => Loss: 0.3730215350
Iteration 4398 => Loss: 0.3730195410
Iteration 4399 => Loss: 0.3730175478
Iteration 4400 => Loss: 0.3730155552
Iteration 4401 => Loss: 0.3730135634
Iteration 4402 => Loss: 0.3730115723
Iteration 4403 => Loss: 0.3730095819
Iteration 4404 => Loss: 0.3730075923
Iteration 4405 => Loss: 0.3730056034
Iteration 4406 => Loss: 0.3730036152
Iteration 4407 => Loss: 0.3730016278
Iteration 4408 => Loss: 0.3729996410
Iteration 4409 => Loss: 0.3729976550
Iteration 4410 => Loss: 0.3729956698
Iteration 4411 => Loss: 0.3729936852
Iteration 4412 => Loss: 0.3729917014
Iteration 4413 => Loss: 0.3729897182
Iteration 4414 => Loss: 0.3729877358
Iteration 4415 => Loss: 0.3729857542
Iteration 4416 => Loss: 0.3729837732
Iteration 4417 => Loss: 0.3729817930
Iteration 4418 => Loss: 0.3729798135
Iteration 4419 => Loss: 0.3729778347
Iteration 4420 => Loss: 0.3729758566
Iteration 4421 => Loss: 0.3729738792
Iteration 4422 => Loss: 0.3729719026
Iteration 4423 => Loss: 0.3729699266
Iteration 4424 => Loss: 0.3729679514
Iteration 4425 => Loss: 0.3729659769
Iteration 4426 => Loss: 0.3729640031
Iteration 4427 => Loss: 0.3729620300
Iteration 4428 => Loss: 0.3729600577
Iteration 4429 => Loss: 0.3729580860
Iteration 4430 => Loss: 0.3729561151
Iteration 4431 => Loss: 0.3729541448
Iteration 4432 => Loss: 0.3729521753
Iteration 4433 => Loss: 0.3729502065
Iteration 4434 => Loss: 0.3729482384
Iteration 4435 => Loss: 0.3729462710
Iteration 4436 => Loss: 0.3729443043
Iteration 4437 => Loss: 0.3729423383
Iteration 4438 => Loss: 0.3729403730
Iteration 4439 => Loss: 0.3729384084
Iteration 4440 => Loss: 0.3729364445
Iteration 4441 => Loss: 0.3729344814
Iteration 4442 => Loss: 0.3729325189
Iteration 4443 => Loss: 0.3729305571
Iteration 4444 => Loss: 0.3729285961
Iteration 4445 => Loss: 0.3729266357
Iteration 4446 => Loss: 0.3729246761
Iteration 4447 => Loss: 0.3729227171
Iteration 4448 => Loss: 0.3729207588
Iteration 4449 => Loss: 0.3729188013
Iteration 4450 => Loss: 0.3729168444
Iteration 4451 => Loss: 0.3729148882
Iteration 4452 => Loss: 0.3729129328
Iteration 4453 => Loss: 0.3729109780
Iteration 4454 => Loss: 0.3729090239
Iteration 4455 => Loss: 0.3729070705
Iteration 4456 => Loss: 0.3729051178
Iteration 4457 => Loss: 0.3729031658
Iteration 4458 => Loss: 0.3729012145
Iteration 4459 => Loss: 0.3728992639
Iteration 4460 => Loss: 0.3728973140
Iteration 4461 => Loss: 0.3728953648
Iteration 4462 => Loss: 0.3728934162
Iteration 4463 => Loss: 0.3728914684
Iteration 4464 => Loss: 0.3728895212
Iteration 4465 => Loss: 0.3728875748
Iteration 4466 => Loss: 0.3728856290
Iteration 4467 => Loss: 0.3728836839
Iteration 4468 => Loss: 0.3728817395
Iteration 4469 => Loss: 0.3728797958
Iteration 4470 => Loss: 0.3728778527
Iteration 4471 => Loss: 0.3728759104
Iteration 4472 => Loss: 0.3728739687
Iteration 4473 => Loss: 0.3728720277
Iteration 4474 => Loss: 0.3728700874
Iteration 4475 => Loss: 0.3728681478
Iteration 4476 => Loss: 0.3728662089
Iteration 4477 => Loss: 0.3728642706
Iteration 4478 => Loss: 0.3728623330
Iteration 4479 => Loss: 0.3728603962
Iteration 4480 => Loss: 0.3728584599
Iteration 4481 => Loss: 0.3728565244
Iteration 4482 => Loss: 0.3728545896
Iteration 4483 => Loss: 0.3728526554
Iteration 4484 => Loss: 0.3728507219
Iteration 4485 => Loss: 0.3728487891
Iteration 4486 => Loss: 0.3728468569
Iteration 4487 => Loss: 0.3728449254
Iteration 4488 => Loss: 0.3728429946
Iteration 4489 => Loss: 0.3728410645
Iteration 4490 => Loss: 0.3728391351
Iteration 4491 => Loss: 0.3728372063
Iteration 4492 => Loss: 0.3728352782
Iteration 4493 => Loss: 0.3728333508
Iteration 4494 => Loss: 0.3728314240
Iteration 4495 => Loss: 0.3728294979
Iteration 4496 => Loss: 0.3728275725
Iteration 4497 => Loss: 0.3728256477
Iteration 4498 => Loss: 0.3728237237
Iteration 4499 => Loss: 0.3728218002
Iteration 4500 => Loss: 0.3728198775
Iteration 4501 => Loss: 0.3728179554
Iteration 4502 => Loss: 0.3728160340
Iteration 4503 => Loss: 0.3728141133
Iteration 4504 => Loss: 0.3728121932
Iteration 4505 => Loss: 0.3728102738
Iteration 4506 => Loss: 0.3728083550
Iteration 4507 => Loss: 0.3728064369
Iteration 4508 => Loss: 0.3728045195
Iteration 4509 => Loss: 0.3728026027
Iteration 4510 => Loss: 0.3728006866
Iteration 4511 => Loss: 0.3727987712
Iteration 4512 => Loss: 0.3727968564
Iteration 4513 => Loss: 0.3727949423
Iteration 4514 => Loss: 0.3727930288
Iteration 4515 => Loss: 0.3727911160
Iteration 4516 => Loss: 0.3727892039
Iteration 4517 => Loss: 0.3727872924
Iteration 4518 => Loss: 0.3727853816
Iteration 4519 => Loss: 0.3727834714
Iteration 4520 => Loss: 0.3727815619
Iteration 4521 => Loss: 0.3727796530
Iteration 4522 => Loss: 0.3727777448
Iteration 4523 => Loss: 0.3727758372
Iteration 4524 => Loss: 0.3727739303
Iteration 4525 => Loss: 0.3727720241
Iteration 4526 => Loss: 0.3727701185
Iteration 4527 => Loss: 0.3727682135
Iteration 4528 => Loss: 0.3727663092
Iteration 4529 => Loss: 0.3727644056
Iteration 4530 => Loss: 0.3727625026
Iteration 4531 => Loss: 0.3727606003
Iteration 4532 => Loss: 0.3727586986
Iteration 4533 => Loss: 0.3727567975
Iteration 4534 => Loss: 0.3727548971
Iteration 4535 => Loss: 0.3727529974
Iteration 4536 => Loss: 0.3727510983
Iteration 4537 => Loss: 0.3727491998
Iteration 4538 => Loss: 0.3727473020
Iteration 4539 => Loss: 0.3727454048
Iteration 4540 => Loss: 0.3727435083
Iteration 4541 => Loss: 0.3727416124
Iteration 4542 => Loss: 0.3727397172
Iteration 4543 => Loss: 0.3727378226
Iteration 4544 => Loss: 0.3727359287
Iteration 4545 => Loss: 0.3727340353
Iteration 4546 => Loss: 0.3727321427
Iteration 4547 => Loss: 0.3727302506
Iteration 4548 => Loss: 0.3727283592
Iteration 4549 => Loss: 0.3727264685
Iteration 4550 => Loss: 0.3727245784
Iteration 4551 => Loss: 0.3727226889
Iteration 4552 => Loss: 0.3727208001
Iteration 4553 => Loss: 0.3727189119
Iteration 4554 => Loss: 0.3727170243
Iteration 4555 => Loss: 0.3727151374
Iteration 4556 => Loss: 0.3727132511
Iteration 4557 => Loss: 0.3727113654
Iteration 4558 => Loss: 0.3727094804
Iteration 4559 => Loss: 0.3727075960
Iteration 4560 => Loss: 0.3727057123
Iteration 4561 => Loss: 0.3727038291
Iteration 4562 => Loss: 0.3727019466
Iteration 4563 => Loss: 0.3727000648
Iteration 4564 => Loss: 0.3726981835
Iteration 4565 => Loss: 0.3726963029
Iteration 4566 => Loss: 0.3726944230
Iteration 4567 => Loss: 0.3726925436
Iteration 4568 => Loss: 0.3726906649
Iteration 4569 => Loss: 0.3726887868
Iteration 4570 => Loss: 0.3726869094
Iteration 4571 => Loss: 0.3726850325
Iteration 4572 => Loss: 0.3726831563
Iteration 4573 => Loss: 0.3726812807
Iteration 4574 => Loss: 0.3726794058
Iteration 4575 => Loss: 0.3726775315
Iteration 4576 => Loss: 0.3726756578
Iteration 4577 => Loss: 0.3726737847
Iteration 4578 => Loss: 0.3726719122
Iteration 4579 => Loss: 0.3726700404
Iteration 4580 => Loss: 0.3726681692
Iteration 4581 => Loss: 0.3726662986
Iteration 4582 => Loss: 0.3726644286
Iteration 4583 => Loss: 0.3726625592
Iteration 4584 => Loss: 0.3726606905
Iteration 4585 => Loss: 0.3726588224
Iteration 4586 => Loss: 0.3726569549
Iteration 4587 => Loss: 0.3726550880
Iteration 4588 => Loss: 0.3726532218
Iteration 4589 => Loss: 0.3726513561
Iteration 4590 => Loss: 0.3726494911
Iteration 4591 => Loss: 0.3726476267
Iteration 4592 => Loss: 0.3726457629
Iteration 4593 => Loss: 0.3726438997
Iteration 4594 => Loss: 0.3726420371
Iteration 4595 => Loss: 0.3726401752
Iteration 4596 => Loss: 0.3726383138
Iteration 4597 => Loss: 0.3726364531
Iteration 4598 => Loss: 0.3726345930
Iteration 4599 => Loss: 0.3726327335
Iteration 4600 => Loss: 0.3726308746
Iteration 4601 => Loss: 0.3726290163
Iteration 4602 => Loss: 0.3726271586
Iteration 4603 => Loss: 0.3726253016
Iteration 4604 => Loss: 0.3726234451
Iteration 4605 => Loss: 0.3726215893
Iteration 4606 => Loss: 0.3726197340
Iteration 4607 => Loss: 0.3726178794
Iteration 4608 => Loss: 0.3726160254
Iteration 4609 => Loss: 0.3726141720
Iteration 4610 => Loss: 0.3726123191
Iteration 4611 => Loss: 0.3726104669
Iteration 4612 => Loss: 0.3726086153
Iteration 4613 => Loss: 0.3726067643
Iteration 4614 => Loss: 0.3726049139
Iteration 4615 => Loss: 0.3726030641
Iteration 4616 => Loss: 0.3726012149
Iteration 4617 => Loss: 0.3725993664
Iteration 4618 => Loss: 0.3725975184
Iteration 4619 => Loss: 0.3725956710
Iteration 4620 => Loss: 0.3725938242
Iteration 4621 => Loss: 0.3725919780
Iteration 4622 => Loss: 0.3725901324
Iteration 4623 => Loss: 0.3725882874
Iteration 4624 => Loss: 0.3725864430
Iteration 4625 => Loss: 0.3725845992
Iteration 4626 => Loss: 0.3725827561
Iteration 4627 => Loss: 0.3725809135
Iteration 4628 => Loss: 0.3725790714
Iteration 4629 => Loss: 0.3725772300
Iteration 4630 => Loss: 0.3725753892
Iteration 4631 => Loss: 0.3725735490
Iteration 4632 => Loss: 0.3725717094
Iteration 4633 => Loss: 0.3725698704
Iteration 4634 => Loss: 0.3725680319
Iteration 4635 => Loss: 0.3725661941
Iteration 4636 => Loss: 0.3725643568
Iteration 4637 => Loss: 0.3725625202
Iteration 4638 => Loss: 0.3725606841
Iteration 4639 => Loss: 0.3725588486
Iteration 4640 => Loss: 0.3725570137
Iteration 4641 => Loss: 0.3725551794
Iteration 4642 => Loss: 0.3725533457
Iteration 4643 => Loss: 0.3725515126
Iteration 4644 => Loss: 0.3725496800
Iteration 4645 => Loss: 0.3725478481
Iteration 4646 => Loss: 0.3725460167
Iteration 4647 => Loss: 0.3725441859
Iteration 4648 => Loss: 0.3725423558
Iteration 4649 => Loss: 0.3725405261
Iteration 4650 => Loss: 0.3725386971
Iteration 4651 => Loss: 0.3725368687
Iteration 4652 => Loss: 0.3725350408
Iteration 4653 => Loss: 0.3725332136
Iteration 4654 => Loss: 0.3725313869
Iteration 4655 => Loss: 0.3725295608
Iteration 4656 => Loss: 0.3725277352
Iteration 4657 => Loss: 0.3725259103
Iteration 4658 => Loss: 0.3725240859
Iteration 4659 => Loss: 0.3725222622
Iteration 4660 => Loss: 0.3725204390
Iteration 4661 => Loss: 0.3725186163
Iteration 4662 => Loss: 0.3725167943
Iteration 4663 => Loss: 0.3725149728
Iteration 4664 => Loss: 0.3725131519
Iteration 4665 => Loss: 0.3725113316
Iteration 4666 => Loss: 0.3725095119
Iteration 4667 => Loss: 0.3725076927
Iteration 4668 => Loss: 0.3725058741
Iteration 4669 => Loss: 0.3725040561
Iteration 4670 => Loss: 0.3725022387
Iteration 4671 => Loss: 0.3725004218
Iteration 4672 => Loss: 0.3724986055
Iteration 4673 => Loss: 0.3724967898
Iteration 4674 => Loss: 0.3724949747
Iteration 4675 => Loss: 0.3724931601
Iteration 4676 => Loss: 0.3724913461
Iteration 4677 => Loss: 0.3724895327
Iteration 4678 => Loss: 0.3724877198
Iteration 4679 => Loss: 0.3724859075
Iteration 4680 => Loss: 0.3724840958
Iteration 4681 => Loss: 0.3724822847
Iteration 4682 => Loss: 0.3724804741
Iteration 4683 => Loss: 0.3724786641
Iteration 4684 => Loss: 0.3724768546
Iteration 4685 => Loss: 0.3724750458
Iteration 4686 => Loss: 0.3724732375
Iteration 4687 => Loss: 0.3724714297
Iteration 4688 => Loss: 0.3724696225
Iteration 4689 => Loss: 0.3724678159
Iteration 4690 => Loss: 0.3724660099
Iteration 4691 => Loss: 0.3724642044
Iteration 4692 => Loss: 0.3724623995
Iteration 4693 => Loss: 0.3724605951
Iteration 4694 => Loss: 0.3724587913
Iteration 4695 => Loss: 0.3724569881
Iteration 4696 => Loss: 0.3724551854
Iteration 4697 => Loss: 0.3724533833
Iteration 4698 => Loss: 0.3724515817
Iteration 4699 => Loss: 0.3724497807
Iteration 4700 => Loss: 0.3724479803
Iteration 4701 => Loss: 0.3724461804
Iteration 4702 => Loss: 0.3724443811
Iteration 4703 => Loss: 0.3724425824
Iteration 4704 => Loss: 0.3724407842
Iteration 4705 => Loss: 0.3724389865
Iteration 4706 => Loss: 0.3724371894
Iteration 4707 => Loss: 0.3724353929
Iteration 4708 => Loss: 0.3724335969
Iteration 4709 => Loss: 0.3724318015
Iteration 4710 => Loss: 0.3724300067
Iteration 4711 => Loss: 0.3724282123
Iteration 4712 => Loss: 0.3724264186
Iteration 4713 => Loss: 0.3724246254
Iteration 4714 => Loss: 0.3724228327
Iteration 4715 => Loss: 0.3724210406
Iteration 4716 => Loss: 0.3724192491
Iteration 4717 => Loss: 0.3724174581
Iteration 4718 => Loss: 0.3724156677
Iteration 4719 => Loss: 0.3724138778
Iteration 4720 => Loss: 0.3724120884
Iteration 4721 => Loss: 0.3724102996
Iteration 4722 => Loss: 0.3724085114
Iteration 4723 => Loss: 0.3724067237
Iteration 4724 => Loss: 0.3724049366
Iteration 4725 => Loss: 0.3724031500
Iteration 4726 => Loss: 0.3724013639
Iteration 4727 => Loss: 0.3723995784
Iteration 4728 => Loss: 0.3723977934
Iteration 4729 => Loss: 0.3723960090
Iteration 4730 => Loss: 0.3723942252
Iteration 4731 => Loss: 0.3723924418
Iteration 4732 => Loss: 0.3723906591
Iteration 4733 => Loss: 0.3723888768
Iteration 4734 => Loss: 0.3723870951
Iteration 4735 => Loss: 0.3723853140
Iteration 4736 => Loss: 0.3723835334
Iteration 4737 => Loss: 0.3723817533
Iteration 4738 => Loss: 0.3723799738
Iteration 4739 => Loss: 0.3723781948
Iteration 4740 => Loss: 0.3723764163
Iteration 4741 => Loss: 0.3723746384
Iteration 4742 => Loss: 0.3723728611
Iteration 4743 => Loss: 0.3723710843
Iteration 4744 => Loss: 0.3723693080
Iteration 4745 => Loss: 0.3723675322
Iteration 4746 => Loss: 0.3723657570
Iteration 4747 => Loss: 0.3723639823
Iteration 4748 => Loss: 0.3723622082
Iteration 4749 => Loss: 0.3723604346
Iteration 4750 => Loss: 0.3723586615
Iteration 4751 => Loss: 0.3723568890
Iteration 4752 => Loss: 0.3723551170
Iteration 4753 => Loss: 0.3723533456
Iteration 4754 => Loss: 0.3723515746
Iteration 4755 => Loss: 0.3723498042
Iteration 4756 => Loss: 0.3723480344
Iteration 4757 => Loss: 0.3723462650
Iteration 4758 => Loss: 0.3723444963
Iteration 4759 => Loss: 0.3723427280
Iteration 4760 => Loss: 0.3723409603
Iteration 4761 => Loss: 0.3723391931
Iteration 4762 => Loss: 0.3723374264
Iteration 4763 => Loss: 0.3723356602
Iteration 4764 => Loss: 0.3723338946
Iteration 4765 => Loss: 0.3723321295
Iteration 4766 => Loss: 0.3723303650
Iteration 4767 => Loss: 0.3723286010
Iteration 4768 => Loss: 0.3723268375
Iteration 4769 => Loss: 0.3723250745
Iteration 4770 => Loss: 0.3723233120
Iteration 4771 => Loss: 0.3723215501
Iteration 4772 => Loss: 0.3723197887
Iteration 4773 => Loss: 0.3723180279
Iteration 4774 => Loss: 0.3723162675
Iteration 4775 => Loss: 0.3723145077
Iteration 4776 => Loss: 0.3723127484
Iteration 4777 => Loss: 0.3723109896
Iteration 4778 => Loss: 0.3723092314
Iteration 4779 => Loss: 0.3723074736
Iteration 4780 => Loss: 0.3723057164
Iteration 4781 => Loss: 0.3723039597
Iteration 4782 => Loss: 0.3723022036
Iteration 4783 => Loss: 0.3723004479
Iteration 4784 => Loss: 0.3722986928
Iteration 4785 => Loss: 0.3722969382
Iteration 4786 => Loss: 0.3722951841
Iteration 4787 => Loss: 0.3722934306
Iteration 4788 => Loss: 0.3722916775
Iteration 4789 => Loss: 0.3722899250
Iteration 4790 => Loss: 0.3722881730
Iteration 4791 => Loss: 0.3722864215
Iteration 4792 => Loss: 0.3722846705
Iteration 4793 => Loss: 0.3722829200
Iteration 4794 => Loss: 0.3722811701
Iteration 4795 => Loss: 0.3722794207
Iteration 4796 => Loss: 0.3722776717
Iteration 4797 => Loss: 0.3722759233
Iteration 4798 => Loss: 0.3722741755
Iteration 4799 => Loss: 0.3722724281
Iteration 4800 => Loss: 0.3722706812
Iteration 4801 => Loss: 0.3722689349
Iteration 4802 => Loss: 0.3722671890
Iteration 4803 => Loss: 0.3722654437
Iteration 4804 => Loss: 0.3722636989
Iteration 4805 => Loss: 0.3722619546
Iteration 4806 => Loss: 0.3722602108
Iteration 4807 => Loss: 0.3722584675
Iteration 4808 => Loss: 0.3722567247
Iteration 4809 => Loss: 0.3722549825
Iteration 4810 => Loss: 0.3722532407
Iteration 4811 => Loss: 0.3722514995
Iteration 4812 => Loss: 0.3722497587
Iteration 4813 => Loss: 0.3722480185
Iteration 4814 => Loss: 0.3722462788
Iteration 4815 => Loss: 0.3722445396
Iteration 4816 => Loss: 0.3722428008
Iteration 4817 => Loss: 0.3722410626
Iteration 4818 => Loss: 0.3722393249
Iteration 4819 => Loss: 0.3722375877
Iteration 4820 => Loss: 0.3722358510
Iteration 4821 => Loss: 0.3722341149
Iteration 4822 => Loss: 0.3722323792
Iteration 4823 => Loss: 0.3722306440
Iteration 4824 => Loss: 0.3722289093
Iteration 4825 => Loss: 0.3722271751
Iteration 4826 => Loss: 0.3722254414
Iteration 4827 => Loss: 0.3722237083
Iteration 4828 => Loss: 0.3722219756
Iteration 4829 => Loss: 0.3722202434
Iteration 4830 => Loss: 0.3722185117
Iteration 4831 => Loss: 0.3722167806
Iteration 4832 => Loss: 0.3722150499
Iteration 4833 => Loss: 0.3722133197
Iteration 4834 => Loss: 0.3722115900
Iteration 4835 => Loss: 0.3722098608
Iteration 4836 => Loss: 0.3722081322
Iteration 4837 => Loss: 0.3722064040
Iteration 4838 => Loss: 0.3722046763
Iteration 4839 => Loss: 0.3722029491
Iteration 4840 => Loss: 0.3722012224
Iteration 4841 => Loss: 0.3721994962
Iteration 4842 => Loss: 0.3721977705
Iteration 4843 => Loss: 0.3721960452
Iteration 4844 => Loss: 0.3721943205
Iteration 4845 => Loss: 0.3721925963
Iteration 4846 => Loss: 0.3721908726
Iteration 4847 => Loss: 0.3721891493
Iteration 4848 => Loss: 0.3721874266
Iteration 4849 => Loss: 0.3721857043
Iteration 4850 => Loss: 0.3721839825
Iteration 4851 => Loss: 0.3721822613
Iteration 4852 => Loss: 0.3721805405
Iteration 4853 => Loss: 0.3721788202
Iteration 4854 => Loss: 0.3721771004
Iteration 4855 => Loss: 0.3721753811
Iteration 4856 => Loss: 0.3721736622
Iteration 4857 => Loss: 0.3721719439
Iteration 4858 => Loss: 0.3721702260
Iteration 4859 => Loss: 0.3721685087
Iteration 4860 => Loss: 0.3721667918
Iteration 4861 => Loss: 0.3721650754
Iteration 4862 => Loss: 0.3721633595
Iteration 4863 => Loss: 0.3721616441
Iteration 4864 => Loss: 0.3721599291
Iteration 4865 => Loss: 0.3721582147
Iteration 4866 => Loss: 0.3721565007
Iteration 4867 => Loss: 0.3721547872
Iteration 4868 => Loss: 0.3721530742
Iteration 4869 => Loss: 0.3721513617
Iteration 4870 => Loss: 0.3721496497
Iteration 4871 => Loss: 0.3721479382
Iteration 4872 => Loss: 0.3721462271
Iteration 4873 => Loss: 0.3721445165
Iteration 4874 => Loss: 0.3721428064
Iteration 4875 => Loss: 0.3721410968
Iteration 4876 => Loss: 0.3721393876
Iteration 4877 => Loss: 0.3721376790
Iteration 4878 => Loss: 0.3721359708
Iteration 4879 => Loss: 0.3721342631
Iteration 4880 => Loss: 0.3721325559
Iteration 4881 => Loss: 0.3721308491
Iteration 4882 => Loss: 0.3721291429
Iteration 4883 => Loss: 0.3721274371
Iteration 4884 => Loss: 0.3721257318
Iteration 4885 => Loss: 0.3721240269
Iteration 4886 => Loss: 0.3721223226
Iteration 4887 => Loss: 0.3721206187
Iteration 4888 => Loss: 0.3721189153
Iteration 4889 => Loss: 0.3721172123
Iteration 4890 => Loss: 0.3721155099
Iteration 4891 => Loss: 0.3721138079
Iteration 4892 => Loss: 0.3721121064
Iteration 4893 => Loss: 0.3721104054
Iteration 4894 => Loss: 0.3721087048
Iteration 4895 => Loss: 0.3721070047
Iteration 4896 => Loss: 0.3721053051
Iteration 4897 => Loss: 0.3721036059
Iteration 4898 => Loss: 0.3721019073
Iteration 4899 => Loss: 0.3721002091
Iteration 4900 => Loss: 0.3720985113
Iteration 4901 => Loss: 0.3720968141
Iteration 4902 => Loss: 0.3720951173
Iteration 4903 => Loss: 0.3720934210
Iteration 4904 => Loss: 0.3720917251
Iteration 4905 => Loss: 0.3720900297
Iteration 4906 => Loss: 0.3720883348
Iteration 4907 => Loss: 0.3720866403
Iteration 4908 => Loss: 0.3720849464
Iteration 4909 => Loss: 0.3720832529
Iteration 4910 => Loss: 0.3720815598
Iteration 4911 => Loss: 0.3720798672
Iteration 4912 => Loss: 0.3720781751
Iteration 4913 => Loss: 0.3720764835
Iteration 4914 => Loss: 0.3720747923
Iteration 4915 => Loss: 0.3720731015
Iteration 4916 => Loss: 0.3720714113
Iteration 4917 => Loss: 0.3720697215
Iteration 4918 => Loss: 0.3720680322
Iteration 4919 => Loss: 0.3720663433
Iteration 4920 => Loss: 0.3720646549
Iteration 4921 => Loss: 0.3720629670
Iteration 4922 => Loss: 0.3720612795
Iteration 4923 => Loss: 0.3720595925
Iteration 4924 => Loss: 0.3720579059
Iteration 4925 => Loss: 0.3720562198
Iteration 4926 => Loss: 0.3720545342
Iteration 4927 => Loss: 0.3720528490
Iteration 4928 => Loss: 0.3720511643
Iteration 4929 => Loss: 0.3720494800
Iteration 4930 => Loss: 0.3720477962
Iteration 4931 => Loss: 0.3720461129
Iteration 4932 => Loss: 0.3720444300
Iteration 4933 => Loss: 0.3720427476
Iteration 4934 => Loss: 0.3720410656
Iteration 4935 => Loss: 0.3720393841
Iteration 4936 => Loss: 0.3720377030
Iteration 4937 => Loss: 0.3720360224
Iteration 4938 => Loss: 0.3720343423
Iteration 4939 => Loss: 0.3720326626
Iteration 4940 => Loss: 0.3720309834
Iteration 4941 => Loss: 0.3720293046
Iteration 4942 => Loss: 0.3720276263
Iteration 4943 => Loss: 0.3720259484
Iteration 4944 => Loss: 0.3720242710
Iteration 4945 => Loss: 0.3720225940
Iteration 4946 => Loss: 0.3720209175
Iteration 4947 => Loss: 0.3720192414
Iteration 4948 => Loss: 0.3720175658
Iteration 4949 => Loss: 0.3720158907
Iteration 4950 => Loss: 0.3720142160
Iteration 4951 => Loss: 0.3720125417
Iteration 4952 => Loss: 0.3720108679
Iteration 4953 => Loss: 0.3720091946
Iteration 4954 => Loss: 0.3720075216
Iteration 4955 => Loss: 0.3720058492
Iteration 4956 => Loss: 0.3720041772
Iteration 4957 => Loss: 0.3720025056
Iteration 4958 => Loss: 0.3720008345
Iteration 4959 => Loss: 0.3719991638
Iteration 4960 => Loss: 0.3719974936
Iteration 4961 => Loss: 0.3719958239
Iteration 4962 => Loss: 0.3719941545
Iteration 4963 => Loss: 0.3719924857
Iteration 4964 => Loss: 0.3719908172
Iteration 4965 => Loss: 0.3719891492
Iteration 4966 => Loss: 0.3719874817
Iteration 4967 => Loss: 0.3719858146
Iteration 4968 => Loss: 0.3719841479
Iteration 4969 => Loss: 0.3719824817
Iteration 4970 => Loss: 0.3719808160
Iteration 4971 => Loss: 0.3719791506
Iteration 4972 => Loss: 0.3719774858
Iteration 4973 => Loss: 0.3719758213
Iteration 4974 => Loss: 0.3719741573
Iteration 4975 => Loss: 0.3719724938
Iteration 4976 => Loss: 0.3719708306
Iteration 4977 => Loss: 0.3719691680
Iteration 4978 => Loss: 0.3719675057
Iteration 4979 => Loss: 0.3719658439
Iteration 4980 => Loss: 0.3719641826
Iteration 4981 => Loss: 0.3719625217
Iteration 4982 => Loss: 0.3719608612
Iteration 4983 => Loss: 0.3719592012
Iteration 4984 => Loss: 0.3719575416
Iteration 4985 => Loss: 0.3719558824
Iteration 4986 => Loss: 0.3719542237
Iteration 4987 => Loss: 0.3719525654
Iteration 4988 => Loss: 0.3719509075
Iteration 4989 => Loss: 0.3719492501
Iteration 4990 => Loss: 0.3719475931
Iteration 4991 => Loss: 0.3719459366
Iteration 4992 => Loss: 0.3719442805
Iteration 4993 => Loss: 0.3719426248
Iteration 4994 => Loss: 0.3719409696
Iteration 4995 => Loss: 0.3719393148
Iteration 4996 => Loss: 0.3719376604
Iteration 4997 => Loss: 0.3719360064
Iteration 4998 => Loss: 0.3719343529
Iteration 4999 => Loss: 0.3719326999
Iteration 5000 => Loss: 0.3719310472
Iteration 5001 => Loss: 0.3719293950
Iteration 5002 => Loss: 0.3719277432
Iteration 5003 => Loss: 0.3719260919
Iteration 5004 => Loss: 0.3719244410
Iteration 5005 => Loss: 0.3719227905
Iteration 5006 => Loss: 0.3719211404
Iteration 5007 => Loss: 0.3719194908
Iteration 5008 => Loss: 0.3719178416
Iteration 5009 => Loss: 0.3719161928
Iteration 5010 => Loss: 0.3719145445
Iteration 5011 => Loss: 0.3719128966
Iteration 5012 => Loss: 0.3719112491
Iteration 5013 => Loss: 0.3719096020
Iteration 5014 => Loss: 0.3719079554
Iteration 5015 => Loss: 0.3719063092
Iteration 5016 => Loss: 0.3719046634
Iteration 5017 => Loss: 0.3719030181
Iteration 5018 => Loss: 0.3719013731
Iteration 5019 => Loss: 0.3718997286
Iteration 5020 => Loss: 0.3718980846
Iteration 5021 => Loss: 0.3718964409
Iteration 5022 => Loss: 0.3718947977
Iteration 5023 => Loss: 0.3718931549
Iteration 5024 => Loss: 0.3718915125
Iteration 5025 => Loss: 0.3718898706
Iteration 5026 => Loss: 0.3718882290
Iteration 5027 => Loss: 0.3718865879
Iteration 5028 => Loss: 0.3718849472
Iteration 5029 => Loss: 0.3718833070
Iteration 5030 => Loss: 0.3718816671
Iteration 5031 => Loss: 0.3718800277
Iteration 5032 => Loss: 0.3718783887
Iteration 5033 => Loss: 0.3718767501
Iteration 5034 => Loss: 0.3718751119
Iteration 5035 => Loss: 0.3718734742
Iteration 5036 => Loss: 0.3718718369
Iteration 5037 => Loss: 0.3718701999
Iteration 5038 => Loss: 0.3718685635
Iteration 5039 => Loss: 0.3718669274
Iteration 5040 => Loss: 0.3718652917
Iteration 5041 => Loss: 0.3718636565
Iteration 5042 => Loss: 0.3718620217
Iteration 5043 => Loss: 0.3718603873
Iteration 5044 => Loss: 0.3718587533
Iteration 5045 => Loss: 0.3718571197
Iteration 5046 => Loss: 0.3718554866
Iteration 5047 => Loss: 0.3718538538
Iteration 5048 => Loss: 0.3718522215
Iteration 5049 => Loss: 0.3718505896
Iteration 5050 => Loss: 0.3718489581
Iteration 5051 => Loss: 0.3718473270
Iteration 5052 => Loss: 0.3718456963
Iteration 5053 => Loss: 0.3718440661
Iteration 5054 => Loss: 0.3718424363
Iteration 5055 => Loss: 0.3718408068
Iteration 5056 => Loss: 0.3718391778
Iteration 5057 => Loss: 0.3718375492
Iteration 5058 => Loss: 0.3718359210
Iteration 5059 => Loss: 0.3718342932
Iteration 5060 => Loss: 0.3718326659
Iteration 5061 => Loss: 0.3718310389
Iteration 5062 => Loss: 0.3718294123
Iteration 5063 => Loss: 0.3718277862
Iteration 5064 => Loss: 0.3718261605
Iteration 5065 => Loss: 0.3718245351
Iteration 5066 => Loss: 0.3718229102
Iteration 5067 => Loss: 0.3718212857
Iteration 5068 => Loss: 0.3718196616
Iteration 5069 => Loss: 0.3718180379
Iteration 5070 => Loss: 0.3718164146
Iteration 5071 => Loss: 0.3718147918
Iteration 5072 => Loss: 0.3718131693
Iteration 5073 => Loss: 0.3718115472
Iteration 5074 => Loss: 0.3718099256
Iteration 5075 => Loss: 0.3718083043
Iteration 5076 => Loss: 0.3718066835
Iteration 5077 => Loss: 0.3718050630
Iteration 5078 => Loss: 0.3718034430
Iteration 5079 => Loss: 0.3718018234
Iteration 5080 => Loss: 0.3718002041
Iteration 5081 => Loss: 0.3717985853
Iteration 5082 => Loss: 0.3717969669
Iteration 5083 => Loss: 0.3717953489
Iteration 5084 => Loss: 0.3717937312
Iteration 5085 => Loss: 0.3717921140
Iteration 5086 => Loss: 0.3717904972
Iteration 5087 => Loss: 0.3717888808
Iteration 5088 => Loss: 0.3717872648
Iteration 5089 => Loss: 0.3717856492
Iteration 5090 => Loss: 0.3717840340
Iteration 5091 => Loss: 0.3717824191
Iteration 5092 => Loss: 0.3717808047
Iteration 5093 => Loss: 0.3717791907
Iteration 5094 => Loss: 0.3717775771
Iteration 5095 => Loss: 0.3717759639
Iteration 5096 => Loss: 0.3717743511
Iteration 5097 => Loss: 0.3717727387
Iteration 5098 => Loss: 0.3717711267
Iteration 5099 => Loss: 0.3717695150
Iteration 5100 => Loss: 0.3717679038
Iteration 5101 => Loss: 0.3717662930
Iteration 5102 => Loss: 0.3717646825
Iteration 5103 => Loss: 0.3717630725
Iteration 5104 => Loss: 0.3717614629
Iteration 5105 => Loss: 0.3717598536
Iteration 5106 => Loss: 0.3717582448
Iteration 5107 => Loss: 0.3717566363
Iteration 5108 => Loss: 0.3717550283
Iteration 5109 => Loss: 0.3717534206
Iteration 5110 => Loss: 0.3717518133
Iteration 5111 => Loss: 0.3717502064
Iteration 5112 => Loss: 0.3717486000
Iteration 5113 => Loss: 0.3717469939
Iteration 5114 => Loss: 0.3717453882
Iteration 5115 => Loss: 0.3717437829
Iteration 5116 => Loss: 0.3717421779
Iteration 5117 => Loss: 0.3717405734
Iteration 5118 => Loss: 0.3717389693
Iteration 5119 => Loss: 0.3717373655
Iteration 5120 => Loss: 0.3717357622
Iteration 5121 => Loss: 0.3717341592
Iteration 5122 => Loss: 0.3717325567
Iteration 5123 => Loss: 0.3717309545
Iteration 5124 => Loss: 0.3717293527
Iteration 5125 => Loss: 0.3717277513
Iteration 5126 => Loss: 0.3717261503
Iteration 5127 => Loss: 0.3717245496
Iteration 5128 => Loss: 0.3717229494
Iteration 5129 => Loss: 0.3717213495
Iteration 5130 => Loss: 0.3717197501
Iteration 5131 => Loss: 0.3717181510
Iteration 5132 => Loss: 0.3717165523
Iteration 5133 => Loss: 0.3717149540
Iteration 5134 => Loss: 0.3717133561
Iteration 5135 => Loss: 0.3717117585
Iteration 5136 => Loss: 0.3717101614
Iteration 5137 => Loss: 0.3717085646
Iteration 5138 => Loss: 0.3717069683
Iteration 5139 => Loss: 0.3717053723
Iteration 5140 => Loss: 0.3717037766
Iteration 5141 => Loss: 0.3717021814
Iteration 5142 => Loss: 0.3717005866
Iteration 5143 => Loss: 0.3716989921
Iteration 5144 => Loss: 0.3716973980
Iteration 5145 => Loss: 0.3716958043
Iteration 5146 => Loss: 0.3716942110
Iteration 5147 => Loss: 0.3716926181
Iteration 5148 => Loss: 0.3716910255
Iteration 5149 => Loss: 0.3716894334
Iteration 5150 => Loss: 0.3716878416
Iteration 5151 => Loss: 0.3716862502
Iteration 5152 => Loss: 0.3716846591
Iteration 5153 => Loss: 0.3716830685
Iteration 5154 => Loss: 0.3716814782
Iteration 5155 => Loss: 0.3716798883
Iteration 5156 => Loss: 0.3716782988
Iteration 5157 => Loss: 0.3716767097
Iteration 5158 => Loss: 0.3716751209
Iteration 5159 => Loss: 0.3716735326
Iteration 5160 => Loss: 0.3716719446
Iteration 5161 => Loss: 0.3716703569
Iteration 5162 => Loss: 0.3716687697
Iteration 5163 => Loss: 0.3716671828
Iteration 5164 => Loss: 0.3716655963
Iteration 5165 => Loss: 0.3716640102
Iteration 5166 => Loss: 0.3716624245
Iteration 5167 => Loss: 0.3716608391
Iteration 5168 => Loss: 0.3716592541
Iteration 5169 => Loss: 0.3716576695
Iteration 5170 => Loss: 0.3716560853
Iteration 5171 => Loss: 0.3716545014
Iteration 5172 => Loss: 0.3716529179
Iteration 5173 => Loss: 0.3716513348
Iteration 5174 => Loss: 0.3716497520
Iteration 5175 => Loss: 0.3716481697
Iteration 5176 => Loss: 0.3716465877
Iteration 5177 => Loss: 0.3716450060
Iteration 5178 => Loss: 0.3716434248
Iteration 5179 => Loss: 0.3716418439
Iteration 5180 => Loss: 0.3716402634
Iteration 5181 => Loss: 0.3716386832
Iteration 5182 => Loss: 0.3716371035
Iteration 5183 => Loss: 0.3716355241
Iteration 5184 => Loss: 0.3716339450
Iteration 5185 => Loss: 0.3716323664
Iteration 5186 => Loss: 0.3716307881
Iteration 5187 => Loss: 0.3716292101
Iteration 5188 => Loss: 0.3716276326
Iteration 5189 => Loss: 0.3716260554
Iteration 5190 => Loss: 0.3716244786
Iteration 5191 => Loss: 0.3716229021
Iteration 5192 => Loss: 0.3716213261
Iteration 5193 => Loss: 0.3716197503
Iteration 5194 => Loss: 0.3716181750
Iteration 5195 => Loss: 0.3716166000
Iteration 5196 => Loss: 0.3716150254
Iteration 5197 => Loss: 0.3716134512
Iteration 5198 => Loss: 0.3716118773
Iteration 5199 => Loss: 0.3716103038
Iteration 5200 => Loss: 0.3716087306
Iteration 5201 => Loss: 0.3716071578
Iteration 5202 => Loss: 0.3716055854
Iteration 5203 => Loss: 0.3716040133
Iteration 5204 => Loss: 0.3716024416
Iteration 5205 => Loss: 0.3716008703
Iteration 5206 => Loss: 0.3715992993
Iteration 5207 => Loss: 0.3715977287
Iteration 5208 => Loss: 0.3715961585
Iteration 5209 => Loss: 0.3715945886
Iteration 5210 => Loss: 0.3715930191
Iteration 5211 => Loss: 0.3715914499
Iteration 5212 => Loss: 0.3715898811
Iteration 5213 => Loss: 0.3715883127
Iteration 5214 => Loss: 0.3715867446
Iteration 5215 => Loss: 0.3715851769
Iteration 5216 => Loss: 0.3715836096
Iteration 5217 => Loss: 0.3715820426
Iteration 5218 => Loss: 0.3715804760
Iteration 5219 => Loss: 0.3715789097
Iteration 5220 => Loss: 0.3715773438
Iteration 5221 => Loss: 0.3715757782
Iteration 5222 => Loss: 0.3715742130
Iteration 5223 => Loss: 0.3715726482
Iteration 5224 => Loss: 0.3715710837
Iteration 5225 => Loss: 0.3715695196
Iteration 5226 => Loss: 0.3715679558
Iteration 5227 => Loss: 0.3715663924
Iteration 5228 => Loss: 0.3715648294
Iteration 5229 => Loss: 0.3715632667
Iteration 5230 => Loss: 0.3715617043
Iteration 5231 => Loss: 0.3715601423
Iteration 5232 => Loss: 0.3715585807
Iteration 5233 => Loss: 0.3715570194
Iteration 5234 => Loss: 0.3715554585
Iteration 5235 => Loss: 0.3715538980
Iteration 5236 => Loss: 0.3715523378
Iteration 5237 => Loss: 0.3715507779
Iteration 5238 => Loss: 0.3715492184
Iteration 5239 => Loss: 0.3715476593
Iteration 5240 => Loss: 0.3715461005
Iteration 5241 => Loss: 0.3715445420
Iteration 5242 => Loss: 0.3715429839
Iteration 5243 => Loss: 0.3715414262
Iteration 5244 => Loss: 0.3715398688
Iteration 5245 => Loss: 0.3715383118
Iteration 5246 => Loss: 0.3715367551
Iteration 5247 => Loss: 0.3715351988
Iteration 5248 => Loss: 0.3715336428
Iteration 5249 => Loss: 0.3715320872
Iteration 5250 => Loss: 0.3715305319
Iteration 5251 => Loss: 0.3715289770
Iteration 5252 => Loss: 0.3715274224
Iteration 5253 => Loss: 0.3715258682
Iteration 5254 => Loss: 0.3715243143
Iteration 5255 => Loss: 0.3715227608
Iteration 5256 => Loss: 0.3715212076
Iteration 5257 => Loss: 0.3715196547
Iteration 5258 => Loss: 0.3715181023
Iteration 5259 => Loss: 0.3715165501
Iteration 5260 => Loss: 0.3715149983
Iteration 5261 => Loss: 0.3715134469
Iteration 5262 => Loss: 0.3715118958
Iteration 5263 => Loss: 0.3715103450
Iteration 5264 => Loss: 0.3715087946
Iteration 5265 => Loss: 0.3715072446
Iteration 5266 => Loss: 0.3715056949
Iteration 5267 => Loss: 0.3715041455
Iteration 5268 => Loss: 0.3715025965
Iteration 5269 => Loss: 0.3715010478
Iteration 5270 => Loss: 0.3714994995
Iteration 5271 => Loss: 0.3714979515
Iteration 5272 => Loss: 0.3714964038
Iteration 5273 => Loss: 0.3714948565
Iteration 5274 => Loss: 0.3714933096
Iteration 5275 => Loss: 0.3714917630
Iteration 5276 => Loss: 0.3714902167
Iteration 5277 => Loss: 0.3714886708
Iteration 5278 => Loss: 0.3714871252
Iteration 5279 => Loss: 0.3714855799
Iteration 5280 => Loss: 0.3714840350
Iteration 5281 => Loss: 0.3714824905
Iteration 5282 => Loss: 0.3714809463
Iteration 5283 => Loss: 0.3714794024
Iteration 5284 => Loss: 0.3714778588
Iteration 5285 => Loss: 0.3714763156
Iteration 5286 => Loss: 0.3714747728
Iteration 5287 => Loss: 0.3714732303
Iteration 5288 => Loss: 0.3714716881
Iteration 5289 => Loss: 0.3714701462
Iteration 5290 => Loss: 0.3714686047
Iteration 5291 => Loss: 0.3714670636
Iteration 5292 => Loss: 0.3714655227
Iteration 5293 => Loss: 0.3714639823
Iteration 5294 => Loss: 0.3714624421
Iteration 5295 => Loss: 0.3714609023
Iteration 5296 => Loss: 0.3714593628
Iteration 5297 => Loss: 0.3714578237
Iteration 5298 => Loss: 0.3714562849
Iteration 5299 => Loss: 0.3714547464
Iteration 5300 => Loss: 0.3714532083
Iteration 5301 => Loss: 0.3714516705
Iteration 5302 => Loss: 0.3714501330
Iteration 5303 => Loss: 0.3714485959
Iteration 5304 => Loss: 0.3714470591
Iteration 5305 => Loss: 0.3714455227
Iteration 5306 => Loss: 0.3714439866
Iteration 5307 => Loss: 0.3714424508
Iteration 5308 => Loss: 0.3714409153
Iteration 5309 => Loss: 0.3714393802
Iteration 5310 => Loss: 0.3714378454
Iteration 5311 => Loss: 0.3714363110
Iteration 5312 => Loss: 0.3714347769
Iteration 5313 => Loss: 0.3714332431
Iteration 5314 => Loss: 0.3714317096
Iteration 5315 => Loss: 0.3714301765
Iteration 5316 => Loss: 0.3714286437
Iteration 5317 => Loss: 0.3714271112
Iteration 5318 => Loss: 0.3714255791
Iteration 5319 => Loss: 0.3714240473
Iteration 5320 => Loss: 0.3714225159
Iteration 5321 => Loss: 0.3714209847
Iteration 5322 => Loss: 0.3714194539
Iteration 5323 => Loss: 0.3714179234
Iteration 5324 => Loss: 0.3714163933
Iteration 5325 => Loss: 0.3714148635
Iteration 5326 => Loss: 0.3714133340
Iteration 5327 => Loss: 0.3714118048
Iteration 5328 => Loss: 0.3714102760
Iteration 5329 => Loss: 0.3714087475
Iteration 5330 => Loss: 0.3714072193
Iteration 5331 => Loss: 0.3714056915
Iteration 5332 => Loss: 0.3714041639
Iteration 5333 => Loss: 0.3714026367
Iteration 5334 => Loss: 0.3714011099
Iteration 5335 => Loss: 0.3713995833
Iteration 5336 => Loss: 0.3713980571
Iteration 5337 => Loss: 0.3713965312
Iteration 5338 => Loss: 0.3713950057
Iteration 5339 => Loss: 0.3713934804
Iteration 5340 => Loss: 0.3713919555
Iteration 5341 => Loss: 0.3713904309
Iteration 5342 => Loss: 0.3713889067
Iteration 5343 => Loss: 0.3713873827
Iteration 5344 => Loss: 0.3713858591
Iteration 5345 => Loss: 0.3713843358
Iteration 5346 => Loss: 0.3713828129
Iteration 5347 => Loss: 0.3713812902
Iteration 5348 => Loss: 0.3713797679
Iteration 5349 => Loss: 0.3713782459
Iteration 5350 => Loss: 0.3713767242
Iteration 5351 => Loss: 0.3713752029
Iteration 5352 => Loss: 0.3713736818
Iteration 5353 => Loss: 0.3713721611
Iteration 5354 => Loss: 0.3713706407
Iteration 5355 => Loss: 0.3713691207
Iteration 5356 => Loss: 0.3713676009
Iteration 5357 => Loss: 0.3713660815
Iteration 5358 => Loss: 0.3713645624
Iteration 5359 => Loss: 0.3713630436
Iteration 5360 => Loss: 0.3713615251
Iteration 5361 => Loss: 0.3713600070
Iteration 5362 => Loss: 0.3713584892
Iteration 5363 => Loss: 0.3713569717
Iteration 5364 => Loss: 0.3713554545
Iteration 5365 => Loss: 0.3713539376
Iteration 5366 => Loss: 0.3713524210
Iteration 5367 => Loss: 0.3713509048
Iteration 5368 => Loss: 0.3713493889
Iteration 5369 => Loss: 0.3713478733
Iteration 5370 => Loss: 0.3713463580
Iteration 5371 => Loss: 0.3713448430
Iteration 5372 => Loss: 0.3713433284
Iteration 5373 => Loss: 0.3713418141
Iteration 5374 => Loss: 0.3713403001
Iteration 5375 => Loss: 0.3713387864
Iteration 5376 => Loss: 0.3713372730
Iteration 5377 => Loss: 0.3713357599
Iteration 5378 => Loss: 0.3713342471
Iteration 5379 => Loss: 0.3713327347
Iteration 5380 => Loss: 0.3713312226
Iteration 5381 => Loss: 0.3713297108
Iteration 5382 => Loss: 0.3713281993
Iteration 5383 => Loss: 0.3713266881
Iteration 5384 => Loss: 0.3713251772
Iteration 5385 => Loss: 0.3713236667
Iteration 5386 => Loss: 0.3713221564
Iteration 5387 => Loss: 0.3713206465
Iteration 5388 => Loss: 0.3713191369
Iteration 5389 => Loss: 0.3713176276
Iteration 5390 => Loss: 0.3713161186
Iteration 5391 => Loss: 0.3713146099
Iteration 5392 => Loss: 0.3713131015
Iteration 5393 => Loss: 0.3713115935
Iteration 5394 => Loss: 0.3713100857
Iteration 5395 => Loss: 0.3713085783
Iteration 5396 => Loss: 0.3713070712
Iteration 5397 => Loss: 0.3713055643
Iteration 5398 => Loss: 0.3713040578
Iteration 5399 => Loss: 0.3713025516
Iteration 5400 => Loss: 0.3713010458
Iteration 5401 => Loss: 0.3712995402
Iteration 5402 => Loss: 0.3712980349
Iteration 5403 => Loss: 0.3712965300
Iteration 5404 => Loss: 0.3712950253
Iteration 5405 => Loss: 0.3712935210
Iteration 5406 => Loss: 0.3712920169
Iteration 5407 => Loss: 0.3712905132
Iteration 5408 => Loss: 0.3712890098
Iteration 5409 => Loss: 0.3712875067
Iteration 5410 => Loss: 0.3712860039
Iteration 5411 => Loss: 0.3712845014
Iteration 5412 => Loss: 0.3712829992
Iteration 5413 => Loss: 0.3712814973
Iteration 5414 => Loss: 0.3712799957
Iteration 5415 => Loss: 0.3712784944
Iteration 5416 => Loss: 0.3712769935
Iteration 5417 => Loss: 0.3712754928
Iteration 5418 => Loss: 0.3712739924
Iteration 5419 => Loss: 0.3712724924
Iteration 5420 => Loss: 0.3712709926
Iteration 5421 => Loss: 0.3712694932
Iteration 5422 => Loss: 0.3712679940
Iteration 5423 => Loss: 0.3712664952
Iteration 5424 => Loss: 0.3712649967
Iteration 5425 => Loss: 0.3712634984
Iteration 5426 => Loss: 0.3712620005
Iteration 5427 => Loss: 0.3712605029
Iteration 5428 => Loss: 0.3712590056
Iteration 5429 => Loss: 0.3712575085
Iteration 5430 => Loss: 0.3712560118
Iteration 5431 => Loss: 0.3712545154
Iteration 5432 => Loss: 0.3712530193
Iteration 5433 => Loss: 0.3712515235
Iteration 5434 => Loss: 0.3712500280
Iteration 5435 => Loss: 0.3712485327
Iteration 5436 => Loss: 0.3712470378
Iteration 5437 => Loss: 0.3712455432
Iteration 5438 => Loss: 0.3712440489
Iteration 5439 => Loss: 0.3712425549
Iteration 5440 => Loss: 0.3712410612
Iteration 5441 => Loss: 0.3712395678
Iteration 5442 => Loss: 0.3712380746
Iteration 5443 => Loss: 0.3712365818
Iteration 5444 => Loss: 0.3712350893
Iteration 5445 => Loss: 0.3712335971
Iteration 5446 => Loss: 0.3712321052
Iteration 5447 => Loss: 0.3712306135
Iteration 5448 => Loss: 0.3712291222
Iteration 5449 => Loss: 0.3712276312
Iteration 5450 => Loss: 0.3712261405
Iteration 5451 => Loss: 0.3712246500
Iteration 5452 => Loss: 0.3712231599
Iteration 5453 => Loss: 0.3712216700
Iteration 5454 => Loss: 0.3712201805
Iteration 5455 => Loss: 0.3712186913
Iteration 5456 => Loss: 0.3712172023
Iteration 5457 => Loss: 0.3712157136
Iteration 5458 => Loss: 0.3712142253
Iteration 5459 => Loss: 0.3712127372
Iteration 5460 => Loss: 0.3712112494
Iteration 5461 => Loss: 0.3712097620
Iteration 5462 => Loss: 0.3712082748
Iteration 5463 => Loss: 0.3712067879
Iteration 5464 => Loss: 0.3712053013
Iteration 5465 => Loss: 0.3712038150
Iteration 5466 => Loss: 0.3712023290
Iteration 5467 => Loss: 0.3712008432
Iteration 5468 => Loss: 0.3711993578
Iteration 5469 => Loss: 0.3711978727
Iteration 5470 => Loss: 0.3711963878
Iteration 5471 => Loss: 0.3711949033
Iteration 5472 => Loss: 0.3711934190
Iteration 5473 => Loss: 0.3711919351
Iteration 5474 => Loss: 0.3711904514
Iteration 5475 => Loss: 0.3711889680
Iteration 5476 => Loss: 0.3711874849
Iteration 5477 => Loss: 0.3711860021
Iteration 5478 => Loss: 0.3711845196
Iteration 5479 => Loss: 0.3711830374
Iteration 5480 => Loss: 0.3711815555
Iteration 5481 => Loss: 0.3711800738
Iteration 5482 => Loss: 0.3711785925
Iteration 5483 => Loss: 0.3711771114
Iteration 5484 => Loss: 0.3711756306
Iteration 5485 => Loss: 0.3711741501
Iteration 5486 => Loss: 0.3711726699
Iteration 5487 => Loss: 0.3711711900
Iteration 5488 => Loss: 0.3711697104
Iteration 5489 => Loss: 0.3711682311
Iteration 5490 => Loss: 0.3711667520
Iteration 5491 => Loss: 0.3711652733
Iteration 5492 => Loss: 0.3711637948
Iteration 5493 => Loss: 0.3711623166
Iteration 5494 => Loss: 0.3711608387
Iteration 5495 => Loss: 0.3711593611
Iteration 5496 => Loss: 0.3711578838
Iteration 5497 => Loss: 0.3711564068
Iteration 5498 => Loss: 0.3711549300
Iteration 5499 => Loss: 0.3711534535
Iteration 5500 => Loss: 0.3711519774
Iteration 5501 => Loss: 0.3711505015
Iteration 5502 => Loss: 0.3711490258
Iteration 5503 => Loss: 0.3711475505
Iteration 5504 => Loss: 0.3711460755
Iteration 5505 => Loss: 0.3711446007
Iteration 5506 => Loss: 0.3711431262
Iteration 5507 => Loss: 0.3711416520
Iteration 5508 => Loss: 0.3711401781
Iteration 5509 => Loss: 0.3711387045
Iteration 5510 => Loss: 0.3711372312
Iteration 5511 => Loss: 0.3711357581
Iteration 5512 => Loss: 0.3711342853
Iteration 5513 => Loss: 0.3711328128
Iteration 5514 => Loss: 0.3711313406
Iteration 5515 => Loss: 0.3711298687
Iteration 5516 => Loss: 0.3711283970
Iteration 5517 => Loss: 0.3711269257
Iteration 5518 => Loss: 0.3711254546
Iteration 5519 => Loss: 0.3711239838
Iteration 5520 => Loss: 0.3711225132
Iteration 5521 => Loss: 0.3711210430
Iteration 5522 => Loss: 0.3711195730
Iteration 5523 => Loss: 0.3711181033
Iteration 5524 => Loss: 0.3711166339
Iteration 5525 => Loss: 0.3711151648
Iteration 5526 => Loss: 0.3711136960
Iteration 5527 => Loss: 0.3711122274
Iteration 5528 => Loss: 0.3711107591
Iteration 5529 => Loss: 0.3711092911
Iteration 5530 => Loss: 0.3711078234
Iteration 5531 => Loss: 0.3711063559
Iteration 5532 => Loss: 0.3711048887
Iteration 5533 => Loss: 0.3711034218
Iteration 5534 => Loss: 0.3711019552
Iteration 5535 => Loss: 0.3711004889
Iteration 5536 => Loss: 0.3710990228
Iteration 5537 => Loss: 0.3710975570
Iteration 5538 => Loss: 0.3710960915
Iteration 5539 => Loss: 0.3710946262
Iteration 5540 => Loss: 0.3710931613
Iteration 5541 => Loss: 0.3710916966
Iteration 5542 => Loss: 0.3710902322
Iteration 5543 => Loss: 0.3710887681
Iteration 5544 => Loss: 0.3710873042
Iteration 5545 => Loss: 0.3710858406
Iteration 5546 => Loss: 0.3710843773
Iteration 5547 => Loss: 0.3710829143
Iteration 5548 => Loss: 0.3710814515
Iteration 5549 => Loss: 0.3710799890
Iteration 5550 => Loss: 0.3710785268
Iteration 5551 => Loss: 0.3710770649
Iteration 5552 => Loss: 0.3710756032
Iteration 5553 => Loss: 0.3710741418
Iteration 5554 => Loss: 0.3710726807
Iteration 5555 => Loss: 0.3710712198
Iteration 5556 => Loss: 0.3710697593
Iteration 5557 => Loss: 0.3710682990
Iteration 5558 => Loss: 0.3710668389
Iteration 5559 => Loss: 0.3710653792
Iteration 5560 => Loss: 0.3710639197
Iteration 5561 => Loss: 0.3710624605
Iteration 5562 => Loss: 0.3710610015
Iteration 5563 => Loss: 0.3710595429
Iteration 5564 => Loss: 0.3710580845
Iteration 5565 => Loss: 0.3710566263
Iteration 5566 => Loss: 0.3710551685
Iteration 5567 => Loss: 0.3710537109
Iteration 5568 => Loss: 0.3710522536
Iteration 5569 => Loss: 0.3710507965
Iteration 5570 => Loss: 0.3710493397
Iteration 5571 => Loss: 0.3710478832
Iteration 5572 => Loss: 0.3710464270
Iteration 5573 => Loss: 0.3710449710
Iteration 5574 => Loss: 0.3710435153
Iteration 5575 => Loss: 0.3710420598
Iteration 5576 => Loss: 0.3710406047
Iteration 5577 => Loss: 0.3710391498
Iteration 5578 => Loss: 0.3710376951
Iteration 5579 => Loss: 0.3710362408
Iteration 5580 => Loss: 0.3710347867
Iteration 5581 => Loss: 0.3710333328
Iteration 5582 => Loss: 0.3710318793
Iteration 5583 => Loss: 0.3710304260
Iteration 5584 => Loss: 0.3710289729
Iteration 5585 => Loss: 0.3710275202
Iteration 5586 => Loss: 0.3710260677
Iteration 5587 => Loss: 0.3710246155
Iteration 5588 => Loss: 0.3710231635
Iteration 5589 => Loss: 0.3710217118
Iteration 5590 => Loss: 0.3710202603
Iteration 5591 => Loss: 0.3710188092
Iteration 5592 => Loss: 0.3710173583
Iteration 5593 => Loss: 0.3710159076
Iteration 5594 => Loss: 0.3710144572
Iteration 5595 => Loss: 0.3710130071
Iteration 5596 => Loss: 0.3710115573
Iteration 5597 => Loss: 0.3710101077
Iteration 5598 => Loss: 0.3710086584
Iteration 5599 => Loss: 0.3710072093
Iteration 5600 => Loss: 0.3710057605
Iteration 5601 => Loss: 0.3710043120
Iteration 5602 => Loss: 0.3710028637
Iteration 5603 => Loss: 0.3710014157
Iteration 5604 => Loss: 0.3709999679
Iteration 5605 => Loss: 0.3709985205
Iteration 5606 => Loss: 0.3709970732
Iteration 5607 => Loss: 0.3709956263
Iteration 5608 => Loss: 0.3709941796
Iteration 5609 => Loss: 0.3709927331
Iteration 5610 => Loss: 0.3709912870
Iteration 5611 => Loss: 0.3709898410
Iteration 5612 => Loss: 0.3709883954
Iteration 5613 => Loss: 0.3709869500
Iteration 5614 => Loss: 0.3709855048
Iteration 5615 => Loss: 0.3709840600
Iteration 5616 => Loss: 0.3709826153
Iteration 5617 => Loss: 0.3709811710
Iteration 5618 => Loss: 0.3709797269
Iteration 5619 => Loss: 0.3709782831
Iteration 5620 => Loss: 0.3709768395
Iteration 5621 => Loss: 0.3709753962
Iteration 5622 => Loss: 0.3709739531
Iteration 5623 => Loss: 0.3709725103
Iteration 5624 => Loss: 0.3709710677
Iteration 5625 => Loss: 0.3709696254
Iteration 5626 => Loss: 0.3709681834
Iteration 5627 => Loss: 0.3709667416
Iteration 5628 => Loss: 0.3709653001
Iteration 5629 => Loss: 0.3709638589
Iteration 5630 => Loss: 0.3709624179
Iteration 5631 => Loss: 0.3709609771
Iteration 5632 => Loss: 0.3709595366
Iteration 5633 => Loss: 0.3709580964
Iteration 5634 => Loss: 0.3709566564
Iteration 5635 => Loss: 0.3709552167
Iteration 5636 => Loss: 0.3709537772
Iteration 5637 => Loss: 0.3709523380
Iteration 5638 => Loss: 0.3709508990
Iteration 5639 => Loss: 0.3709494603
Iteration 5640 => Loss: 0.3709480219
Iteration 5641 => Loss: 0.3709465837
Iteration 5642 => Loss: 0.3709451458
Iteration 5643 => Loss: 0.3709437081
Iteration 5644 => Loss: 0.3709422706
Iteration 5645 => Loss: 0.3709408335
Iteration 5646 => Loss: 0.3709393965
Iteration 5647 => Loss: 0.3709379599
Iteration 5648 => Loss: 0.3709365235
Iteration 5649 => Loss: 0.3709350873
Iteration 5650 => Loss: 0.3709336514
Iteration 5651 => Loss: 0.3709322157
Iteration 5652 => Loss: 0.3709307803
Iteration 5653 => Loss: 0.3709293452
Iteration 5654 => Loss: 0.3709279103
Iteration 5655 => Loss: 0.3709264756
Iteration 5656 => Loss: 0.3709250412
Iteration 5657 => Loss: 0.3709236071
Iteration 5658 => Loss: 0.3709221732
Iteration 5659 => Loss: 0.3709207395
Iteration 5660 => Loss: 0.3709193061
Iteration 5661 => Loss: 0.3709178730
Iteration 5662 => Loss: 0.3709164401
Iteration 5663 => Loss: 0.3709150074
Iteration 5664 => Loss: 0.3709135750
Iteration 5665 => Loss: 0.3709121429
Iteration 5666 => Loss: 0.3709107110
Iteration 5667 => Loss: 0.3709092794
Iteration 5668 => Loss: 0.3709078480
Iteration 5669 => Loss: 0.3709064168
Iteration 5670 => Loss: 0.3709049859
Iteration 5671 => Loss: 0.3709035553
Iteration 5672 => Loss: 0.3709021249
Iteration 5673 => Loss: 0.3709006947
Iteration 5674 => Loss: 0.3708992648
Iteration 5675 => Loss: 0.3708978351
Iteration 5676 => Loss: 0.3708964057
Iteration 5677 => Loss: 0.3708949766
Iteration 5678 => Loss: 0.3708935476
Iteration 5679 => Loss: 0.3708921190
Iteration 5680 => Loss: 0.3708906905
Iteration 5681 => Loss: 0.3708892624
Iteration 5682 => Loss: 0.3708878344
Iteration 5683 => Loss: 0.3708864067
Iteration 5684 => Loss: 0.3708849793
Iteration 5685 => Loss: 0.3708835521
Iteration 5686 => Loss: 0.3708821252
Iteration 5687 => Loss: 0.3708806985
Iteration 5688 => Loss: 0.3708792720
Iteration 5689 => Loss: 0.3708778458
Iteration 5690 => Loss: 0.3708764198
Iteration 5691 => Loss: 0.3708749941
Iteration 5692 => Loss: 0.3708735686
Iteration 5693 => Loss: 0.3708721434
Iteration 5694 => Loss: 0.3708707184
Iteration 5695 => Loss: 0.3708692936
Iteration 5696 => Loss: 0.3708678691
Iteration 5697 => Loss: 0.3708664449
Iteration 5698 => Loss: 0.3708650209
Iteration 5699 => Loss: 0.3708635971
Iteration 5700 => Loss: 0.3708621736
Iteration 5701 => Loss: 0.3708607503
Iteration 5702 => Loss: 0.3708593272
Iteration 5703 => Loss: 0.3708579044
Iteration 5704 => Loss: 0.3708564818
Iteration 5705 => Loss: 0.3708550595
Iteration 5706 => Loss: 0.3708536374
Iteration 5707 => Loss: 0.3708522156
Iteration 5708 => Loss: 0.3708507940
Iteration 5709 => Loss: 0.3708493727
Iteration 5710 => Loss: 0.3708479515
Iteration 5711 => Loss: 0.3708465307
Iteration 5712 => Loss: 0.3708451100
Iteration 5713 => Loss: 0.3708436896
Iteration 5714 => Loss: 0.3708422695
Iteration 5715 => Loss: 0.3708408496
Iteration 5716 => Loss: 0.3708394299
Iteration 5717 => Loss: 0.3708380105
Iteration 5718 => Loss: 0.3708365913
Iteration 5719 => Loss: 0.3708351723
Iteration 5720 => Loss: 0.3708337536
Iteration 5721 => Loss: 0.3708323351
Iteration 5722 => Loss: 0.3708309169
Iteration 5723 => Loss: 0.3708294989
Iteration 5724 => Loss: 0.3708280811
Iteration 5725 => Loss: 0.3708266636
Iteration 5726 => Loss: 0.3708252463
Iteration 5727 => Loss: 0.3708238293
Iteration 5728 => Loss: 0.3708224124
Iteration 5729 => Loss: 0.3708209959
Iteration 5730 => Loss: 0.3708195795
Iteration 5731 => Loss: 0.3708181634
Iteration 5732 => Loss: 0.3708167476
Iteration 5733 => Loss: 0.3708153319
Iteration 5734 => Loss: 0.3708139165
Iteration 5735 => Loss: 0.3708125014
Iteration 5736 => Loss: 0.3708110865
Iteration 5737 => Loss: 0.3708096718
Iteration 5738 => Loss: 0.3708082573
Iteration 5739 => Loss: 0.3708068431
Iteration 5740 => Loss: 0.3708054291
Iteration 5741 => Loss: 0.3708040154
Iteration 5742 => Loss: 0.3708026019
Iteration 5743 => Loss: 0.3708011886
Iteration 5744 => Loss: 0.3707997756
Iteration 5745 => Loss: 0.3707983628
Iteration 5746 => Loss: 0.3707969502
Iteration 5747 => Loss: 0.3707955379
Iteration 5748 => Loss: 0.3707941258
Iteration 5749 => Loss: 0.3707927139
Iteration 5750 => Loss: 0.3707913023
Iteration 5751 => Loss: 0.3707898908
Iteration 5752 => Loss: 0.3707884797
Iteration 5753 => Loss: 0.3707870687
Iteration 5754 => Loss: 0.3707856580
Iteration 5755 => Loss: 0.3707842476
Iteration 5756 => Loss: 0.3707828373
Iteration 5757 => Loss: 0.3707814273
Iteration 5758 => Loss: 0.3707800175
Iteration 5759 => Loss: 0.3707786080
Iteration 5760 => Loss: 0.3707771987
Iteration 5761 => Loss: 0.3707757896
Iteration 5762 => Loss: 0.3707743807
Iteration 5763 => Loss: 0.3707729721
Iteration 5764 => Loss: 0.3707715637
Iteration 5765 => Loss: 0.3707701556
Iteration 5766 => Loss: 0.3707687476
Iteration 5767 => Loss: 0.3707673399
Iteration 5768 => Loss: 0.3707659325
Iteration 5769 => Loss: 0.3707645252
Iteration 5770 => Loss: 0.3707631182
Iteration 5771 => Loss: 0.3707617114
Iteration 5772 => Loss: 0.3707603049
Iteration 5773 => Loss: 0.3707588986
Iteration 5774 => Loss: 0.3707574925
Iteration 5775 => Loss: 0.3707560866
Iteration 5776 => Loss: 0.3707546810
Iteration 5777 => Loss: 0.3707532756
Iteration 5778 => Loss: 0.3707518704
Iteration 5779 => Loss: 0.3707504654
Iteration 5780 => Loss: 0.3707490607
Iteration 5781 => Loss: 0.3707476562
Iteration 5782 => Loss: 0.3707462519
Iteration 5783 => Loss: 0.3707448479
Iteration 5784 => Loss: 0.3707434441
Iteration 5785 => Loss: 0.3707420405
Iteration 5786 => Loss: 0.3707406371
Iteration 5787 => Loss: 0.3707392340
Iteration 5788 => Loss: 0.3707378311
Iteration 5789 => Loss: 0.3707364284
Iteration 5790 => Loss: 0.3707350260
Iteration 5791 => Loss: 0.3707336237
Iteration 5792 => Loss: 0.3707322217
Iteration 5793 => Loss: 0.3707308199
Iteration 5794 => Loss: 0.3707294184
Iteration 5795 => Loss: 0.3707280171
Iteration 5796 => Loss: 0.3707266160
Iteration 5797 => Loss: 0.3707252151
Iteration 5798 => Loss: 0.3707238144
Iteration 5799 => Loss: 0.3707224140
Iteration 5800 => Loss: 0.3707210138
Iteration 5801 => Loss: 0.3707196138
Iteration 5802 => Loss: 0.3707182141
Iteration 5803 => Loss: 0.3707168145
Iteration 5804 => Loss: 0.3707154152
Iteration 5805 => Loss: 0.3707140161
Iteration 5806 => Loss: 0.3707126173
Iteration 5807 => Loss: 0.3707112186
Iteration 5808 => Loss: 0.3707098202
Iteration 5809 => Loss: 0.3707084220
Iteration 5810 => Loss: 0.3707070240
Iteration 5811 => Loss: 0.3707056263
Iteration 5812 => Loss: 0.3707042288
Iteration 5813 => Loss: 0.3707028314
Iteration 5814 => Loss: 0.3707014344
Iteration 5815 => Loss: 0.3707000375
Iteration 5816 => Loss: 0.3706986409
Iteration 5817 => Loss: 0.3706972444
Iteration 5818 => Loss: 0.3706958482
Iteration 5819 => Loss: 0.3706944523
Iteration 5820 => Loss: 0.3706930565
Iteration 5821 => Loss: 0.3706916610
Iteration 5822 => Loss: 0.3706902656
Iteration 5823 => Loss: 0.3706888705
Iteration 5824 => Loss: 0.3706874757
Iteration 5825 => Loss: 0.3706860810
Iteration 5826 => Loss: 0.3706846866
Iteration 5827 => Loss: 0.3706832924
Iteration 5828 => Loss: 0.3706818984
Iteration 5829 => Loss: 0.3706805046
Iteration 5830 => Loss: 0.3706791110
Iteration 5831 => Loss: 0.3706777177
Iteration 5832 => Loss: 0.3706763245
Iteration 5833 => Loss: 0.3706749316
Iteration 5834 => Loss: 0.3706735390
Iteration 5835 => Loss: 0.3706721465
Iteration 5836 => Loss: 0.3706707542
Iteration 5837 => Loss: 0.3706693622
Iteration 5838 => Loss: 0.3706679704
Iteration 5839 => Loss: 0.3706665788
Iteration 5840 => Loss: 0.3706651874
Iteration 5841 => Loss: 0.3706637962
Iteration 5842 => Loss: 0.3706624053
Iteration 5843 => Loss: 0.3706610146
Iteration 5844 => Loss: 0.3706596241
Iteration 5845 => Loss: 0.3706582338
Iteration 5846 => Loss: 0.3706568437
Iteration 5847 => Loss: 0.3706554538
Iteration 5848 => Loss: 0.3706540642
Iteration 5849 => Loss: 0.3706526747
Iteration 5850 => Loss: 0.3706512855
Iteration 5851 => Loss: 0.3706498965
Iteration 5852 => Loss: 0.3706485077
Iteration 5853 => Loss: 0.3706471192
Iteration 5854 => Loss: 0.3706457308
Iteration 5855 => Loss: 0.3706443427
Iteration 5856 => Loss: 0.3706429547
Iteration 5857 => Loss: 0.3706415670
Iteration 5858 => Loss: 0.3706401795
Iteration 5859 => Loss: 0.3706387922
Iteration 5860 => Loss: 0.3706374052
Iteration 5861 => Loss: 0.3706360183
Iteration 5862 => Loss: 0.3706346317
Iteration 5863 => Loss: 0.3706332452
Iteration 5864 => Loss: 0.3706318590
Iteration 5865 => Loss: 0.3706304730
Iteration 5866 => Loss: 0.3706290872
Iteration 5867 => Loss: 0.3706277016
Iteration 5868 => Loss: 0.3706263163
Iteration 5869 => Loss: 0.3706249311
Iteration 5870 => Loss: 0.3706235462
Iteration 5871 => Loss: 0.3706221614
Iteration 5872 => Loss: 0.3706207769
Iteration 5873 => Loss: 0.3706193926
Iteration 5874 => Loss: 0.3706180085
Iteration 5875 => Loss: 0.3706166246
Iteration 5876 => Loss: 0.3706152410
Iteration 5877 => Loss: 0.3706138575
Iteration 5878 => Loss: 0.3706124743
Iteration 5879 => Loss: 0.3706110912
Iteration 5880 => Loss: 0.3706097084
Iteration 5881 => Loss: 0.3706083258
Iteration 5882 => Loss: 0.3706069434
Iteration 5883 => Loss: 0.3706055612
Iteration 5884 => Loss: 0.3706041792
Iteration 5885 => Loss: 0.3706027974
Iteration 5886 => Loss: 0.3706014158
Iteration 5887 => Loss: 0.3706000345
Iteration 5888 => Loss: 0.3705986533
Iteration 5889 => Loss: 0.3705972724
Iteration 5890 => Loss: 0.3705958916
Iteration 5891 => Loss: 0.3705945111
Iteration 5892 => Loss: 0.3705931308
Iteration 5893 => Loss: 0.3705917507
Iteration 5894 => Loss: 0.3705903708
Iteration 5895 => Loss: 0.3705889911
Iteration 5896 => Loss: 0.3705876116
Iteration 5897 => Loss: 0.3705862323
Iteration 5898 => Loss: 0.3705848533
Iteration 5899 => Loss: 0.3705834744
Iteration 5900 => Loss: 0.3705820957
Iteration 5901 => Loss: 0.3705807173
Iteration 5902 => Loss: 0.3705793391
Iteration 5903 => Loss: 0.3705779610
Iteration 5904 => Loss: 0.3705765832
Iteration 5905 => Loss: 0.3705752056
Iteration 5906 => Loss: 0.3705738282
Iteration 5907 => Loss: 0.3705724510
Iteration 5908 => Loss: 0.3705710740
Iteration 5909 => Loss: 0.3705696972
Iteration 5910 => Loss: 0.3705683206
Iteration 5911 => Loss: 0.3705669442
Iteration 5912 => Loss: 0.3705655680
Iteration 5913 => Loss: 0.3705641920
Iteration 5914 => Loss: 0.3705628163
Iteration 5915 => Loss: 0.3705614407
Iteration 5916 => Loss: 0.3705600653
Iteration 5917 => Loss: 0.3705586902
Iteration 5918 => Loss: 0.3705573152
Iteration 5919 => Loss: 0.3705559405
Iteration 5920 => Loss: 0.3705545659
Iteration 5921 => Loss: 0.3705531916
Iteration 5922 => Loss: 0.3705518175
Iteration 5923 => Loss: 0.3705504435
Iteration 5924 => Loss: 0.3705490698
Iteration 5925 => Loss: 0.3705476963
Iteration 5926 => Loss: 0.3705463229
Iteration 5927 => Loss: 0.3705449498
Iteration 5928 => Loss: 0.3705435769
Iteration 5929 => Loss: 0.3705422042
Iteration 5930 => Loss: 0.3705408317
Iteration 5931 => Loss: 0.3705394594
Iteration 5932 => Loss: 0.3705380873
Iteration 5933 => Loss: 0.3705367154
Iteration 5934 => Loss: 0.3705353437
Iteration 5935 => Loss: 0.3705339722
Iteration 5936 => Loss: 0.3705326009
Iteration 5937 => Loss: 0.3705312298
Iteration 5938 => Loss: 0.3705298589
Iteration 5939 => Loss: 0.3705284882
Iteration 5940 => Loss: 0.3705271177
Iteration 5941 => Loss: 0.3705257474
Iteration 5942 => Loss: 0.3705243773
Iteration 5943 => Loss: 0.3705230074
Iteration 5944 => Loss: 0.3705216377
Iteration 5945 => Loss: 0.3705202682
Iteration 5946 => Loss: 0.3705188989
Iteration 5947 => Loss: 0.3705175298
Iteration 5948 => Loss: 0.3705161609
Iteration 5949 => Loss: 0.3705147922
Iteration 5950 => Loss: 0.3705134237
Iteration 5951 => Loss: 0.3705120554
Iteration 5952 => Loss: 0.3705106873
Iteration 5953 => Loss: 0.3705093194
Iteration 5954 => Loss: 0.3705079517
Iteration 5955 => Loss: 0.3705065842
Iteration 5956 => Loss: 0.3705052169
Iteration 5957 => Loss: 0.3705038498
Iteration 5958 => Loss: 0.3705024829
Iteration 5959 => Loss: 0.3705011162
Iteration 5960 => Loss: 0.3704997497
Iteration 5961 => Loss: 0.3704983834
Iteration 5962 => Loss: 0.3704970172
Iteration 5963 => Loss: 0.3704956513
Iteration 5964 => Loss: 0.3704942856
Iteration 5965 => Loss: 0.3704929201
Iteration 5966 => Loss: 0.3704915547
Iteration 5967 => Loss: 0.3704901896
Iteration 5968 => Loss: 0.3704888247
Iteration 5969 => Loss: 0.3704874599
Iteration 5970 => Loss: 0.3704860954
Iteration 5971 => Loss: 0.3704847310
Iteration 5972 => Loss: 0.3704833669
Iteration 5973 => Loss: 0.3704820029
Iteration 5974 => Loss: 0.3704806392
Iteration 5975 => Loss: 0.3704792756
Iteration 5976 => Loss: 0.3704779122
Iteration 5977 => Loss: 0.3704765491
Iteration 5978 => Loss: 0.3704751861
Iteration 5979 => Loss: 0.3704738233
Iteration 5980 => Loss: 0.3704724607
Iteration 5981 => Loss: 0.3704710983
Iteration 5982 => Loss: 0.3704697361
Iteration 5983 => Loss: 0.3704683741
Iteration 5984 => Loss: 0.3704670123
Iteration 5985 => Loss: 0.3704656507
Iteration 5986 => Loss: 0.3704642893
Iteration 5987 => Loss: 0.3704629280
Iteration 5988 => Loss: 0.3704615670
Iteration 5989 => Loss: 0.3704602061
Iteration 5990 => Loss: 0.3704588455
Iteration 5991 => Loss: 0.3704574850
Iteration 5992 => Loss: 0.3704561248
Iteration 5993 => Loss: 0.3704547647
Iteration 5994 => Loss: 0.3704534048
Iteration 5995 => Loss: 0.3704520451
Iteration 5996 => Loss: 0.3704506856
Iteration 5997 => Loss: 0.3704493263
Iteration 5998 => Loss: 0.3704479672
Iteration 5999 => Loss: 0.3704466083
Iteration 6000 => Loss: 0.3704452496
Iteration 6001 => Loss: 0.3704438910
Iteration 6002 => Loss: 0.3704425327
Iteration 6003 => Loss: 0.3704411745
Iteration 6004 => Loss: 0.3704398166
Iteration 6005 => Loss: 0.3704384588
Iteration 6006 => Loss: 0.3704371012
Iteration 6007 => Loss: 0.3704357438
Iteration 6008 => Loss: 0.3704343866
Iteration 6009 => Loss: 0.3704330296
Iteration 6010 => Loss: 0.3704316728
Iteration 6011 => Loss: 0.3704303162
Iteration 6012 => Loss: 0.3704289597
Iteration 6013 => Loss: 0.3704276035
Iteration 6014 => Loss: 0.3704262474
Iteration 6015 => Loss: 0.3704248915
Iteration 6016 => Loss: 0.3704235359
Iteration 6017 => Loss: 0.3704221804
Iteration 6018 => Loss: 0.3704208251
Iteration 6019 => Loss: 0.3704194700
Iteration 6020 => Loss: 0.3704181150
Iteration 6021 => Loss: 0.3704167603
Iteration 6022 => Loss: 0.3704154057
Iteration 6023 => Loss: 0.3704140514
Iteration 6024 => Loss: 0.3704126972
Iteration 6025 => Loss: 0.3704113432
Iteration 6026 => Loss: 0.3704099894
Iteration 6027 => Loss: 0.3704086358
Iteration 6028 => Loss: 0.3704072824
Iteration 6029 => Loss: 0.3704059292
Iteration 6030 => Loss: 0.3704045761
Iteration 6031 => Loss: 0.3704032233
Iteration 6032 => Loss: 0.3704018706
Iteration 6033 => Loss: 0.3704005181
Iteration 6034 => Loss: 0.3703991658
Iteration 6035 => Loss: 0.3703978137
Iteration 6036 => Loss: 0.3703964618
Iteration 6037 => Loss: 0.3703951100
Iteration 6038 => Loss: 0.3703937585
Iteration 6039 => Loss: 0.3703924071
Iteration 6040 => Loss: 0.3703910559
Iteration 6041 => Loss: 0.3703897049
Iteration 6042 => Loss: 0.3703883541
Iteration 6043 => Loss: 0.3703870035
Iteration 6044 => Loss: 0.3703856530
Iteration 6045 => Loss: 0.3703843028
Iteration 6046 => Loss: 0.3703829527
Iteration 6047 => Loss: 0.3703816028
Iteration 6048 => Loss: 0.3703802531
Iteration 6049 => Loss: 0.3703789036
Iteration 6050 => Loss: 0.3703775543
Iteration 6051 => Loss: 0.3703762051
Iteration 6052 => Loss: 0.3703748562
Iteration 6053 => Loss: 0.3703735074
Iteration 6054 => Loss: 0.3703721588
Iteration 6055 => Loss: 0.3703708104
Iteration 6056 => Loss: 0.3703694622
Iteration 6057 => Loss: 0.3703681141
Iteration 6058 => Loss: 0.3703667663
Iteration 6059 => Loss: 0.3703654186
Iteration 6060 => Loss: 0.3703640711
Iteration 6061 => Loss: 0.3703627238
Iteration 6062 => Loss: 0.3703613766
Iteration 6063 => Loss: 0.3703600297
Iteration 6064 => Loss: 0.3703586829
Iteration 6065 => Loss: 0.3703573363
Iteration 6066 => Loss: 0.3703559899
Iteration 6067 => Loss: 0.3703546437
Iteration 6068 => Loss: 0.3703532977
Iteration 6069 => Loss: 0.3703519518
Iteration 6070 => Loss: 0.3703506062
Iteration 6071 => Loss: 0.3703492607
Iteration 6072 => Loss: 0.3703479154
Iteration 6073 => Loss: 0.3703465702
Iteration 6074 => Loss: 0.3703452253
Iteration 6075 => Loss: 0.3703438805
Iteration 6076 => Loss: 0.3703425359
Iteration 6077 => Loss: 0.3703411915
Iteration 6078 => Loss: 0.3703398473
Iteration 6079 => Loss: 0.3703385032
Iteration 6080 => Loss: 0.3703371594
Iteration 6081 => Loss: 0.3703358157
Iteration 6082 => Loss: 0.3703344722
Iteration 6083 => Loss: 0.3703331289
Iteration 6084 => Loss: 0.3703317857
Iteration 6085 => Loss: 0.3703304427
Iteration 6086 => Loss: 0.3703291000
Iteration 6087 => Loss: 0.3703277573
Iteration 6088 => Loss: 0.3703264149
Iteration 6089 => Loss: 0.3703250727
Iteration 6090 => Loss: 0.3703237306
Iteration 6091 => Loss: 0.3703223887
Iteration 6092 => Loss: 0.3703210470
Iteration 6093 => Loss: 0.3703197054
Iteration 6094 => Loss: 0.3703183641
Iteration 6095 => Loss: 0.3703170229
Iteration 6096 => Loss: 0.3703156819
Iteration 6097 => Loss: 0.3703143411
Iteration 6098 => Loss: 0.3703130004
Iteration 6099 => Loss: 0.3703116600
Iteration 6100 => Loss: 0.3703103197
Iteration 6101 => Loss: 0.3703089796
Iteration 6102 => Loss: 0.3703076396
Iteration 6103 => Loss: 0.3703062999
Iteration 6104 => Loss: 0.3703049603
Iteration 6105 => Loss: 0.3703036209
Iteration 6106 => Loss: 0.3703022816
Iteration 6107 => Loss: 0.3703009426
Iteration 6108 => Loss: 0.3702996037
Iteration 6109 => Loss: 0.3702982650
Iteration 6110 => Loss: 0.3702969265
Iteration 6111 => Loss: 0.3702955881
Iteration 6112 => Loss: 0.3702942500
Iteration 6113 => Loss: 0.3702929120
Iteration 6114 => Loss: 0.3702915741
Iteration 6115 => Loss: 0.3702902365
Iteration 6116 => Loss: 0.3702888990
Iteration 6117 => Loss: 0.3702875617
Iteration 6118 => Loss: 0.3702862246
Iteration 6119 => Loss: 0.3702848876
Iteration 6120 => Loss: 0.3702835509
Iteration 6121 => Loss: 0.3702822143
Iteration 6122 => Loss: 0.3702808779
Iteration 6123 => Loss: 0.3702795416
Iteration 6124 => Loss: 0.3702782055
Iteration 6125 => Loss: 0.3702768696
Iteration 6126 => Loss: 0.3702755339
Iteration 6127 => Loss: 0.3702741983
Iteration 6128 => Loss: 0.3702728630
Iteration 6129 => Loss: 0.3702715278
Iteration 6130 => Loss: 0.3702701927
Iteration 6131 => Loss: 0.3702688579
Iteration 6132 => Loss: 0.3702675232
Iteration 6133 => Loss: 0.3702661887
Iteration 6134 => Loss: 0.3702648543
Iteration 6135 => Loss: 0.3702635202
Iteration 6136 => Loss: 0.3702621862
Iteration 6137 => Loss: 0.3702608523
Iteration 6138 => Loss: 0.3702595187
Iteration 6139 => Loss: 0.3702581852
Iteration 6140 => Loss: 0.3702568519
Iteration 6141 => Loss: 0.3702555188
Iteration 6142 => Loss: 0.3702541858
Iteration 6143 => Loss: 0.3702528530
Iteration 6144 => Loss: 0.3702515204
Iteration 6145 => Loss: 0.3702501879
Iteration 6146 => Loss: 0.3702488557
Iteration 6147 => Loss: 0.3702475236
Iteration 6148 => Loss: 0.3702461916
Iteration 6149 => Loss: 0.3702448599
Iteration 6150 => Loss: 0.3702435283
Iteration 6151 => Loss: 0.3702421969
Iteration 6152 => Loss: 0.3702408656
Iteration 6153 => Loss: 0.3702395345
Iteration 6154 => Loss: 0.3702382036
Iteration 6155 => Loss: 0.3702368729
Iteration 6156 => Loss: 0.3702355423
Iteration 6157 => Loss: 0.3702342119
Iteration 6158 => Loss: 0.3702328817
Iteration 6159 => Loss: 0.3702315516
Iteration 6160 => Loss: 0.3702302217
Iteration 6161 => Loss: 0.3702288920
Iteration 6162 => Loss: 0.3702275624
Iteration 6163 => Loss: 0.3702262330
Iteration 6164 => Loss: 0.3702249038
Iteration 6165 => Loss: 0.3702235748
Iteration 6166 => Loss: 0.3702222459
Iteration 6167 => Loss: 0.3702209172
Iteration 6168 => Loss: 0.3702195886
Iteration 6169 => Loss: 0.3702182603
Iteration 6170 => Loss: 0.3702169321
Iteration 6171 => Loss: 0.3702156040
Iteration 6172 => Loss: 0.3702142761
Iteration 6173 => Loss: 0.3702129484
Iteration 6174 => Loss: 0.3702116209
Iteration 6175 => Loss: 0.3702102935
Iteration 6176 => Loss: 0.3702089663
Iteration 6177 => Loss: 0.3702076393
Iteration 6178 => Loss: 0.3702063124
Iteration 6179 => Loss: 0.3702049857
Iteration 6180 => Loss: 0.3702036592
Iteration 6181 => Loss: 0.3702023328
Iteration 6182 => Loss: 0.3702010066
Iteration 6183 => Loss: 0.3701996806
Iteration 6184 => Loss: 0.3701983547
Iteration 6185 => Loss: 0.3701970290
Iteration 6186 => Loss: 0.3701957035
Iteration 6187 => Loss: 0.3701943781
Iteration 6188 => Loss: 0.3701930529
Iteration 6189 => Loss: 0.3701917279
Iteration 6190 => Loss: 0.3701904030
Iteration 6191 => Loss: 0.3701890783
Iteration 6192 => Loss: 0.3701877538
Iteration 6193 => Loss: 0.3701864294
Iteration 6194 => Loss: 0.3701851052
Iteration 6195 => Loss: 0.3701837812
Iteration 6196 => Loss: 0.3701824573
Iteration 6197 => Loss: 0.3701811336
Iteration 6198 => Loss: 0.3701798100
Iteration 6199 => Loss: 0.3701784866
Iteration 6200 => Loss: 0.3701771634
Iteration 6201 => Loss: 0.3701758403
Iteration 6202 => Loss: 0.3701745174
Iteration 6203 => Loss: 0.3701731947
Iteration 6204 => Loss: 0.3701718722
Iteration 6205 => Loss: 0.3701705497
Iteration 6206 => Loss: 0.3701692275
Iteration 6207 => Loss: 0.3701679054
Iteration 6208 => Loss: 0.3701665835
Iteration 6209 => Loss: 0.3701652618
Iteration 6210 => Loss: 0.3701639402
Iteration 6211 => Loss: 0.3701626188
Iteration 6212 => Loss: 0.3701612975
Iteration 6213 => Loss: 0.3701599764
Iteration 6214 => Loss: 0.3701586555
Iteration 6215 => Loss: 0.3701573347
Iteration 6216 => Loss: 0.3701560141
Iteration 6217 => Loss: 0.3701546936
Iteration 6218 => Loss: 0.3701533734
Iteration 6219 => Loss: 0.3701520532
Iteration 6220 => Loss: 0.3701507333
Iteration 6221 => Loss: 0.3701494135
Iteration 6222 => Loss: 0.3701480938
Iteration 6223 => Loss: 0.3701467744
Iteration 6224 => Loss: 0.3701454550
Iteration 6225 => Loss: 0.3701441359
Iteration 6226 => Loss: 0.3701428169
Iteration 6227 => Loss: 0.3701414981
Iteration 6228 => Loss: 0.3701401794
Iteration 6229 => Loss: 0.3701388609
Iteration 6230 => Loss: 0.3701375425
Iteration 6231 => Loss: 0.3701362243
Iteration 6232 => Loss: 0.3701349063
Iteration 6233 => Loss: 0.3701335884
Iteration 6234 => Loss: 0.3701322707
Iteration 6235 => Loss: 0.3701309532
Iteration 6236 => Loss: 0.3701296358
Iteration 6237 => Loss: 0.3701283186
Iteration 6238 => Loss: 0.3701270015
Iteration 6239 => Loss: 0.3701256846
Iteration 6240 => Loss: 0.3701243678
Iteration 6241 => Loss: 0.3701230512
Iteration 6242 => Loss: 0.3701217348
Iteration 6243 => Loss: 0.3701204185
Iteration 6244 => Loss: 0.3701191024
Iteration 6245 => Loss: 0.3701177865
Iteration 6246 => Loss: 0.3701164707
Iteration 6247 => Loss: 0.3701151550
Iteration 6248 => Loss: 0.3701138395
Iteration 6249 => Loss: 0.3701125242
Iteration 6250 => Loss: 0.3701112091
Iteration 6251 => Loss: 0.3701098940
Iteration 6252 => Loss: 0.3701085792
Iteration 6253 => Loss: 0.3701072645
Iteration 6254 => Loss: 0.3701059500
Iteration 6255 => Loss: 0.3701046356
Iteration 6256 => Loss: 0.3701033214
Iteration 6257 => Loss: 0.3701020073
Iteration 6258 => Loss: 0.3701006934
Iteration 6259 => Loss: 0.3700993797
Iteration 6260 => Loss: 0.3700980661
Iteration 6261 => Loss: 0.3700967527
Iteration 6262 => Loss: 0.3700954394
Iteration 6263 => Loss: 0.3700941263
Iteration 6264 => Loss: 0.3700928133
Iteration 6265 => Loss: 0.3700915005
Iteration 6266 => Loss: 0.3700901878
Iteration 6267 => Loss: 0.3700888754
Iteration 6268 => Loss: 0.3700875630
Iteration 6269 => Loss: 0.3700862508
Iteration 6270 => Loss: 0.3700849388
Iteration 6271 => Loss: 0.3700836269
Iteration 6272 => Loss: 0.3700823152
Iteration 6273 => Loss: 0.3700810037
Iteration 6274 => Loss: 0.3700796923
Iteration 6275 => Loss: 0.3700783810
Iteration 6276 => Loss: 0.3700770699
Iteration 6277 => Loss: 0.3700757590
Iteration 6278 => Loss: 0.3700744482
Iteration 6279 => Loss: 0.3700731376
Iteration 6280 => Loss: 0.3700718271
Iteration 6281 => Loss: 0.3700705168
Iteration 6282 => Loss: 0.3700692066
Iteration 6283 => Loss: 0.3700678966
Iteration 6284 => Loss: 0.3700665867
Iteration 6285 => Loss: 0.3700652770
Iteration 6286 => Loss: 0.3700639675
Iteration 6287 => Loss: 0.3700626581
Iteration 6288 => Loss: 0.3700613489
Iteration 6289 => Loss: 0.3700600398
Iteration 6290 => Loss: 0.3700587308
Iteration 6291 => Loss: 0.3700574221
Iteration 6292 => Loss: 0.3700561134
Iteration 6293 => Loss: 0.3700548050
Iteration 6294 => Loss: 0.3700534966
Iteration 6295 => Loss: 0.3700521885
Iteration 6296 => Loss: 0.3700508804
Iteration 6297 => Loss: 0.3700495726
Iteration 6298 => Loss: 0.3700482649
Iteration 6299 => Loss: 0.3700469573
Iteration 6300 => Loss: 0.3700456499
Iteration 6301 => Loss: 0.3700443427
Iteration 6302 => Loss: 0.3700430356
Iteration 6303 => Loss: 0.3700417286
Iteration 6304 => Loss: 0.3700404218
Iteration 6305 => Loss: 0.3700391152
Iteration 6306 => Loss: 0.3700378087
Iteration 6307 => Loss: 0.3700365023
Iteration 6308 => Loss: 0.3700351961
Iteration 6309 => Loss: 0.3700338901
Iteration 6310 => Loss: 0.3700325842
Iteration 6311 => Loss: 0.3700312785
Iteration 6312 => Loss: 0.3700299729
Iteration 6313 => Loss: 0.3700286674
Iteration 6314 => Loss: 0.3700273622
Iteration 6315 => Loss: 0.3700260570
Iteration 6316 => Loss: 0.3700247520
Iteration 6317 => Loss: 0.3700234472
Iteration 6318 => Loss: 0.3700221425
Iteration 6319 => Loss: 0.3700208380
Iteration 6320 => Loss: 0.3700195336
Iteration 6321 => Loss: 0.3700182294
Iteration 6322 => Loss: 0.3700169253
Iteration 6323 => Loss: 0.3700156213
Iteration 6324 => Loss: 0.3700143176
Iteration 6325 => Loss: 0.3700130139
Iteration 6326 => Loss: 0.3700117104
Iteration 6327 => Loss: 0.3700104071
Iteration 6328 => Loss: 0.3700091039
Iteration 6329 => Loss: 0.3700078009
Iteration 6330 => Loss: 0.3700064980
Iteration 6331 => Loss: 0.3700051952
Iteration 6332 => Loss: 0.3700038927
Iteration 6333 => Loss: 0.3700025902
Iteration 6334 => Loss: 0.3700012879
Iteration 6335 => Loss: 0.3699999858
Iteration 6336 => Loss: 0.3699986838
Iteration 6337 => Loss: 0.3699973819
Iteration 6338 => Loss: 0.3699960802
Iteration 6339 => Loss: 0.3699947787
Iteration 6340 => Loss: 0.3699934773
Iteration 6341 => Loss: 0.3699921760
Iteration 6342 => Loss: 0.3699908749
Iteration 6343 => Loss: 0.3699895739
Iteration 6344 => Loss: 0.3699882731
Iteration 6345 => Loss: 0.3699869724
Iteration 6346 => Loss: 0.3699856719
Iteration 6347 => Loss: 0.3699843715
Iteration 6348 => Loss: 0.3699830713
Iteration 6349 => Loss: 0.3699817712
Iteration 6350 => Loss: 0.3699804713
Iteration 6351 => Loss: 0.3699791715
Iteration 6352 => Loss: 0.3699778719
Iteration 6353 => Loss: 0.3699765724
Iteration 6354 => Loss: 0.3699752730
Iteration 6355 => Loss: 0.3699739738
Iteration 6356 => Loss: 0.3699726747
Iteration 6357 => Loss: 0.3699713758
Iteration 6358 => Loss: 0.3699700771
Iteration 6359 => Loss: 0.3699687784
Iteration 6360 => Loss: 0.3699674800
Iteration 6361 => Loss: 0.3699661816
Iteration 6362 => Loss: 0.3699648835
Iteration 6363 => Loss: 0.3699635854
Iteration 6364 => Loss: 0.3699622875
Iteration 6365 => Loss: 0.3699609898
Iteration 6366 => Loss: 0.3699596922
Iteration 6367 => Loss: 0.3699583947
Iteration 6368 => Loss: 0.3699570974
Iteration 6369 => Loss: 0.3699558002
Iteration 6370 => Loss: 0.3699545032
Iteration 6371 => Loss: 0.3699532063
Iteration 6372 => Loss: 0.3699519096
Iteration 6373 => Loss: 0.3699506130
Iteration 6374 => Loss: 0.3699493166
Iteration 6375 => Loss: 0.3699480202
Iteration 6376 => Loss: 0.3699467241
Iteration 6377 => Loss: 0.3699454281
Iteration 6378 => Loss: 0.3699441322
Iteration 6379 => Loss: 0.3699428365
Iteration 6380 => Loss: 0.3699415409
Iteration 6381 => Loss: 0.3699402454
Iteration 6382 => Loss: 0.3699389501
Iteration 6383 => Loss: 0.3699376550
Iteration 6384 => Loss: 0.3699363600
Iteration 6385 => Loss: 0.3699350651
Iteration 6386 => Loss: 0.3699337704
Iteration 6387 => Loss: 0.3699324758
Iteration 6388 => Loss: 0.3699311813
Iteration 6389 => Loss: 0.3699298870
Iteration 6390 => Loss: 0.3699285929
Iteration 6391 => Loss: 0.3699272989
Iteration 6392 => Loss: 0.3699260050
Iteration 6393 => Loss: 0.3699247113
Iteration 6394 => Loss: 0.3699234177
Iteration 6395 => Loss: 0.3699221242
Iteration 6396 => Loss: 0.3699208309
Iteration 6397 => Loss: 0.3699195378
Iteration 6398 => Loss: 0.3699182447
Iteration 6399 => Loss: 0.3699169519
Iteration 6400 => Loss: 0.3699156591
Iteration 6401 => Loss: 0.3699143665
Iteration 6402 => Loss: 0.3699130741
Iteration 6403 => Loss: 0.3699117817
Iteration 6404 => Loss: 0.3699104896
Iteration 6405 => Loss: 0.3699091975
Iteration 6406 => Loss: 0.3699079056
Iteration 6407 => Loss: 0.3699066139
Iteration 6408 => Loss: 0.3699053223
Iteration 6409 => Loss: 0.3699040308
Iteration 6410 => Loss: 0.3699027395
Iteration 6411 => Loss: 0.3699014483
Iteration 6412 => Loss: 0.3699001572
Iteration 6413 => Loss: 0.3698988663
Iteration 6414 => Loss: 0.3698975755
Iteration 6415 => Loss: 0.3698962849
Iteration 6416 => Loss: 0.3698949944
Iteration 6417 => Loss: 0.3698937040
Iteration 6418 => Loss: 0.3698924138
Iteration 6419 => Loss: 0.3698911237
Iteration 6420 => Loss: 0.3698898338
Iteration 6421 => Loss: 0.3698885440
Iteration 6422 => Loss: 0.3698872544
Iteration 6423 => Loss: 0.3698859648
Iteration 6424 => Loss: 0.3698846755
Iteration 6425 => Loss: 0.3698833862
Iteration 6426 => Loss: 0.3698820971
Iteration 6427 => Loss: 0.3698808081
Iteration 6428 => Loss: 0.3698795193
Iteration 6429 => Loss: 0.3698782306
Iteration 6430 => Loss: 0.3698769421
Iteration 6431 => Loss: 0.3698756537
Iteration 6432 => Loss: 0.3698743654
Iteration 6433 => Loss: 0.3698730772
Iteration 6434 => Loss: 0.3698717892
Iteration 6435 => Loss: 0.3698705014
Iteration 6436 => Loss: 0.3698692137
Iteration 6437 => Loss: 0.3698679261
Iteration 6438 => Loss: 0.3698666386
Iteration 6439 => Loss: 0.3698653513
Iteration 6440 => Loss: 0.3698640641
Iteration 6441 => Loss: 0.3698627771
Iteration 6442 => Loss: 0.3698614902
Iteration 6443 => Loss: 0.3698602034
Iteration 6444 => Loss: 0.3698589168
Iteration 6445 => Loss: 0.3698576303
Iteration 6446 => Loss: 0.3698563440
Iteration 6447 => Loss: 0.3698550577
Iteration 6448 => Loss: 0.3698537717
Iteration 6449 => Loss: 0.3698524857
Iteration 6450 => Loss: 0.3698511999
Iteration 6451 => Loss: 0.3698499142
Iteration 6452 => Loss: 0.3698486287
Iteration 6453 => Loss: 0.3698473433
Iteration 6454 => Loss: 0.3698460580
Iteration 6455 => Loss: 0.3698447729
Iteration 6456 => Loss: 0.3698434879
Iteration 6457 => Loss: 0.3698422030
Iteration 6458 => Loss: 0.3698409183
Iteration 6459 => Loss: 0.3698396337
Iteration 6460 => Loss: 0.3698383493
Iteration 6461 => Loss: 0.3698370650
Iteration 6462 => Loss: 0.3698357808
Iteration 6463 => Loss: 0.3698344967
Iteration 6464 => Loss: 0.3698332128
Iteration 6465 => Loss: 0.3698319290
Iteration 6466 => Loss: 0.3698306454
Iteration 6467 => Loss: 0.3698293619
Iteration 6468 => Loss: 0.3698280785
Iteration 6469 => Loss: 0.3698267953
Iteration 6470 => Loss: 0.3698255121
Iteration 6471 => Loss: 0.3698242292
Iteration 6472 => Loss: 0.3698229463
Iteration 6473 => Loss: 0.3698216636
Iteration 6474 => Loss: 0.3698203810
Iteration 6475 => Loss: 0.3698190986
Iteration 6476 => Loss: 0.3698178163
Iteration 6477 => Loss: 0.3698165341
Iteration 6478 => Loss: 0.3698152521
Iteration 6479 => Loss: 0.3698139702
Iteration 6480 => Loss: 0.3698126884
Iteration 6481 => Loss: 0.3698114068
Iteration 6482 => Loss: 0.3698101253
Iteration 6483 => Loss: 0.3698088439
Iteration 6484 => Loss: 0.3698075626
Iteration 6485 => Loss: 0.3698062815
Iteration 6486 => Loss: 0.3698050006
Iteration 6487 => Loss: 0.3698037197
Iteration 6488 => Loss: 0.3698024390
Iteration 6489 => Loss: 0.3698011584
Iteration 6490 => Loss: 0.3697998780
Iteration 6491 => Loss: 0.3697985977
Iteration 6492 => Loss: 0.3697973175
Iteration 6493 => Loss: 0.3697960374
Iteration 6494 => Loss: 0.3697947575
Iteration 6495 => Loss: 0.3697934777
Iteration 6496 => Loss: 0.3697921981
Iteration 6497 => Loss: 0.3697909185
Iteration 6498 => Loss: 0.3697896391
Iteration 6499 => Loss: 0.3697883599
Iteration 6500 => Loss: 0.3697870807
Iteration 6501 => Loss: 0.3697858017
Iteration 6502 => Loss: 0.3697845229
Iteration 6503 => Loss: 0.3697832441
Iteration 6504 => Loss: 0.3697819655
Iteration 6505 => Loss: 0.3697806870
Iteration 6506 => Loss: 0.3697794087
Iteration 6507 => Loss: 0.3697781305
Iteration 6508 => Loss: 0.3697768524
Iteration 6509 => Loss: 0.3697755744
Iteration 6510 => Loss: 0.3697742966
Iteration 6511 => Loss: 0.3697730189
Iteration 6512 => Loss: 0.3697717414
Iteration 6513 => Loss: 0.3697704639
Iteration 6514 => Loss: 0.3697691866
Iteration 6515 => Loss: 0.3697679094
Iteration 6516 => Loss: 0.3697666324
Iteration 6517 => Loss: 0.3697653555
Iteration 6518 => Loss: 0.3697640787
Iteration 6519 => Loss: 0.3697628020
Iteration 6520 => Loss: 0.3697615255
Iteration 6521 => Loss: 0.3697602491
Iteration 6522 => Loss: 0.3697589728
Iteration 6523 => Loss: 0.3697576967
Iteration 6524 => Loss: 0.3697564207
Iteration 6525 => Loss: 0.3697551448
Iteration 6526 => Loss: 0.3697538690
Iteration 6527 => Loss: 0.3697525934
Iteration 6528 => Loss: 0.3697513179
Iteration 6529 => Loss: 0.3697500425
Iteration 6530 => Loss: 0.3697487673
Iteration 6531 => Loss: 0.3697474922
Iteration 6532 => Loss: 0.3697462172
Iteration 6533 => Loss: 0.3697449423
Iteration 6534 => Loss: 0.3697436676
Iteration 6535 => Loss: 0.3697423930
Iteration 6536 => Loss: 0.3697411185
Iteration 6537 => Loss: 0.3697398442
Iteration 6538 => Loss: 0.3697385700
Iteration 6539 => Loss: 0.3697372959
Iteration 6540 => Loss: 0.3697360219
Iteration 6541 => Loss: 0.3697347481
Iteration 6542 => Loss: 0.3697334744
Iteration 6543 => Loss: 0.3697322008
Iteration 6544 => Loss: 0.3697309273
Iteration 6545 => Loss: 0.3697296540
Iteration 6546 => Loss: 0.3697283808
Iteration 6547 => Loss: 0.3697271077
Iteration 6548 => Loss: 0.3697258348
Iteration 6549 => Loss: 0.3697245619
Iteration 6550 => Loss: 0.3697232892
Iteration 6551 => Loss: 0.3697220167
Iteration 6552 => Loss: 0.3697207442
Iteration 6553 => Loss: 0.3697194719
Iteration 6554 => Loss: 0.3697181997
Iteration 6555 => Loss: 0.3697169276
Iteration 6556 => Loss: 0.3697156557
Iteration 6557 => Loss: 0.3697143839
Iteration 6558 => Loss: 0.3697131122
Iteration 6559 => Loss: 0.3697118406
Iteration 6560 => Loss: 0.3697105692
Iteration 6561 => Loss: 0.3697092979
Iteration 6562 => Loss: 0.3697080267
Iteration 6563 => Loss: 0.3697067556
Iteration 6564 => Loss: 0.3697054847
Iteration 6565 => Loss: 0.3697042139
Iteration 6566 => Loss: 0.3697029432
Iteration 6567 => Loss: 0.3697016726
Iteration 6568 => Loss: 0.3697004022
Iteration 6569 => Loss: 0.3696991319
Iteration 6570 => Loss: 0.3696978617
Iteration 6571 => Loss: 0.3696965916
Iteration 6572 => Loss: 0.3696953217
Iteration 6573 => Loss: 0.3696940519
Iteration 6574 => Loss: 0.3696927822
Iteration 6575 => Loss: 0.3696915126
Iteration 6576 => Loss: 0.3696902432
Iteration 6577 => Loss: 0.3696889739
Iteration 6578 => Loss: 0.3696877047
Iteration 6579 => Loss: 0.3696864356
Iteration 6580 => Loss: 0.3696851666
Iteration 6581 => Loss: 0.3696838978
Iteration 6582 => Loss: 0.3696826291
Iteration 6583 => Loss: 0.3696813605
Iteration 6584 => Loss: 0.3696800921
Iteration 6585 => Loss: 0.3696788237
Iteration 6586 => Loss: 0.3696775555
Iteration 6587 => Loss: 0.3696762875
Iteration 6588 => Loss: 0.3696750195
Iteration 6589 => Loss: 0.3696737517
Iteration 6590 => Loss: 0.3696724839
Iteration 6591 => Loss: 0.3696712163
Iteration 6592 => Loss: 0.3696699489
Iteration 6593 => Loss: 0.3696686815
Iteration 6594 => Loss: 0.3696674143
Iteration 6595 => Loss: 0.3696661472
Iteration 6596 => Loss: 0.3696648802
Iteration 6597 => Loss: 0.3696636133
Iteration 6598 => Loss: 0.3696623466
Iteration 6599 => Loss: 0.3696610800
Iteration 6600 => Loss: 0.3696598135
Iteration 6601 => Loss: 0.3696585471
Iteration 6602 => Loss: 0.3696572809
Iteration 6603 => Loss: 0.3696560147
Iteration 6604 => Loss: 0.3696547487
Iteration 6605 => Loss: 0.3696534828
Iteration 6606 => Loss: 0.3696522171
Iteration 6607 => Loss: 0.3696509514
Iteration 6608 => Loss: 0.3696496859
Iteration 6609 => Loss: 0.3696484205
Iteration 6610 => Loss: 0.3696471552
Iteration 6611 => Loss: 0.3696458901
Iteration 6612 => Loss: 0.3696446250
Iteration 6613 => Loss: 0.3696433601
Iteration 6614 => Loss: 0.3696420953
Iteration 6615 => Loss: 0.3696408306
Iteration 6616 => Loss: 0.3696395661
Iteration 6617 => Loss: 0.3696383016
Iteration 6618 => Loss: 0.3696370373
Iteration 6619 => Loss: 0.3696357731
Iteration 6620 => Loss: 0.3696345090
Iteration 6621 => Loss: 0.3696332451
Iteration 6622 => Loss: 0.3696319813
Iteration 6623 => Loss: 0.3696307175
Iteration 6624 => Loss: 0.3696294539
Iteration 6625 => Loss: 0.3696281905
Iteration 6626 => Loss: 0.3696269271
Iteration 6627 => Loss: 0.3696256639
Iteration 6628 => Loss: 0.3696244007
Iteration 6629 => Loss: 0.3696231377
Iteration 6630 => Loss: 0.3696218749
Iteration 6631 => Loss: 0.3696206121
Iteration 6632 => Loss: 0.3696193495
Iteration 6633 => Loss: 0.3696180869
Iteration 6634 => Loss: 0.3696168245
Iteration 6635 => Loss: 0.3696155622
Iteration 6636 => Loss: 0.3696143001
Iteration 6637 => Loss: 0.3696130380
Iteration 6638 => Loss: 0.3696117761
Iteration 6639 => Loss: 0.3696105143
Iteration 6640 => Loss: 0.3696092526
Iteration 6641 => Loss: 0.3696079910
Iteration 6642 => Loss: 0.3696067296
Iteration 6643 => Loss: 0.3696054682
Iteration 6644 => Loss: 0.3696042070
Iteration 6645 => Loss: 0.3696029459
Iteration 6646 => Loss: 0.3696016849
Iteration 6647 => Loss: 0.3696004240
Iteration 6648 => Loss: 0.3695991633
Iteration 6649 => Loss: 0.3695979027
Iteration 6650 => Loss: 0.3695966421
Iteration 6651 => Loss: 0.3695953817
Iteration 6652 => Loss: 0.3695941215
Iteration 6653 => Loss: 0.3695928613
Iteration 6654 => Loss: 0.3695916013
Iteration 6655 => Loss: 0.3695903413
Iteration 6656 => Loss: 0.3695890815
Iteration 6657 => Loss: 0.3695878218
Iteration 6658 => Loss: 0.3695865622
Iteration 6659 => Loss: 0.3695853028
Iteration 6660 => Loss: 0.3695840434
Iteration 6661 => Loss: 0.3695827842
Iteration 6662 => Loss: 0.3695815251
Iteration 6663 => Loss: 0.3695802661
Iteration 6664 => Loss: 0.3695790072
Iteration 6665 => Loss: 0.3695777484
Iteration 6666 => Loss: 0.3695764898
Iteration 6667 => Loss: 0.3695752313
Iteration 6668 => Loss: 0.3695739729
Iteration 6669 => Loss: 0.3695727146
Iteration 6670 => Loss: 0.3695714564
Iteration 6671 => Loss: 0.3695701983
Iteration 6672 => Loss: 0.3695689403
Iteration 6673 => Loss: 0.3695676825
Iteration 6674 => Loss: 0.3695664248
Iteration 6675 => Loss: 0.3695651672
Iteration 6676 => Loss: 0.3695639097
Iteration 6677 => Loss: 0.3695626523
Iteration 6678 => Loss: 0.3695613951
Iteration 6679 => Loss: 0.3695601379
Iteration 6680 => Loss: 0.3695588809
Iteration 6681 => Loss: 0.3695576240
Iteration 6682 => Loss: 0.3695563672
Iteration 6683 => Loss: 0.3695551105
Iteration 6684 => Loss: 0.3695538539
Iteration 6685 => Loss: 0.3695525974
Iteration 6686 => Loss: 0.3695513411
Iteration 6687 => Loss: 0.3695500849
Iteration 6688 => Loss: 0.3695488287
Iteration 6689 => Loss: 0.3695475727
Iteration 6690 => Loss: 0.3695463169
Iteration 6691 => Loss: 0.3695450611
Iteration 6692 => Loss: 0.3695438054
Iteration 6693 => Loss: 0.3695425499
Iteration 6694 => Loss: 0.3695412945
Iteration 6695 => Loss: 0.3695400391
Iteration 6696 => Loss: 0.3695387839
Iteration 6697 => Loss: 0.3695375288
Iteration 6698 => Loss: 0.3695362739
Iteration 6699 => Loss: 0.3695350190
Iteration 6700 => Loss: 0.3695337643
Iteration 6701 => Loss: 0.3695325096
Iteration 6702 => Loss: 0.3695312551
Iteration 6703 => Loss: 0.3695300007
Iteration 6704 => Loss: 0.3695287464
Iteration 6705 => Loss: 0.3695274922
Iteration 6706 => Loss: 0.3695262381
Iteration 6707 => Loss: 0.3695249842
Iteration 6708 => Loss: 0.3695237303
Iteration 6709 => Loss: 0.3695224766
Iteration 6710 => Loss: 0.3695212230
Iteration 6711 => Loss: 0.3695199694
Iteration 6712 => Loss: 0.3695187161
Iteration 6713 => Loss: 0.3695174628
Iteration 6714 => Loss: 0.3695162096
Iteration 6715 => Loss: 0.3695149565
Iteration 6716 => Loss: 0.3695137036
Iteration 6717 => Loss: 0.3695124507
Iteration 6718 => Loss: 0.3695111980
Iteration 6719 => Loss: 0.3695099454
Iteration 6720 => Loss: 0.3695086929
Iteration 6721 => Loss: 0.3695074405
Iteration 6722 => Loss: 0.3695061882
Iteration 6723 => Loss: 0.3695049361
Iteration 6724 => Loss: 0.3695036840
Iteration 6725 => Loss: 0.3695024321
Iteration 6726 => Loss: 0.3695011802
Iteration 6727 => Loss: 0.3694999285
Iteration 6728 => Loss: 0.3694986769
Iteration 6729 => Loss: 0.3694974254
Iteration 6730 => Loss: 0.3694961740
Iteration 6731 => Loss: 0.3694949227
Iteration 6732 => Loss: 0.3694936716
Iteration 6733 => Loss: 0.3694924205
Iteration 6734 => Loss: 0.3694911695
Iteration 6735 => Loss: 0.3694899187
Iteration 6736 => Loss: 0.3694886680
Iteration 6737 => Loss: 0.3694874174
Iteration 6738 => Loss: 0.3694861669
Iteration 6739 => Loss: 0.3694849165
Iteration 6740 => Loss: 0.3694836662
Iteration 6741 => Loss: 0.3694824160
Iteration 6742 => Loss: 0.3694811659
Iteration 6743 => Loss: 0.3694799160
Iteration 6744 => Loss: 0.3694786661
Iteration 6745 => Loss: 0.3694774164
Iteration 6746 => Loss: 0.3694761668
Iteration 6747 => Loss: 0.3694749172
Iteration 6748 => Loss: 0.3694736678
Iteration 6749 => Loss: 0.3694724185
Iteration 6750 => Loss: 0.3694711693
Iteration 6751 => Loss: 0.3694699203
Iteration 6752 => Loss: 0.3694686713
Iteration 6753 => Loss: 0.3694674224
Iteration 6754 => Loss: 0.3694661737
Iteration 6755 => Loss: 0.3694649250
Iteration 6756 => Loss: 0.3694636765
Iteration 6757 => Loss: 0.3694624281
Iteration 6758 => Loss: 0.3694611797
Iteration 6759 => Loss: 0.3694599315
Iteration 6760 => Loss: 0.3694586834
Iteration 6761 => Loss: 0.3694574354
Iteration 6762 => Loss: 0.3694561876
Iteration 6763 => Loss: 0.3694549398
Iteration 6764 => Loss: 0.3694536921
Iteration 6765 => Loss: 0.3694524445
Iteration 6766 => Loss: 0.3694511971
Iteration 6767 => Loss: 0.3694499497
Iteration 6768 => Loss: 0.3694487025
Iteration 6769 => Loss: 0.3694474554
Iteration 6770 => Loss: 0.3694462084
Iteration 6771 => Loss: 0.3694449614
Iteration 6772 => Loss: 0.3694437146
Iteration 6773 => Loss: 0.3694424679
Iteration 6774 => Loss: 0.3694412213
Iteration 6775 => Loss: 0.3694399749
Iteration 6776 => Loss: 0.3694387285
Iteration 6777 => Loss: 0.3694374822
Iteration 6778 => Loss: 0.3694362360
Iteration 6779 => Loss: 0.3694349900
Iteration 6780 => Loss: 0.3694337440
Iteration 6781 => Loss: 0.3694324982
Iteration 6782 => Loss: 0.3694312525
Iteration 6783 => Loss: 0.3694300068
Iteration 6784 => Loss: 0.3694287613
Iteration 6785 => Loss: 0.3694275159
Iteration 6786 => Loss: 0.3694262706
Iteration 6787 => Loss: 0.3694250254
Iteration 6788 => Loss: 0.3694237803
Iteration 6789 => Loss: 0.3694225353
Iteration 6790 => Loss: 0.3694212904
Iteration 6791 => Loss: 0.3694200456
Iteration 6792 => Loss: 0.3694188010
Iteration 6793 => Loss: 0.3694175564
Iteration 6794 => Loss: 0.3694163119
Iteration 6795 => Loss: 0.3694150676
Iteration 6796 => Loss: 0.3694138233
Iteration 6797 => Loss: 0.3694125792
Iteration 6798 => Loss: 0.3694113351
Iteration 6799 => Loss: 0.3694100912
Iteration 6800 => Loss: 0.3694088474
Iteration 6801 => Loss: 0.3694076037
Iteration 6802 => Loss: 0.3694063600
Iteration 6803 => Loss: 0.3694051165
Iteration 6804 => Loss: 0.3694038731
Iteration 6805 => Loss: 0.3694026298
Iteration 6806 => Loss: 0.3694013866
Iteration 6807 => Loss: 0.3694001435
Iteration 6808 => Loss: 0.3693989005
Iteration 6809 => Loss: 0.3693976577
Iteration 6810 => Loss: 0.3693964149
Iteration 6811 => Loss: 0.3693951722
Iteration 6812 => Loss: 0.3693939296
Iteration 6813 => Loss: 0.3693926872
Iteration 6814 => Loss: 0.3693914448
Iteration 6815 => Loss: 0.3693902026
Iteration 6816 => Loss: 0.3693889604
Iteration 6817 => Loss: 0.3693877184
Iteration 6818 => Loss: 0.3693864764
Iteration 6819 => Loss: 0.3693852346
Iteration 6820 => Loss: 0.3693839928
Iteration 6821 => Loss: 0.3693827512
Iteration 6822 => Loss: 0.3693815097
Iteration 6823 => Loss: 0.3693802683
Iteration 6824 => Loss: 0.3693790269
Iteration 6825 => Loss: 0.3693777857
Iteration 6826 => Loss: 0.3693765446
Iteration 6827 => Loss: 0.3693753036
Iteration 6828 => Loss: 0.3693740627
Iteration 6829 => Loss: 0.3693728219
Iteration 6830 => Loss: 0.3693715812
Iteration 6831 => Loss: 0.3693703406
Iteration 6832 => Loss: 0.3693691001
Iteration 6833 => Loss: 0.3693678597
Iteration 6834 => Loss: 0.3693666194
Iteration 6835 => Loss: 0.3693653792
Iteration 6836 => Loss: 0.3693641391
Iteration 6837 => Loss: 0.3693628992
Iteration 6838 => Loss: 0.3693616593
Iteration 6839 => Loss: 0.3693604195
Iteration 6840 => Loss: 0.3693591798
Iteration 6841 => Loss: 0.3693579403
Iteration 6842 => Loss: 0.3693567008
Iteration 6843 => Loss: 0.3693554614
Iteration 6844 => Loss: 0.3693542222
Iteration 6845 => Loss: 0.3693529830
Iteration 6846 => Loss: 0.3693517439
Iteration 6847 => Loss: 0.3693505050
Iteration 6848 => Loss: 0.3693492661
Iteration 6849 => Loss: 0.3693480274
Iteration 6850 => Loss: 0.3693467887
Iteration 6851 => Loss: 0.3693455502
Iteration 6852 => Loss: 0.3693443117
Iteration 6853 => Loss: 0.3693430734
Iteration 6854 => Loss: 0.3693418351
Iteration 6855 => Loss: 0.3693405970
Iteration 6856 => Loss: 0.3693393589
Iteration 6857 => Loss: 0.3693381210
Iteration 6858 => Loss: 0.3693368831
Iteration 6859 => Loss: 0.3693356454
Iteration 6860 => Loss: 0.3693344078
Iteration 6861 => Loss: 0.3693331702
Iteration 6862 => Loss: 0.3693319328
Iteration 6863 => Loss: 0.3693306954
Iteration 6864 => Loss: 0.3693294582
Iteration 6865 => Loss: 0.3693282211
Iteration 6866 => Loss: 0.3693269840
Iteration 6867 => Loss: 0.3693257471
Iteration 6868 => Loss: 0.3693245103
Iteration 6869 => Loss: 0.3693232735
Iteration 6870 => Loss: 0.3693220369
Iteration 6871 => Loss: 0.3693208004
Iteration 6872 => Loss: 0.3693195639
Iteration 6873 => Loss: 0.3693183276
Iteration 6874 => Loss: 0.3693170914
Iteration 6875 => Loss: 0.3693158552
Iteration 6876 => Loss: 0.3693146192
Iteration 6877 => Loss: 0.3693133833
Iteration 6878 => Loss: 0.3693121474
Iteration 6879 => Loss: 0.3693109117
Iteration 6880 => Loss: 0.3693096760
Iteration 6881 => Loss: 0.3693084405
Iteration 6882 => Loss: 0.3693072051
Iteration 6883 => Loss: 0.3693059697
Iteration 6884 => Loss: 0.3693047345
Iteration 6885 => Loss: 0.3693034994
Iteration 6886 => Loss: 0.3693022643
Iteration 6887 => Loss: 0.3693010294
Iteration 6888 => Loss: 0.3692997945
Iteration 6889 => Loss: 0.3692985598
Iteration 6890 => Loss: 0.3692973251
Iteration 6891 => Loss: 0.3692960906
Iteration 6892 => Loss: 0.3692948561
Iteration 6893 => Loss: 0.3692936218
Iteration 6894 => Loss: 0.3692923876
Iteration 6895 => Loss: 0.3692911534
Iteration 6896 => Loss: 0.3692899193
Iteration 6897 => Loss: 0.3692886854
Iteration 6898 => Loss: 0.3692874515
Iteration 6899 => Loss: 0.3692862178
Iteration 6900 => Loss: 0.3692849841
Iteration 6901 => Loss: 0.3692837506
Iteration 6902 => Loss: 0.3692825171
Iteration 6903 => Loss: 0.3692812837
Iteration 6904 => Loss: 0.3692800505
Iteration 6905 => Loss: 0.3692788173
Iteration 6906 => Loss: 0.3692775842
Iteration 6907 => Loss: 0.3692763512
Iteration 6908 => Loss: 0.3692751184
Iteration 6909 => Loss: 0.3692738856
Iteration 6910 => Loss: 0.3692726529
Iteration 6911 => Loss: 0.3692714203
Iteration 6912 => Loss: 0.3692701878
Iteration 6913 => Loss: 0.3692689554
Iteration 6914 => Loss: 0.3692677231
Iteration 6915 => Loss: 0.3692664909
Iteration 6916 => Loss: 0.3692652588
Iteration 6917 => Loss: 0.3692640268
Iteration 6918 => Loss: 0.3692627949
Iteration 6919 => Loss: 0.3692615631
Iteration 6920 => Loss: 0.3692603314
Iteration 6921 => Loss: 0.3692590998
Iteration 6922 => Loss: 0.3692578683
Iteration 6923 => Loss: 0.3692566369
Iteration 6924 => Loss: 0.3692554055
Iteration 6925 => Loss: 0.3692541743
Iteration 6926 => Loss: 0.3692529432
Iteration 6927 => Loss: 0.3692517121
Iteration 6928 => Loss: 0.3692504812
Iteration 6929 => Loss: 0.3692492503
Iteration 6930 => Loss: 0.3692480196
Iteration 6931 => Loss: 0.3692467889
Iteration 6932 => Loss: 0.3692455584
Iteration 6933 => Loss: 0.3692443279
Iteration 6934 => Loss: 0.3692430976
Iteration 6935 => Loss: 0.3692418673
Iteration 6936 => Loss: 0.3692406371
Iteration 6937 => Loss: 0.3692394070
Iteration 6938 => Loss: 0.3692381771
Iteration 6939 => Loss: 0.3692369472
Iteration 6940 => Loss: 0.3692357174
Iteration 6941 => Loss: 0.3692344877
Iteration 6942 => Loss: 0.3692332581
Iteration 6943 => Loss: 0.3692320286
Iteration 6944 => Loss: 0.3692307992
Iteration 6945 => Loss: 0.3692295698
Iteration 6946 => Loss: 0.3692283406
Iteration 6947 => Loss: 0.3692271115
Iteration 6948 => Loss: 0.3692258825
Iteration 6949 => Loss: 0.3692246535
Iteration 6950 => Loss: 0.3692234247
Iteration 6951 => Loss: 0.3692221959
Iteration 6952 => Loss: 0.3692209673
Iteration 6953 => Loss: 0.3692197387
Iteration 6954 => Loss: 0.3692185103
Iteration 6955 => Loss: 0.3692172819
Iteration 6956 => Loss: 0.3692160536
Iteration 6957 => Loss: 0.3692148254
Iteration 6958 => Loss: 0.3692135974
Iteration 6959 => Loss: 0.3692123694
Iteration 6960 => Loss: 0.3692111415
Iteration 6961 => Loss: 0.3692099137
Iteration 6962 => Loss: 0.3692086860
Iteration 6963 => Loss: 0.3692074583
Iteration 6964 => Loss: 0.3692062308
Iteration 6965 => Loss: 0.3692050034
Iteration 6966 => Loss: 0.3692037761
Iteration 6967 => Loss: 0.3692025488
Iteration 6968 => Loss: 0.3692013217
Iteration 6969 => Loss: 0.3692000946
Iteration 6970 => Loss: 0.3691988677
Iteration 6971 => Loss: 0.3691976408
Iteration 6972 => Loss: 0.3691964140
Iteration 6973 => Loss: 0.3691951873
Iteration 6974 => Loss: 0.3691939607
Iteration 6975 => Loss: 0.3691927342
Iteration 6976 => Loss: 0.3691915078
Iteration 6977 => Loss: 0.3691902815
Iteration 6978 => Loss: 0.3691890553
Iteration 6979 => Loss: 0.3691878292
Iteration 6980 => Loss: 0.3691866032
Iteration 6981 => Loss: 0.3691853772
Iteration 6982 => Loss: 0.3691841514
Iteration 6983 => Loss: 0.3691829256
Iteration 6984 => Loss: 0.3691817000
Iteration 6985 => Loss: 0.3691804744
Iteration 6986 => Loss: 0.3691792489
Iteration 6987 => Loss: 0.3691780235
Iteration 6988 => Loss: 0.3691767983
Iteration 6989 => Loss: 0.3691755731
Iteration 6990 => Loss: 0.3691743479
Iteration 6991 => Loss: 0.3691731229
Iteration 6992 => Loss: 0.3691718980
Iteration 6993 => Loss: 0.3691706732
Iteration 6994 => Loss: 0.3691694484
Iteration 6995 => Loss: 0.3691682238
Iteration 6996 => Loss: 0.3691669992
Iteration 6997 => Loss: 0.3691657748
Iteration 6998 => Loss: 0.3691645504
Iteration 6999 => Loss: 0.3691633261
Iteration 7000 => Loss: 0.3691621019
Iteration 7001 => Loss: 0.3691608778
Iteration 7002 => Loss: 0.3691596538
Iteration 7003 => Loss: 0.3691584299
Iteration 7004 => Loss: 0.3691572061
Iteration 7005 => Loss: 0.3691559824
Iteration 7006 => Loss: 0.3691547587
Iteration 7007 => Loss: 0.3691535352
Iteration 7008 => Loss: 0.3691523117
Iteration 7009 => Loss: 0.3691510883
Iteration 7010 => Loss: 0.3691498651
Iteration 7011 => Loss: 0.3691486419
Iteration 7012 => Loss: 0.3691474188
Iteration 7013 => Loss: 0.3691461958
Iteration 7014 => Loss: 0.3691449729
Iteration 7015 => Loss: 0.3691437500
Iteration 7016 => Loss: 0.3691425273
Iteration 7017 => Loss: 0.3691413046
Iteration 7018 => Loss: 0.3691400821
Iteration 7019 => Loss: 0.3691388596
Iteration 7020 => Loss: 0.3691376373
Iteration 7021 => Loss: 0.3691364150
Iteration 7022 => Loss: 0.3691351928
Iteration 7023 => Loss: 0.3691339707
Iteration 7024 => Loss: 0.3691327487
Iteration 7025 => Loss: 0.3691315267
Iteration 7026 => Loss: 0.3691303049
Iteration 7027 => Loss: 0.3691290832
Iteration 7028 => Loss: 0.3691278615
Iteration 7029 => Loss: 0.3691266399
Iteration 7030 => Loss: 0.3691254185
Iteration 7031 => Loss: 0.3691241971
Iteration 7032 => Loss: 0.3691229758
Iteration 7033 => Loss: 0.3691217546
Iteration 7034 => Loss: 0.3691205335
Iteration 7035 => Loss: 0.3691193124
Iteration 7036 => Loss: 0.3691180915
Iteration 7037 => Loss: 0.3691168706
Iteration 7038 => Loss: 0.3691156499
Iteration 7039 => Loss: 0.3691144292
Iteration 7040 => Loss: 0.3691132086
Iteration 7041 => Loss: 0.3691119881
Iteration 7042 => Loss: 0.3691107677
Iteration 7043 => Loss: 0.3691095474
Iteration 7044 => Loss: 0.3691083272
Iteration 7045 => Loss: 0.3691071070
Iteration 7046 => Loss: 0.3691058870
Iteration 7047 => Loss: 0.3691046670
Iteration 7048 => Loss: 0.3691034472
Iteration 7049 => Loss: 0.3691022274
Iteration 7050 => Loss: 0.3691010077
Iteration 7051 => Loss: 0.3690997881
Iteration 7052 => Loss: 0.3690985685
Iteration 7053 => Loss: 0.3690973491
Iteration 7054 => Loss: 0.3690961298
Iteration 7055 => Loss: 0.3690949105
Iteration 7056 => Loss: 0.3690936913
Iteration 7057 => Loss: 0.3690924723
Iteration 7058 => Loss: 0.3690912533
Iteration 7059 => Loss: 0.3690900344
Iteration 7060 => Loss: 0.3690888155
Iteration 7061 => Loss: 0.3690875968
Iteration 7062 => Loss: 0.3690863782
Iteration 7063 => Loss: 0.3690851596
Iteration 7064 => Loss: 0.3690839412
Iteration 7065 => Loss: 0.3690827228
Iteration 7066 => Loss: 0.3690815045
Iteration 7067 => Loss: 0.3690802863
Iteration 7068 => Loss: 0.3690790682
Iteration 7069 => Loss: 0.3690778501
Iteration 7070 => Loss: 0.3690766322
Iteration 7071 => Loss: 0.3690754143
Iteration 7072 => Loss: 0.3690741966
Iteration 7073 => Loss: 0.3690729789
Iteration 7074 => Loss: 0.3690717613
Iteration 7075 => Loss: 0.3690705438
Iteration 7076 => Loss: 0.3690693263
Iteration 7077 => Loss: 0.3690681090
Iteration 7078 => Loss: 0.3690668918
Iteration 7079 => Loss: 0.3690656746
Iteration 7080 => Loss: 0.3690644575
Iteration 7081 => Loss: 0.3690632405
Iteration 7082 => Loss: 0.3690620236
Iteration 7083 => Loss: 0.3690608068
Iteration 7084 => Loss: 0.3690595901
Iteration 7085 => Loss: 0.3690583734
Iteration 7086 => Loss: 0.3690571569
Iteration 7087 => Loss: 0.3690559404
Iteration 7088 => Loss: 0.3690547240
Iteration 7089 => Loss: 0.3690535077
Iteration 7090 => Loss: 0.3690522915
Iteration 7091 => Loss: 0.3690510754
Iteration 7092 => Loss: 0.3690498593
Iteration 7093 => Loss: 0.3690486434
Iteration 7094 => Loss: 0.3690474275
Iteration 7095 => Loss: 0.3690462117
Iteration 7096 => Loss: 0.3690449960
Iteration 7097 => Loss: 0.3690437804
Iteration 7098 => Loss: 0.3690425649
Iteration 7099 => Loss: 0.3690413494
Iteration 7100 => Loss: 0.3690401341
Iteration 7101 => Loss: 0.3690389188
Iteration 7102 => Loss: 0.3690377036
Iteration 7103 => Loss: 0.3690364885
Iteration 7104 => Loss: 0.3690352735
Iteration 7105 => Loss: 0.3690340586
Iteration 7106 => Loss: 0.3690328437
Iteration 7107 => Loss: 0.3690316289
Iteration 7108 => Loss: 0.3690304143
Iteration 7109 => Loss: 0.3690291997
Iteration 7110 => Loss: 0.3690279852
Iteration 7111 => Loss: 0.3690267707
Iteration 7112 => Loss: 0.3690255564
Iteration 7113 => Loss: 0.3690243421
Iteration 7114 => Loss: 0.3690231280
Iteration 7115 => Loss: 0.3690219139
Iteration 7116 => Loss: 0.3690206999
Iteration 7117 => Loss: 0.3690194860
Iteration 7118 => Loss: 0.3690182721
Iteration 7119 => Loss: 0.3690170584
Iteration 7120 => Loss: 0.3690158447
Iteration 7121 => Loss: 0.3690146311
Iteration 7122 => Loss: 0.3690134176
Iteration 7123 => Loss: 0.3690122042
Iteration 7124 => Loss: 0.3690109909
Iteration 7125 => Loss: 0.3690097777
Iteration 7126 => Loss: 0.3690085645
Iteration 7127 => Loss: 0.3690073514
Iteration 7128 => Loss: 0.3690061384
Iteration 7129 => Loss: 0.3690049255
Iteration 7130 => Loss: 0.3690037127
Iteration 7131 => Loss: 0.3690024999
Iteration 7132 => Loss: 0.3690012873
Iteration 7133 => Loss: 0.3690000747
Iteration 7134 => Loss: 0.3689988622
Iteration 7135 => Loss: 0.3689976498
Iteration 7136 => Loss: 0.3689964375
Iteration 7137 => Loss: 0.3689952252
Iteration 7138 => Loss: 0.3689940131
Iteration 7139 => Loss: 0.3689928010
Iteration 7140 => Loss: 0.3689915890
Iteration 7141 => Loss: 0.3689903771
Iteration 7142 => Loss: 0.3689891653
Iteration 7143 => Loss: 0.3689879535
Iteration 7144 => Loss: 0.3689867419
Iteration 7145 => Loss: 0.3689855303
Iteration 7146 => Loss: 0.3689843188
Iteration 7147 => Loss: 0.3689831074
Iteration 7148 => Loss: 0.3689818960
Iteration 7149 => Loss: 0.3689806848
Iteration 7150 => Loss: 0.3689794736
Iteration 7151 => Loss: 0.3689782625
Iteration 7152 => Loss: 0.3689770515
Iteration 7153 => Loss: 0.3689758406
Iteration 7154 => Loss: 0.3689746298
Iteration 7155 => Loss: 0.3689734190
Iteration 7156 => Loss: 0.3689722083
Iteration 7157 => Loss: 0.3689709977
Iteration 7158 => Loss: 0.3689697872
Iteration 7159 => Loss: 0.3689685768
Iteration 7160 => Loss: 0.3689673664
Iteration 7161 => Loss: 0.3689661562
Iteration 7162 => Loss: 0.3689649460
Iteration 7163 => Loss: 0.3689637359
Iteration 7164 => Loss: 0.3689625259
Iteration 7165 => Loss: 0.3689613159
Iteration 7166 => Loss: 0.3689601061
Iteration 7167 => Loss: 0.3689588963
Iteration 7168 => Loss: 0.3689576866
Iteration 7169 => Loss: 0.3689564770
Iteration 7170 => Loss: 0.3689552675
Iteration 7171 => Loss: 0.3689540580
Iteration 7172 => Loss: 0.3689528486
Iteration 7173 => Loss: 0.3689516394
Iteration 7174 => Loss: 0.3689504301
Iteration 7175 => Loss: 0.3689492210
Iteration 7176 => Loss: 0.3689480120
Iteration 7177 => Loss: 0.3689468030
Iteration 7178 => Loss: 0.3689455941
Iteration 7179 => Loss: 0.3689443853
Iteration 7180 => Loss: 0.3689431766
Iteration 7181 => Loss: 0.3689419680
Iteration 7182 => Loss: 0.3689407594
Iteration 7183 => Loss: 0.3689395509
Iteration 7184 => Loss: 0.3689383425
Iteration 7185 => Loss: 0.3689371342
Iteration 7186 => Loss: 0.3689359260
Iteration 7187 => Loss: 0.3689347178
Iteration 7188 => Loss: 0.3689335097
Iteration 7189 => Loss: 0.3689323017
Iteration 7190 => Loss: 0.3689310938
Iteration 7191 => Loss: 0.3689298860
Iteration 7192 => Loss: 0.3689286782
Iteration 7193 => Loss: 0.3689274705
Iteration 7194 => Loss: 0.3689262629
Iteration 7195 => Loss: 0.3689250554
Iteration 7196 => Loss: 0.3689238480
Iteration 7197 => Loss: 0.3689226406
Iteration 7198 => Loss: 0.3689214334
Iteration 7199 => Loss: 0.3689202262
Iteration 7200 => Loss: 0.3689190190
Iteration 7201 => Loss: 0.3689178120
Iteration 7202 => Loss: 0.3689166050
Iteration 7203 => Loss: 0.3689153982
Iteration 7204 => Loss: 0.3689141914
Iteration 7205 => Loss: 0.3689129846
Iteration 7206 => Loss: 0.3689117780
Iteration 7207 => Loss: 0.3689105714
Iteration 7208 => Loss: 0.3689093649
Iteration 7209 => Loss: 0.3689081585
Iteration 7210 => Loss: 0.3689069522
Iteration 7211 => Loss: 0.3689057460
Iteration 7212 => Loss: 0.3689045398
Iteration 7213 => Loss: 0.3689033337
Iteration 7214 => Loss: 0.3689021277
Iteration 7215 => Loss: 0.3689009218
Iteration 7216 => Loss: 0.3688997159
Iteration 7217 => Loss: 0.3688985102
Iteration 7218 => Loss: 0.3688973045
Iteration 7219 => Loss: 0.3688960988
Iteration 7220 => Loss: 0.3688948933
Iteration 7221 => Loss: 0.3688936878
Iteration 7222 => Loss: 0.3688924825
Iteration 7223 => Loss: 0.3688912772
Iteration 7224 => Loss: 0.3688900719
Iteration 7225 => Loss: 0.3688888668
Iteration 7226 => Loss: 0.3688876617
Iteration 7227 => Loss: 0.3688864567
Iteration 7228 => Loss: 0.3688852518
Iteration 7229 => Loss: 0.3688840470
Iteration 7230 => Loss: 0.3688828422
Iteration 7231 => Loss: 0.3688816376
Iteration 7232 => Loss: 0.3688804330
Iteration 7233 => Loss: 0.3688792284
Iteration 7234 => Loss: 0.3688780240
Iteration 7235 => Loss: 0.3688768196
Iteration 7236 => Loss: 0.3688756153
Iteration 7237 => Loss: 0.3688744111
Iteration 7238 => Loss: 0.3688732070
Iteration 7239 => Loss: 0.3688720029
Iteration 7240 => Loss: 0.3688707990
Iteration 7241 => Loss: 0.3688695951
Iteration 7242 => Loss: 0.3688683912
Iteration 7243 => Loss: 0.3688671875
Iteration 7244 => Loss: 0.3688659838
Iteration 7245 => Loss: 0.3688647802
Iteration 7246 => Loss: 0.3688635767
Iteration 7247 => Loss: 0.3688623733
Iteration 7248 => Loss: 0.3688611699
Iteration 7249 => Loss: 0.3688599666
Iteration 7250 => Loss: 0.3688587634
Iteration 7251 => Loss: 0.3688575603
Iteration 7252 => Loss: 0.3688563573
Iteration 7253 => Loss: 0.3688551543
Iteration 7254 => Loss: 0.3688539514
Iteration 7255 => Loss: 0.3688527486
Iteration 7256 => Loss: 0.3688515458
Iteration 7257 => Loss: 0.3688503432
Iteration 7258 => Loss: 0.3688491406
Iteration 7259 => Loss: 0.3688479380
Iteration 7260 => Loss: 0.3688467356
Iteration 7261 => Loss: 0.3688455332
Iteration 7262 => Loss: 0.3688443310
Iteration 7263 => Loss: 0.3688431287
Iteration 7264 => Loss: 0.3688419266
Iteration 7265 => Loss: 0.3688407246
Iteration 7266 => Loss: 0.3688395226
Iteration 7267 => Loss: 0.3688383207
Iteration 7268 => Loss: 0.3688371188
Iteration 7269 => Loss: 0.3688359171
Iteration 7270 => Loss: 0.3688347154
Iteration 7271 => Loss: 0.3688335138
Iteration 7272 => Loss: 0.3688323123
Iteration 7273 => Loss: 0.3688311108
Iteration 7274 => Loss: 0.3688299095
Iteration 7275 => Loss: 0.3688287082
Iteration 7276 => Loss: 0.3688275069
Iteration 7277 => Loss: 0.3688263058
Iteration 7278 => Loss: 0.3688251047
Iteration 7279 => Loss: 0.3688239037
Iteration 7280 => Loss: 0.3688227028
Iteration 7281 => Loss: 0.3688215020
Iteration 7282 => Loss: 0.3688203012
Iteration 7283 => Loss: 0.3688191005
Iteration 7284 => Loss: 0.3688178999
Iteration 7285 => Loss: 0.3688166993
Iteration 7286 => Loss: 0.3688154989
Iteration 7287 => Loss: 0.3688142985
Iteration 7288 => Loss: 0.3688130981
Iteration 7289 => Loss: 0.3688118979
Iteration 7290 => Loss: 0.3688106977
Iteration 7291 => Loss: 0.3688094976
Iteration 7292 => Loss: 0.3688082976
Iteration 7293 => Loss: 0.3688070977
Iteration 7294 => Loss: 0.3688058978
Iteration 7295 => Loss: 0.3688046980
Iteration 7296 => Loss: 0.3688034983
Iteration 7297 => Loss: 0.3688022986
Iteration 7298 => Loss: 0.3688010991
Iteration 7299 => Loss: 0.3687998996
Iteration 7300 => Loss: 0.3687987001
Iteration 7301 => Loss: 0.3687975008
Iteration 7302 => Loss: 0.3687963015
Iteration 7303 => Loss: 0.3687951023
Iteration 7304 => Loss: 0.3687939032
Iteration 7305 => Loss: 0.3687927041
Iteration 7306 => Loss: 0.3687915052
Iteration 7307 => Loss: 0.3687903063
Iteration 7308 => Loss: 0.3687891074
Iteration 7309 => Loss: 0.3687879087
Iteration 7310 => Loss: 0.3687867100
Iteration 7311 => Loss: 0.3687855114
Iteration 7312 => Loss: 0.3687843129
Iteration 7313 => Loss: 0.3687831144
Iteration 7314 => Loss: 0.3687819160
Iteration 7315 => Loss: 0.3687807177
Iteration 7316 => Loss: 0.3687795195
Iteration 7317 => Loss: 0.3687783213
Iteration 7318 => Loss: 0.3687771232
Iteration 7319 => Loss: 0.3687759252
Iteration 7320 => Loss: 0.3687747272
Iteration 7321 => Loss: 0.3687735294
Iteration 7322 => Loss: 0.3687723316
Iteration 7323 => Loss: 0.3687711338
Iteration 7324 => Loss: 0.3687699362
Iteration 7325 => Loss: 0.3687687386
Iteration 7326 => Loss: 0.3687675411
Iteration 7327 => Loss: 0.3687663437
Iteration 7328 => Loss: 0.3687651463
Iteration 7329 => Loss: 0.3687639490
Iteration 7330 => Loss: 0.3687627518
Iteration 7331 => Loss: 0.3687615547
Iteration 7332 => Loss: 0.3687603576
Iteration 7333 => Loss: 0.3687591606
Iteration 7334 => Loss: 0.3687579637
Iteration 7335 => Loss: 0.3687567668
Iteration 7336 => Loss: 0.3687555701
Iteration 7337 => Loss: 0.3687543733
Iteration 7338 => Loss: 0.3687531767
Iteration 7339 => Loss: 0.3687519802
Iteration 7340 => Loss: 0.3687507837
Iteration 7341 => Loss: 0.3687495873
Iteration 7342 => Loss: 0.3687483909
Iteration 7343 => Loss: 0.3687471946
Iteration 7344 => Loss: 0.3687459984
Iteration 7345 => Loss: 0.3687448023
Iteration 7346 => Loss: 0.3687436063
Iteration 7347 => Loss: 0.3687424103
Iteration 7348 => Loss: 0.3687412144
Iteration 7349 => Loss: 0.3687400185
Iteration 7350 => Loss: 0.3687388228
Iteration 7351 => Loss: 0.3687376271
Iteration 7352 => Loss: 0.3687364314
Iteration 7353 => Loss: 0.3687352359
Iteration 7354 => Loss: 0.3687340404
Iteration 7355 => Loss: 0.3687328450
Iteration 7356 => Loss: 0.3687316497
Iteration 7357 => Loss: 0.3687304544
Iteration 7358 => Loss: 0.3687292592
Iteration 7359 => Loss: 0.3687280641
Iteration 7360 => Loss: 0.3687268691
Iteration 7361 => Loss: 0.3687256741
Iteration 7362 => Loss: 0.3687244792
Iteration 7363 => Loss: 0.3687232843
Iteration 7364 => Loss: 0.3687220896
Iteration 7365 => Loss: 0.3687208949
Iteration 7366 => Loss: 0.3687197003
Iteration 7367 => Loss: 0.3687185057
Iteration 7368 => Loss: 0.3687173112
Iteration 7369 => Loss: 0.3687161168
Iteration 7370 => Loss: 0.3687149225
Iteration 7371 => Loss: 0.3687137282
Iteration 7372 => Loss: 0.3687125340
Iteration 7373 => Loss: 0.3687113399
Iteration 7374 => Loss: 0.3687101458
Iteration 7375 => Loss: 0.3687089519
Iteration 7376 => Loss: 0.3687077579
Iteration 7377 => Loss: 0.3687065641
Iteration 7378 => Loss: 0.3687053703
Iteration 7379 => Loss: 0.3687041766
Iteration 7380 => Loss: 0.3687029830
Iteration 7381 => Loss: 0.3687017894
Iteration 7382 => Loss: 0.3687005960
Iteration 7383 => Loss: 0.3686994025
Iteration 7384 => Loss: 0.3686982092
Iteration 7385 => Loss: 0.3686970159
Iteration 7386 => Loss: 0.3686958227
Iteration 7387 => Loss: 0.3686946296
Iteration 7388 => Loss: 0.3686934365
Iteration 7389 => Loss: 0.3686922435
Iteration 7390 => Loss: 0.3686910506
Iteration 7391 => Loss: 0.3686898577
Iteration 7392 => Loss: 0.3686886649
Iteration 7393 => Loss: 0.3686874722
Iteration 7394 => Loss: 0.3686862796
Iteration 7395 => Loss: 0.3686850870
Iteration 7396 => Loss: 0.3686838945
Iteration 7397 => Loss: 0.3686827020
Iteration 7398 => Loss: 0.3686815097
Iteration 7399 => Loss: 0.3686803174
Iteration 7400 => Loss: 0.3686791252
Iteration 7401 => Loss: 0.3686779330
Iteration 7402 => Loss: 0.3686767409
Iteration 7403 => Loss: 0.3686755489
Iteration 7404 => Loss: 0.3686743569
Iteration 7405 => Loss: 0.3686731650
Iteration 7406 => Loss: 0.3686719732
Iteration 7407 => Loss: 0.3686707815
Iteration 7408 => Loss: 0.3686695898
Iteration 7409 => Loss: 0.3686683982
Iteration 7410 => Loss: 0.3686672067
Iteration 7411 => Loss: 0.3686660152
Iteration 7412 => Loss: 0.3686648238
Iteration 7413 => Loss: 0.3686636325
Iteration 7414 => Loss: 0.3686624412
Iteration 7415 => Loss: 0.3686612500
Iteration 7416 => Loss: 0.3686600589
Iteration 7417 => Loss: 0.3686588679
Iteration 7418 => Loss: 0.3686576769
Iteration 7419 => Loss: 0.3686564860
Iteration 7420 => Loss: 0.3686552951
Iteration 7421 => Loss: 0.3686541043
Iteration 7422 => Loss: 0.3686529136
Iteration 7423 => Loss: 0.3686517230
Iteration 7424 => Loss: 0.3686505324
Iteration 7425 => Loss: 0.3686493419
Iteration 7426 => Loss: 0.3686481515
Iteration 7427 => Loss: 0.3686469611
Iteration 7428 => Loss: 0.3686457708
Iteration 7429 => Loss: 0.3686445806
Iteration 7430 => Loss: 0.3686433904
Iteration 7431 => Loss: 0.3686422003
Iteration 7432 => Loss: 0.3686410103
Iteration 7433 => Loss: 0.3686398203
Iteration 7434 => Loss: 0.3686386304
Iteration 7435 => Loss: 0.3686374406
Iteration 7436 => Loss: 0.3686362509
Iteration 7437 => Loss: 0.3686350612
Iteration 7438 => Loss: 0.3686338716
Iteration 7439 => Loss: 0.3686326820
Iteration 7440 => Loss: 0.3686314925
Iteration 7441 => Loss: 0.3686303031
Iteration 7442 => Loss: 0.3686291138
Iteration 7443 => Loss: 0.3686279245
Iteration 7444 => Loss: 0.3686267353
Iteration 7445 => Loss: 0.3686255461
Iteration 7446 => Loss: 0.3686243570
Iteration 7447 => Loss: 0.3686231680
Iteration 7448 => Loss: 0.3686219791
Iteration 7449 => Loss: 0.3686207902
Iteration 7450 => Loss: 0.3686196014
Iteration 7451 => Loss: 0.3686184127
Iteration 7452 => Loss: 0.3686172240
Iteration 7453 => Loss: 0.3686160354
Iteration 7454 => Loss: 0.3686148469
Iteration 7455 => Loss: 0.3686136584
Iteration 7456 => Loss: 0.3686124700
Iteration 7457 => Loss: 0.3686112816
Iteration 7458 => Loss: 0.3686100934
Iteration 7459 => Loss: 0.3686089052
Iteration 7460 => Loss: 0.3686077170
Iteration 7461 => Loss: 0.3686065290
Iteration 7462 => Loss: 0.3686053409
Iteration 7463 => Loss: 0.3686041530
Iteration 7464 => Loss: 0.3686029651
Iteration 7465 => Loss: 0.3686017773
Iteration 7466 => Loss: 0.3686005896
Iteration 7467 => Loss: 0.3685994019
Iteration 7468 => Loss: 0.3685982143
Iteration 7469 => Loss: 0.3685970268
Iteration 7470 => Loss: 0.3685958393
Iteration 7471 => Loss: 0.3685946519
Iteration 7472 => Loss: 0.3685934646
Iteration 7473 => Loss: 0.3685922773
Iteration 7474 => Loss: 0.3685910901
Iteration 7475 => Loss: 0.3685899030
Iteration 7476 => Loss: 0.3685887159
Iteration 7477 => Loss: 0.3685875289
Iteration 7478 => Loss: 0.3685863419
Iteration 7479 => Loss: 0.3685851551
Iteration 7480 => Loss: 0.3685839683
Iteration 7481 => Loss: 0.3685827815
Iteration 7482 => Loss: 0.3685815948
Iteration 7483 => Loss: 0.3685804082
Iteration 7484 => Loss: 0.3685792217
Iteration 7485 => Loss: 0.3685780352
Iteration 7486 => Loss: 0.3685768488
Iteration 7487 => Loss: 0.3685756624
Iteration 7488 => Loss: 0.3685744762
Iteration 7489 => Loss: 0.3685732899
Iteration 7490 => Loss: 0.3685721038
Iteration 7491 => Loss: 0.3685709177
Iteration 7492 => Loss: 0.3685697317
Iteration 7493 => Loss: 0.3685685457
Iteration 7494 => Loss: 0.3685673598
Iteration 7495 => Loss: 0.3685661740
Iteration 7496 => Loss: 0.3685649883
Iteration 7497 => Loss: 0.3685638026
Iteration 7498 => Loss: 0.3685626169
Iteration 7499 => Loss: 0.3685614314
Iteration 7500 => Loss: 0.3685602459
Iteration 7501 => Loss: 0.3685590604
Iteration 7502 => Loss: 0.3685578751
Iteration 7503 => Loss: 0.3685566898
Iteration 7504 => Loss: 0.3685555045
Iteration 7505 => Loss: 0.3685543194
Iteration 7506 => Loss: 0.3685531343
Iteration 7507 => Loss: 0.3685519492
Iteration 7508 => Loss: 0.3685507642
Iteration 7509 => Loss: 0.3685495793
Iteration 7510 => Loss: 0.3685483945
Iteration 7511 => Loss: 0.3685472097
Iteration 7512 => Loss: 0.3685460250
Iteration 7513 => Loss: 0.3685448403
Iteration 7514 => Loss: 0.3685436557
Iteration 7515 => Loss: 0.3685424712
Iteration 7516 => Loss: 0.3685412867
Iteration 7517 => Loss: 0.3685401023
Iteration 7518 => Loss: 0.3685389180
Iteration 7519 => Loss: 0.3685377337
Iteration 7520 => Loss: 0.3685365495
Iteration 7521 => Loss: 0.3685353654
Iteration 7522 => Loss: 0.3685341813
Iteration 7523 => Loss: 0.3685329973
Iteration 7524 => Loss: 0.3685318134
Iteration 7525 => Loss: 0.3685306295
Iteration 7526 => Loss: 0.3685294457
Iteration 7527 => Loss: 0.3685282619
Iteration 7528 => Loss: 0.3685270782
Iteration 7529 => Loss: 0.3685258946
Iteration 7530 => Loss: 0.3685247110
Iteration 7531 => Loss: 0.3685235275
Iteration 7532 => Loss: 0.3685223441
Iteration 7533 => Loss: 0.3685211607
Iteration 7534 => Loss: 0.3685199774
Iteration 7535 => Loss: 0.3685187942
Iteration 7536 => Loss: 0.3685176110
Iteration 7537 => Loss: 0.3685164279
Iteration 7538 => Loss: 0.3685152448
Iteration 7539 => Loss: 0.3685140618
Iteration 7540 => Loss: 0.3685128789
Iteration 7541 => Loss: 0.3685116960
Iteration 7542 => Loss: 0.3685105132
Iteration 7543 => Loss: 0.3685093305
Iteration 7544 => Loss: 0.3685081478
Iteration 7545 => Loss: 0.3685069652
Iteration 7546 => Loss: 0.3685057827
Iteration 7547 => Loss: 0.3685046002
Iteration 7548 => Loss: 0.3685034177
Iteration 7549 => Loss: 0.3685022354
Iteration 7550 => Loss: 0.3685010531
Iteration 7551 => Loss: 0.3684998709
Iteration 7552 => Loss: 0.3684986887
Iteration 7553 => Loss: 0.3684975066
Iteration 7554 => Loss: 0.3684963245
Iteration 7555 => Loss: 0.3684951426
Iteration 7556 => Loss: 0.3684939607
Iteration 7557 => Loss: 0.3684927788
Iteration 7558 => Loss: 0.3684915970
Iteration 7559 => Loss: 0.3684904153
Iteration 7560 => Loss: 0.3684892336
Iteration 7561 => Loss: 0.3684880520
Iteration 7562 => Loss: 0.3684868705
Iteration 7563 => Loss: 0.3684856890
Iteration 7564 => Loss: 0.3684845076
Iteration 7565 => Loss: 0.3684833262
Iteration 7566 => Loss: 0.3684821449
Iteration 7567 => Loss: 0.3684809637
Iteration 7568 => Loss: 0.3684797825
Iteration 7569 => Loss: 0.3684786014
Iteration 7570 => Loss: 0.3684774204
Iteration 7571 => Loss: 0.3684762394
Iteration 7572 => Loss: 0.3684750585
Iteration 7573 => Loss: 0.3684738776
Iteration 7574 => Loss: 0.3684726968
Iteration 7575 => Loss: 0.3684715161
Iteration 7576 => Loss: 0.3684703354
Iteration 7577 => Loss: 0.3684691548
Iteration 7578 => Loss: 0.3684679743
Iteration 7579 => Loss: 0.3684667938
Iteration 7580 => Loss: 0.3684656134
Iteration 7581 => Loss: 0.3684644330
Iteration 7582 => Loss: 0.3684632527
Iteration 7583 => Loss: 0.3684620725
Iteration 7584 => Loss: 0.3684608923
Iteration 7585 => Loss: 0.3684597122
Iteration 7586 => Loss: 0.3684585321
Iteration 7587 => Loss: 0.3684573521
Iteration 7588 => Loss: 0.3684561722
Iteration 7589 => Loss: 0.3684549924
Iteration 7590 => Loss: 0.3684538125
Iteration 7591 => Loss: 0.3684526328
Iteration 7592 => Loss: 0.3684514531
Iteration 7593 => Loss: 0.3684502735
Iteration 7594 => Loss: 0.3684490939
Iteration 7595 => Loss: 0.3684479144
Iteration 7596 => Loss: 0.3684467350
Iteration 7597 => Loss: 0.3684455556
Iteration 7598 => Loss: 0.3684443763
Iteration 7599 => Loss: 0.3684431971
Iteration 7600 => Loss: 0.3684420179
Iteration 7601 => Loss: 0.3684408387
Iteration 7602 => Loss: 0.3684396597
Iteration 7603 => Loss: 0.3684384806
Iteration 7604 => Loss: 0.3684373017
Iteration 7605 => Loss: 0.3684361228
Iteration 7606 => Loss: 0.3684349440
Iteration 7607 => Loss: 0.3684337652
Iteration 7608 => Loss: 0.3684325865
Iteration 7609 => Loss: 0.3684314079
Iteration 7610 => Loss: 0.3684302293
Iteration 7611 => Loss: 0.3684290507
Iteration 7612 => Loss: 0.3684278723
Iteration 7613 => Loss: 0.3684266939
Iteration 7614 => Loss: 0.3684255155
Iteration 7615 => Loss: 0.3684243372
Iteration 7616 => Loss: 0.3684231590
Iteration 7617 => Loss: 0.3684219809
Iteration 7618 => Loss: 0.3684208028
Iteration 7619 => Loss: 0.3684196247
Iteration 7620 => Loss: 0.3684184467
Iteration 7621 => Loss: 0.3684172688
Iteration 7622 => Loss: 0.3684160910
Iteration 7623 => Loss: 0.3684149132
Iteration 7624 => Loss: 0.3684137354
Iteration 7625 => Loss: 0.3684125577
Iteration 7626 => Loss: 0.3684113801
Iteration 7627 => Loss: 0.3684102026
Iteration 7628 => Loss: 0.3684090251
Iteration 7629 => Loss: 0.3684078476
Iteration 7630 => Loss: 0.3684066702
Iteration 7631 => Loss: 0.3684054929
Iteration 7632 => Loss: 0.3684043156
Iteration 7633 => Loss: 0.3684031384
Iteration 7634 => Loss: 0.3684019613
Iteration 7635 => Loss: 0.3684007842
Iteration 7636 => Loss: 0.3683996072
Iteration 7637 => Loss: 0.3683984302
Iteration 7638 => Loss: 0.3683972533
Iteration 7639 => Loss: 0.3683960765
Iteration 7640 => Loss: 0.3683948997
Iteration 7641 => Loss: 0.3683937230
Iteration 7642 => Loss: 0.3683925463
Iteration 7643 => Loss: 0.3683913697
Iteration 7644 => Loss: 0.3683901932
Iteration 7645 => Loss: 0.3683890167
Iteration 7646 => Loss: 0.3683878402
Iteration 7647 => Loss: 0.3683866639
Iteration 7648 => Loss: 0.3683854876
Iteration 7649 => Loss: 0.3683843113
Iteration 7650 => Loss: 0.3683831351
Iteration 7651 => Loss: 0.3683819590
Iteration 7652 => Loss: 0.3683807829
Iteration 7653 => Loss: 0.3683796069
Iteration 7654 => Loss: 0.3683784310
Iteration 7655 => Loss: 0.3683772551
Iteration 7656 => Loss: 0.3683760792
Iteration 7657 => Loss: 0.3683749034
Iteration 7658 => Loss: 0.3683737277
Iteration 7659 => Loss: 0.3683725521
Iteration 7660 => Loss: 0.3683713765
Iteration 7661 => Loss: 0.3683702009
Iteration 7662 => Loss: 0.3683690254
Iteration 7663 => Loss: 0.3683678500
Iteration 7664 => Loss: 0.3683666746
Iteration 7665 => Loss: 0.3683654993
Iteration 7666 => Loss: 0.3683643241
Iteration 7667 => Loss: 0.3683631489
Iteration 7668 => Loss: 0.3683619737
Iteration 7669 => Loss: 0.3683607987
Iteration 7670 => Loss: 0.3683596237
Iteration 7671 => Loss: 0.3683584487
Iteration 7672 => Loss: 0.3683572738
Iteration 7673 => Loss: 0.3683560989
Iteration 7674 => Loss: 0.3683549242
Iteration 7675 => Loss: 0.3683537494
Iteration 7676 => Loss: 0.3683525748
Iteration 7677 => Loss: 0.3683514002
Iteration 7678 => Loss: 0.3683502256
Iteration 7679 => Loss: 0.3683490511
Iteration 7680 => Loss: 0.3683478767
Iteration 7681 => Loss: 0.3683467023
Iteration 7682 => Loss: 0.3683455280
Iteration 7683 => Loss: 0.3683443537
Iteration 7684 => Loss: 0.3683431795
Iteration 7685 => Loss: 0.3683420054
Iteration 7686 => Loss: 0.3683408313
Iteration 7687 => Loss: 0.3683396573
Iteration 7688 => Loss: 0.3683384833
Iteration 7689 => Loss: 0.3683373094
Iteration 7690 => Loss: 0.3683361355
Iteration 7691 => Loss: 0.3683349617
Iteration 7692 => Loss: 0.3683337880
Iteration 7693 => Loss: 0.3683326143
Iteration 7694 => Loss: 0.3683314406
Iteration 7695 => Loss: 0.3683302671
Iteration 7696 => Loss: 0.3683290936
Iteration 7697 => Loss: 0.3683279201
Iteration 7698 => Loss: 0.3683267467
Iteration 7699 => Loss: 0.3683255734
Iteration 7700 => Loss: 0.3683244001
Iteration 7701 => Loss: 0.3683232269
Iteration 7702 => Loss: 0.3683220537
Iteration 7703 => Loss: 0.3683208806
Iteration 7704 => Loss: 0.3683197075
Iteration 7705 => Loss: 0.3683185345
Iteration 7706 => Loss: 0.3683173616
Iteration 7707 => Loss: 0.3683161887
Iteration 7708 => Loss: 0.3683150159
Iteration 7709 => Loss: 0.3683138431
Iteration 7710 => Loss: 0.3683126704
Iteration 7711 => Loss: 0.3683114977
Iteration 7712 => Loss: 0.3683103251
Iteration 7713 => Loss: 0.3683091526
Iteration 7714 => Loss: 0.3683079801
Iteration 7715 => Loss: 0.3683068077
Iteration 7716 => Loss: 0.3683056353
Iteration 7717 => Loss: 0.3683044630
Iteration 7718 => Loss: 0.3683032907
Iteration 7719 => Loss: 0.3683021185
Iteration 7720 => Loss: 0.3683009464
Iteration 7721 => Loss: 0.3682997743
Iteration 7722 => Loss: 0.3682986023
Iteration 7723 => Loss: 0.3682974303
Iteration 7724 => Loss: 0.3682962584
Iteration 7725 => Loss: 0.3682950865
Iteration 7726 => Loss: 0.3682939147
Iteration 7727 => Loss: 0.3682927429
Iteration 7728 => Loss: 0.3682915712
Iteration 7729 => Loss: 0.3682903996
Iteration 7730 => Loss: 0.3682892280
Iteration 7731 => Loss: 0.3682880565
Iteration 7732 => Loss: 0.3682868850
Iteration 7733 => Loss: 0.3682857136
Iteration 7734 => Loss: 0.3682845422
Iteration 7735 => Loss: 0.3682833709
Iteration 7736 => Loss: 0.3682821997
Iteration 7737 => Loss: 0.3682810285
Iteration 7738 => Loss: 0.3682798574
Iteration 7739 => Loss: 0.3682786863
Iteration 7740 => Loss: 0.3682775153
Iteration 7741 => Loss: 0.3682763443
Iteration 7742 => Loss: 0.3682751734
Iteration 7743 => Loss: 0.3682740025
Iteration 7744 => Loss: 0.3682728317
Iteration 7745 => Loss: 0.3682716610
Iteration 7746 => Loss: 0.3682704903
Iteration 7747 => Loss: 0.3682693197
Iteration 7748 => Loss: 0.3682681491
Iteration 7749 => Loss: 0.3682669786
Iteration 7750 => Loss: 0.3682658081
Iteration 7751 => Loss: 0.3682646377
Iteration 7752 => Loss: 0.3682634673
Iteration 7753 => Loss: 0.3682622970
Iteration 7754 => Loss: 0.3682611268
Iteration 7755 => Loss: 0.3682599566
Iteration 7756 => Loss: 0.3682587864
Iteration 7757 => Loss: 0.3682576164
Iteration 7758 => Loss: 0.3682564463
Iteration 7759 => Loss: 0.3682552764
Iteration 7760 => Loss: 0.3682541065
Iteration 7761 => Loss: 0.3682529366
Iteration 7762 => Loss: 0.3682517668
Iteration 7763 => Loss: 0.3682505970
Iteration 7764 => Loss: 0.3682494274
Iteration 7765 => Loss: 0.3682482577
Iteration 7766 => Loss: 0.3682470881
Iteration 7767 => Loss: 0.3682459186
Iteration 7768 => Loss: 0.3682447491
Iteration 7769 => Loss: 0.3682435797
Iteration 7770 => Loss: 0.3682424103
Iteration 7771 => Loss: 0.3682412410
Iteration 7772 => Loss: 0.3682400718
Iteration 7773 => Loss: 0.3682389026
Iteration 7774 => Loss: 0.3682377334
Iteration 7775 => Loss: 0.3682365643
Iteration 7776 => Loss: 0.3682353953
Iteration 7777 => Loss: 0.3682342263
Iteration 7778 => Loss: 0.3682330574
Iteration 7779 => Loss: 0.3682318885
Iteration 7780 => Loss: 0.3682307197
Iteration 7781 => Loss: 0.3682295509
Iteration 7782 => Loss: 0.3682283822
Iteration 7783 => Loss: 0.3682272136
Iteration 7784 => Loss: 0.3682260450
Iteration 7785 => Loss: 0.3682248764
Iteration 7786 => Loss: 0.3682237079
Iteration 7787 => Loss: 0.3682225395
Iteration 7788 => Loss: 0.3682213711
Iteration 7789 => Loss: 0.3682202028
Iteration 7790 => Loss: 0.3682190345
Iteration 7791 => Loss: 0.3682178663
Iteration 7792 => Loss: 0.3682166981
Iteration 7793 => Loss: 0.3682155300
Iteration 7794 => Loss: 0.3682143619
Iteration 7795 => Loss: 0.3682131939
Iteration 7796 => Loss: 0.3682120260
Iteration 7797 => Loss: 0.3682108581
Iteration 7798 => Loss: 0.3682096902
Iteration 7799 => Loss: 0.3682085224
Iteration 7800 => Loss: 0.3682073547
Iteration 7801 => Loss: 0.3682061870
Iteration 7802 => Loss: 0.3682050194
Iteration 7803 => Loss: 0.3682038518
Iteration 7804 => Loss: 0.3682026843
Iteration 7805 => Loss: 0.3682015168
Iteration 7806 => Loss: 0.3682003494
Iteration 7807 => Loss: 0.3681991820
Iteration 7808 => Loss: 0.3681980147
Iteration 7809 => Loss: 0.3681968475
Iteration 7810 => Loss: 0.3681956803
Iteration 7811 => Loss: 0.3681945131
Iteration 7812 => Loss: 0.3681933460
Iteration 7813 => Loss: 0.3681921790
Iteration 7814 => Loss: 0.3681910120
Iteration 7815 => Loss: 0.3681898450
Iteration 7816 => Loss: 0.3681886782
Iteration 7817 => Loss: 0.3681875113
Iteration 7818 => Loss: 0.3681863446
Iteration 7819 => Loss: 0.3681851778
Iteration 7820 => Loss: 0.3681840112
Iteration 7821 => Loss: 0.3681828446
Iteration 7822 => Loss: 0.3681816780
Iteration 7823 => Loss: 0.3681805115
Iteration 7824 => Loss: 0.3681793450
Iteration 7825 => Loss: 0.3681781786
Iteration 7826 => Loss: 0.3681770123
Iteration 7827 => Loss: 0.3681758460
Iteration 7828 => Loss: 0.3681746797
Iteration 7829 => Loss: 0.3681735135
Iteration 7830 => Loss: 0.3681723474
Iteration 7831 => Loss: 0.3681711813
Iteration 7832 => Loss: 0.3681700153
Iteration 7833 => Loss: 0.3681688493
Iteration 7834 => Loss: 0.3681676833
Iteration 7835 => Loss: 0.3681665175
Iteration 7836 => Loss: 0.3681653516
Iteration 7837 => Loss: 0.3681641859
Iteration 7838 => Loss: 0.3681630202
Iteration 7839 => Loss: 0.3681618545
Iteration 7840 => Loss: 0.3681606889
Iteration 7841 => Loss: 0.3681595233
Iteration 7842 => Loss: 0.3681583578
Iteration 7843 => Loss: 0.3681571923
Iteration 7844 => Loss: 0.3681560269
Iteration 7845 => Loss: 0.3681548616
Iteration 7846 => Loss: 0.3681536963
Iteration 7847 => Loss: 0.3681525310
Iteration 7848 => Loss: 0.3681513658
Iteration 7849 => Loss: 0.3681502007
Iteration 7850 => Loss: 0.3681490356
Iteration 7851 => Loss: 0.3681478706
Iteration 7852 => Loss: 0.3681467056
Iteration 7853 => Loss: 0.3681455406
Iteration 7854 => Loss: 0.3681443757
Iteration 7855 => Loss: 0.3681432109
Iteration 7856 => Loss: 0.3681420461
Iteration 7857 => Loss: 0.3681408814
Iteration 7858 => Loss: 0.3681397167
Iteration 7859 => Loss: 0.3681385521
Iteration 7860 => Loss: 0.3681373875
Iteration 7861 => Loss: 0.3681362230
Iteration 7862 => Loss: 0.3681350585
Iteration 7863 => Loss: 0.3681338941
Iteration 7864 => Loss: 0.3681327298
Iteration 7865 => Loss: 0.3681315654
Iteration 7866 => Loss: 0.3681304012
Iteration 7867 => Loss: 0.3681292370
Iteration 7868 => Loss: 0.3681280728
Iteration 7869 => Loss: 0.3681269087
Iteration 7870 => Loss: 0.3681257446
Iteration 7871 => Loss: 0.3681245806
Iteration 7872 => Loss: 0.3681234167
Iteration 7873 => Loss: 0.3681222528
Iteration 7874 => Loss: 0.3681210889
Iteration 7875 => Loss: 0.3681199251
Iteration 7876 => Loss: 0.3681187614
Iteration 7877 => Loss: 0.3681175977
Iteration 7878 => Loss: 0.3681164340
Iteration 7879 => Loss: 0.3681152704
Iteration 7880 => Loss: 0.3681141069
Iteration 7881 => Loss: 0.3681129434
Iteration 7882 => Loss: 0.3681117800
Iteration 7883 => Loss: 0.3681106166
Iteration 7884 => Loss: 0.3681094532
Iteration 7885 => Loss: 0.3681082899
Iteration 7886 => Loss: 0.3681071267
Iteration 7887 => Loss: 0.3681059635
Iteration 7888 => Loss: 0.3681048004
Iteration 7889 => Loss: 0.3681036373
Iteration 7890 => Loss: 0.3681024743
Iteration 7891 => Loss: 0.3681013113
Iteration 7892 => Loss: 0.3681001483
Iteration 7893 => Loss: 0.3680989855
Iteration 7894 => Loss: 0.3680978226
Iteration 7895 => Loss: 0.3680966598
Iteration 7896 => Loss: 0.3680954971
Iteration 7897 => Loss: 0.3680943344
Iteration 7898 => Loss: 0.3680931718
Iteration 7899 => Loss: 0.3680920092
Iteration 7900 => Loss: 0.3680908467
Iteration 7901 => Loss: 0.3680896842
Iteration 7902 => Loss: 0.3680885218
Iteration 7903 => Loss: 0.3680873594
Iteration 7904 => Loss: 0.3680861971
Iteration 7905 => Loss: 0.3680850348
Iteration 7906 => Loss: 0.3680838726
Iteration 7907 => Loss: 0.3680827104
Iteration 7908 => Loss: 0.3680815483
Iteration 7909 => Loss: 0.3680803862
Iteration 7910 => Loss: 0.3680792242
Iteration 7911 => Loss: 0.3680780622
Iteration 7912 => Loss: 0.3680769003
Iteration 7913 => Loss: 0.3680757384
Iteration 7914 => Loss: 0.3680745766
Iteration 7915 => Loss: 0.3680734148
Iteration 7916 => Loss: 0.3680722531
Iteration 7917 => Loss: 0.3680710914
Iteration 7918 => Loss: 0.3680699298
Iteration 7919 => Loss: 0.3680687682
Iteration 7920 => Loss: 0.3680676067
Iteration 7921 => Loss: 0.3680664452
Iteration 7922 => Loss: 0.3680652838
Iteration 7923 => Loss: 0.3680641224
Iteration 7924 => Loss: 0.3680629611
Iteration 7925 => Loss: 0.3680617998
Iteration 7926 => Loss: 0.3680606386
Iteration 7927 => Loss: 0.3680594774
Iteration 7928 => Loss: 0.3680583163
Iteration 7929 => Loss: 0.3680571552
Iteration 7930 => Loss: 0.3680559942
Iteration 7931 => Loss: 0.3680548332
Iteration 7932 => Loss: 0.3680536723
Iteration 7933 => Loss: 0.3680525114
Iteration 7934 => Loss: 0.3680513506
Iteration 7935 => Loss: 0.3680501898
Iteration 7936 => Loss: 0.3680490291
Iteration 7937 => Loss: 0.3680478684
Iteration 7938 => Loss: 0.3680467078
Iteration 7939 => Loss: 0.3680455472
Iteration 7940 => Loss: 0.3680443867
Iteration 7941 => Loss: 0.3680432262
Iteration 7942 => Loss: 0.3680420657
Iteration 7943 => Loss: 0.3680409054
Iteration 7944 => Loss: 0.3680397450
Iteration 7945 => Loss: 0.3680385847
Iteration 7946 => Loss: 0.3680374245
Iteration 7947 => Loss: 0.3680362643
Iteration 7948 => Loss: 0.3680351042
Iteration 7949 => Loss: 0.3680339441
Iteration 7950 => Loss: 0.3680327840
Iteration 7951 => Loss: 0.3680316240
Iteration 7952 => Loss: 0.3680304641
Iteration 7953 => Loss: 0.3680293042
Iteration 7954 => Loss: 0.3680281444
Iteration 7955 => Loss: 0.3680269846
Iteration 7956 => Loss: 0.3680258248
Iteration 7957 => Loss: 0.3680246651
Iteration 7958 => Loss: 0.3680235055
Iteration 7959 => Loss: 0.3680223459
Iteration 7960 => Loss: 0.3680211863
Iteration 7961 => Loss: 0.3680200268
Iteration 7962 => Loss: 0.3680188674
Iteration 7963 => Loss: 0.3680177079
Iteration 7964 => Loss: 0.3680165486
Iteration 7965 => Loss: 0.3680153893
Iteration 7966 => Loss: 0.3680142300
Iteration 7967 => Loss: 0.3680130708
Iteration 7968 => Loss: 0.3680119116
Iteration 7969 => Loss: 0.3680107525
Iteration 7970 => Loss: 0.3680095935
Iteration 7971 => Loss: 0.3680084344
Iteration 7972 => Loss: 0.3680072755
Iteration 7973 => Loss: 0.3680061166
Iteration 7974 => Loss: 0.3680049577
Iteration 7975 => Loss: 0.3680037989
Iteration 7976 => Loss: 0.3680026401
Iteration 7977 => Loss: 0.3680014813
Iteration 7978 => Loss: 0.3680003227
Iteration 7979 => Loss: 0.3679991640
Iteration 7980 => Loss: 0.3679980054
Iteration 7981 => Loss: 0.3679968469
Iteration 7982 => Loss: 0.3679956884
Iteration 7983 => Loss: 0.3679945300
Iteration 7984 => Loss: 0.3679933716
Iteration 7985 => Loss: 0.3679922132
Iteration 7986 => Loss: 0.3679910549
Iteration 7987 => Loss: 0.3679898967
Iteration 7988 => Loss: 0.3679887385
Iteration 7989 => Loss: 0.3679875803
Iteration 7990 => Loss: 0.3679864222
Iteration 7991 => Loss: 0.3679852642
Iteration 7992 => Loss: 0.3679841062
Iteration 7993 => Loss: 0.3679829482
Iteration 7994 => Loss: 0.3679817903
Iteration 7995 => Loss: 0.3679806324
Iteration 7996 => Loss: 0.3679794746
Iteration 7997 => Loss: 0.3679783168
Iteration 7998 => Loss: 0.3679771591
Iteration 7999 => Loss: 0.3679760014
Iteration 8000 => Loss: 0.3679748438
Iteration 8001 => Loss: 0.3679736862
Iteration 8002 => Loss: 0.3679725287
Iteration 8003 => Loss: 0.3679713712
Iteration 8004 => Loss: 0.3679702138
Iteration 8005 => Loss: 0.3679690564
Iteration 8006 => Loss: 0.3679678990
Iteration 8007 => Loss: 0.3679667417
Iteration 8008 => Loss: 0.3679655845
Iteration 8009 => Loss: 0.3679644273
Iteration 8010 => Loss: 0.3679632701
Iteration 8011 => Loss: 0.3679621130
Iteration 8012 => Loss: 0.3679609560
Iteration 8013 => Loss: 0.3679597990
Iteration 8014 => Loss: 0.3679586420
Iteration 8015 => Loss: 0.3679574851
Iteration 8016 => Loss: 0.3679563282
Iteration 8017 => Loss: 0.3679551714
Iteration 8018 => Loss: 0.3679540146
Iteration 8019 => Loss: 0.3679528579
Iteration 8020 => Loss: 0.3679517012
Iteration 8021 => Loss: 0.3679505445
Iteration 8022 => Loss: 0.3679493880
Iteration 8023 => Loss: 0.3679482314
Iteration 8024 => Loss: 0.3679470749
Iteration 8025 => Loss: 0.3679459185
Iteration 8026 => Loss: 0.3679447621
Iteration 8027 => Loss: 0.3679436057
Iteration 8028 => Loss: 0.3679424494
Iteration 8029 => Loss: 0.3679412931
Iteration 8030 => Loss: 0.3679401369
Iteration 8031 => Loss: 0.3679389807
Iteration 8032 => Loss: 0.3679378246
Iteration 8033 => Loss: 0.3679366686
Iteration 8034 => Loss: 0.3679355125
Iteration 8035 => Loss: 0.3679343565
Iteration 8036 => Loss: 0.3679332006
Iteration 8037 => Loss: 0.3679320447
Iteration 8038 => Loss: 0.3679308889
Iteration 8039 => Loss: 0.3679297331
Iteration 8040 => Loss: 0.3679285773
Iteration 8041 => Loss: 0.3679274216
Iteration 8042 => Loss: 0.3679262660
Iteration 8043 => Loss: 0.3679251103
Iteration 8044 => Loss: 0.3679239548
Iteration 8045 => Loss: 0.3679227993
Iteration 8046 => Loss: 0.3679216438
Iteration 8047 => Loss: 0.3679204884
Iteration 8048 => Loss: 0.3679193330
Iteration 8049 => Loss: 0.3679181777
Iteration 8050 => Loss: 0.3679170224
Iteration 8051 => Loss: 0.3679158671
Iteration 8052 => Loss: 0.3679147119
Iteration 8053 => Loss: 0.3679135568
Iteration 8054 => Loss: 0.3679124017
Iteration 8055 => Loss: 0.3679112466
Iteration 8056 => Loss: 0.3679100916
Iteration 8057 => Loss: 0.3679089366
Iteration 8058 => Loss: 0.3679077817
Iteration 8059 => Loss: 0.3679066268
Iteration 8060 => Loss: 0.3679054720
Iteration 8061 => Loss: 0.3679043172
Iteration 8062 => Loss: 0.3679031625
Iteration 8063 => Loss: 0.3679020078
Iteration 8064 => Loss: 0.3679008532
Iteration 8065 => Loss: 0.3678996986
Iteration 8066 => Loss: 0.3678985440
Iteration 8067 => Loss: 0.3678973895
Iteration 8068 => Loss: 0.3678962350
Iteration 8069 => Loss: 0.3678950806
Iteration 8070 => Loss: 0.3678939263
Iteration 8071 => Loss: 0.3678927719
Iteration 8072 => Loss: 0.3678916176
Iteration 8073 => Loss: 0.3678904634
Iteration 8074 => Loss: 0.3678893092
Iteration 8075 => Loss: 0.3678881551
Iteration 8076 => Loss: 0.3678870010
Iteration 8077 => Loss: 0.3678858469
Iteration 8078 => Loss: 0.3678846929
Iteration 8079 => Loss: 0.3678835390
Iteration 8080 => Loss: 0.3678823850
Iteration 8081 => Loss: 0.3678812312
Iteration 8082 => Loss: 0.3678800773
Iteration 8083 => Loss: 0.3678789236
Iteration 8084 => Loss: 0.3678777698
Iteration 8085 => Loss: 0.3678766161
Iteration 8086 => Loss: 0.3678754625
Iteration 8087 => Loss: 0.3678743089
Iteration 8088 => Loss: 0.3678731553
Iteration 8089 => Loss: 0.3678720018
Iteration 8090 => Loss: 0.3678708484
Iteration 8091 => Loss: 0.3678696949
Iteration 8092 => Loss: 0.3678685416
Iteration 8093 => Loss: 0.3678673882
Iteration 8094 => Loss: 0.3678662350
Iteration 8095 => Loss: 0.3678650817
Iteration 8096 => Loss: 0.3678639285
Iteration 8097 => Loss: 0.3678627754
Iteration 8098 => Loss: 0.3678616223
Iteration 8099 => Loss: 0.3678604692
Iteration 8100 => Loss: 0.3678593162
Iteration 8101 => Loss: 0.3678581632
Iteration 8102 => Loss: 0.3678570103
Iteration 8103 => Loss: 0.3678558574
Iteration 8104 => Loss: 0.3678547046
Iteration 8105 => Loss: 0.3678535518
Iteration 8106 => Loss: 0.3678523990
Iteration 8107 => Loss: 0.3678512463
Iteration 8108 => Loss: 0.3678500937
Iteration 8109 => Loss: 0.3678489410
Iteration 8110 => Loss: 0.3678477885
Iteration 8111 => Loss: 0.3678466360
Iteration 8112 => Loss: 0.3678454835
Iteration 8113 => Loss: 0.3678443310
Iteration 8114 => Loss: 0.3678431786
Iteration 8115 => Loss: 0.3678420263
Iteration 8116 => Loss: 0.3678408740
Iteration 8117 => Loss: 0.3678397217
Iteration 8118 => Loss: 0.3678385695
Iteration 8119 => Loss: 0.3678374174
Iteration 8120 => Loss: 0.3678362652
Iteration 8121 => Loss: 0.3678351131
Iteration 8122 => Loss: 0.3678339611
Iteration 8123 => Loss: 0.3678328091
Iteration 8124 => Loss: 0.3678316572
Iteration 8125 => Loss: 0.3678305053
Iteration 8126 => Loss: 0.3678293534
Iteration 8127 => Loss: 0.3678282016
Iteration 8128 => Loss: 0.3678270498
Iteration 8129 => Loss: 0.3678258981
Iteration 8130 => Loss: 0.3678247464
Iteration 8131 => Loss: 0.3678235948
Iteration 8132 => Loss: 0.3678224432
Iteration 8133 => Loss: 0.3678212916
Iteration 8134 => Loss: 0.3678201401
Iteration 8135 => Loss: 0.3678189886
Iteration 8136 => Loss: 0.3678178372
Iteration 8137 => Loss: 0.3678166858
Iteration 8138 => Loss: 0.3678155345
Iteration 8139 => Loss: 0.3678143832
Iteration 8140 => Loss: 0.3678132320
Iteration 8141 => Loss: 0.3678120808
Iteration 8142 => Loss: 0.3678109296
Iteration 8143 => Loss: 0.3678097785
Iteration 8144 => Loss: 0.3678086274
Iteration 8145 => Loss: 0.3678074764
Iteration 8146 => Loss: 0.3678063254
Iteration 8147 => Loss: 0.3678051745
Iteration 8148 => Loss: 0.3678040236
Iteration 8149 => Loss: 0.3678028727
Iteration 8150 => Loss: 0.3678017219
Iteration 8151 => Loss: 0.3678005711
Iteration 8152 => Loss: 0.3677994204
Iteration 8153 => Loss: 0.3677982697
Iteration 8154 => Loss: 0.3677971191
Iteration 8155 => Loss: 0.3677959685
Iteration 8156 => Loss: 0.3677948179
Iteration 8157 => Loss: 0.3677936674
Iteration 8158 => Loss: 0.3677925170
Iteration 8159 => Loss: 0.3677913665
Iteration 8160 => Loss: 0.3677902162
Iteration 8161 => Loss: 0.3677890658
Iteration 8162 => Loss: 0.3677879155
Iteration 8163 => Loss: 0.3677867653
Iteration 8164 => Loss: 0.3677856151
Iteration 8165 => Loss: 0.3677844649
Iteration 8166 => Loss: 0.3677833148
Iteration 8167 => Loss: 0.3677821647
Iteration 8168 => Loss: 0.3677810147
Iteration 8169 => Loss: 0.3677798647
Iteration 8170 => Loss: 0.3677787148
Iteration 8171 => Loss: 0.3677775649
Iteration 8172 => Loss: 0.3677764150
Iteration 8173 => Loss: 0.3677752652
Iteration 8174 => Loss: 0.3677741154
Iteration 8175 => Loss: 0.3677729657
Iteration 8176 => Loss: 0.3677718160
Iteration 8177 => Loss: 0.3677706663
Iteration 8178 => Loss: 0.3677695167
Iteration 8179 => Loss: 0.3677683672
Iteration 8180 => Loss: 0.3677672177
Iteration 8181 => Loss: 0.3677660682
Iteration 8182 => Loss: 0.3677649188
Iteration 8183 => Loss: 0.3677637694
Iteration 8184 => Loss: 0.3677626200
Iteration 8185 => Loss: 0.3677614707
Iteration 8186 => Loss: 0.3677603214
Iteration 8187 => Loss: 0.3677591722
Iteration 8188 => Loss: 0.3677580230
Iteration 8189 => Loss: 0.3677568739
Iteration 8190 => Loss: 0.3677557248
Iteration 8191 => Loss: 0.3677545758
Iteration 8192 => Loss: 0.3677534268
Iteration 8193 => Loss: 0.3677522778
Iteration 8194 => Loss: 0.3677511289
Iteration 8195 => Loss: 0.3677499800
Iteration 8196 => Loss: 0.3677488312
Iteration 8197 => Loss: 0.3677476824
Iteration 8198 => Loss: 0.3677465336
Iteration 8199 => Loss: 0.3677453849
Iteration 8200 => Loss: 0.3677442362
Iteration 8201 => Loss: 0.3677430876
Iteration 8202 => Loss: 0.3677419390
Iteration 8203 => Loss: 0.3677407905
Iteration 8204 => Loss: 0.3677396420
Iteration 8205 => Loss: 0.3677384935
Iteration 8206 => Loss: 0.3677373451
Iteration 8207 => Loss: 0.3677361967
Iteration 8208 => Loss: 0.3677350484
Iteration 8209 => Loss: 0.3677339001
Iteration 8210 => Loss: 0.3677327519
Iteration 8211 => Loss: 0.3677316037
Iteration 8212 => Loss: 0.3677304555
Iteration 8213 => Loss: 0.3677293074
Iteration 8214 => Loss: 0.3677281593
Iteration 8215 => Loss: 0.3677270112
Iteration 8216 => Loss: 0.3677258632
Iteration 8217 => Loss: 0.3677247153
Iteration 8218 => Loss: 0.3677235674
Iteration 8219 => Loss: 0.3677224195
Iteration 8220 => Loss: 0.3677212717
Iteration 8221 => Loss: 0.3677201239
Iteration 8222 => Loss: 0.3677189761
Iteration 8223 => Loss: 0.3677178284
Iteration 8224 => Loss: 0.3677166808
Iteration 8225 => Loss: 0.3677155332
Iteration 8226 => Loss: 0.3677143856
Iteration 8227 => Loss: 0.3677132380
Iteration 8228 => Loss: 0.3677120905
Iteration 8229 => Loss: 0.3677109431
Iteration 8230 => Loss: 0.3677097957
Iteration 8231 => Loss: 0.3677086483
Iteration 8232 => Loss: 0.3677075010
Iteration 8233 => Loss: 0.3677063537
Iteration 8234 => Loss: 0.3677052064
Iteration 8235 => Loss: 0.3677040592
Iteration 8236 => Loss: 0.3677029121
Iteration 8237 => Loss: 0.3677017649
Iteration 8238 => Loss: 0.3677006179
Iteration 8239 => Loss: 0.3676994708
Iteration 8240 => Loss: 0.3676983238
Iteration 8241 => Loss: 0.3676971769
Iteration 8242 => Loss: 0.3676960299
Iteration 8243 => Loss: 0.3676948831
Iteration 8244 => Loss: 0.3676937362
Iteration 8245 => Loss: 0.3676925894
Iteration 8246 => Loss: 0.3676914427
Iteration 8247 => Loss: 0.3676902960
Iteration 8248 => Loss: 0.3676891493
Iteration 8249 => Loss: 0.3676880027
Iteration 8250 => Loss: 0.3676868561
Iteration 8251 => Loss: 0.3676857095
Iteration 8252 => Loss: 0.3676845630
Iteration 8253 => Loss: 0.3676834166
Iteration 8254 => Loss: 0.3676822701
Iteration 8255 => Loss: 0.3676811238
Iteration 8256 => Loss: 0.3676799774
Iteration 8257 => Loss: 0.3676788311
Iteration 8258 => Loss: 0.3676776848
Iteration 8259 => Loss: 0.3676765386
Iteration 8260 => Loss: 0.3676753924
Iteration 8261 => Loss: 0.3676742463
Iteration 8262 => Loss: 0.3676731002
Iteration 8263 => Loss: 0.3676719542
Iteration 8264 => Loss: 0.3676708081
Iteration 8265 => Loss: 0.3676696622
Iteration 8266 => Loss: 0.3676685162
Iteration 8267 => Loss: 0.3676673703
Iteration 8268 => Loss: 0.3676662245
Iteration 8269 => Loss: 0.3676650787
Iteration 8270 => Loss: 0.3676639329
Iteration 8271 => Loss: 0.3676627872
Iteration 8272 => Loss: 0.3676616415
Iteration 8273 => Loss: 0.3676604958
Iteration 8274 => Loss: 0.3676593502
Iteration 8275 => Loss: 0.3676582046
Iteration 8276 => Loss: 0.3676570591
Iteration 8277 => Loss: 0.3676559136
Iteration 8278 => Loss: 0.3676547682
Iteration 8279 => Loss: 0.3676536228
Iteration 8280 => Loss: 0.3676524774
Iteration 8281 => Loss: 0.3676513321
Iteration 8282 => Loss: 0.3676501868
Iteration 8283 => Loss: 0.3676490415
Iteration 8284 => Loss: 0.3676478963
Iteration 8285 => Loss: 0.3676467511
Iteration 8286 => Loss: 0.3676456060
Iteration 8287 => Loss: 0.3676444609
Iteration 8288 => Loss: 0.3676433159
Iteration 8289 => Loss: 0.3676421709
Iteration 8290 => Loss: 0.3676410259
Iteration 8291 => Loss: 0.3676398810
Iteration 8292 => Loss: 0.3676387361
Iteration 8293 => Loss: 0.3676375913
Iteration 8294 => Loss: 0.3676364464
Iteration 8295 => Loss: 0.3676353017
Iteration 8296 => Loss: 0.3676341570
Iteration 8297 => Loss: 0.3676330123
Iteration 8298 => Loss: 0.3676318676
Iteration 8299 => Loss: 0.3676307230
Iteration 8300 => Loss: 0.3676295784
Iteration 8301 => Loss: 0.3676284339
Iteration 8302 => Loss: 0.3676272894
Iteration 8303 => Loss: 0.3676261450
Iteration 8304 => Loss: 0.3676250006
Iteration 8305 => Loss: 0.3676238562
Iteration 8306 => Loss: 0.3676227119
Iteration 8307 => Loss: 0.3676215676
Iteration 8308 => Loss: 0.3676204233
Iteration 8309 => Loss: 0.3676192791
Iteration 8310 => Loss: 0.3676181350
Iteration 8311 => Loss: 0.3676169908
Iteration 8312 => Loss: 0.3676158467
Iteration 8313 => Loss: 0.3676147027
Iteration 8314 => Loss: 0.3676135587
Iteration 8315 => Loss: 0.3676124147
Iteration 8316 => Loss: 0.3676112708
Iteration 8317 => Loss: 0.3676101269
Iteration 8318 => Loss: 0.3676089830
Iteration 8319 => Loss: 0.3676078392
Iteration 8320 => Loss: 0.3676066954
Iteration 8321 => Loss: 0.3676055517
Iteration 8322 => Loss: 0.3676044080
Iteration 8323 => Loss: 0.3676032644
Iteration 8324 => Loss: 0.3676021207
Iteration 8325 => Loss: 0.3676009772
Iteration 8326 => Loss: 0.3675998336
Iteration 8327 => Loss: 0.3675986901
Iteration 8328 => Loss: 0.3675975467
Iteration 8329 => Loss: 0.3675964032
Iteration 8330 => Loss: 0.3675952599
Iteration 8331 => Loss: 0.3675941165
Iteration 8332 => Loss: 0.3675929732
Iteration 8333 => Loss: 0.3675918299
Iteration 8334 => Loss: 0.3675906867
Iteration 8335 => Loss: 0.3675895435
Iteration 8336 => Loss: 0.3675884004
Iteration 8337 => Loss: 0.3675872573
Iteration 8338 => Loss: 0.3675861142
Iteration 8339 => Loss: 0.3675849712
Iteration 8340 => Loss: 0.3675838282
Iteration 8341 => Loss: 0.3675826852
Iteration 8342 => Loss: 0.3675815423
Iteration 8343 => Loss: 0.3675803995
Iteration 8344 => Loss: 0.3675792566
Iteration 8345 => Loss: 0.3675781138
Iteration 8346 => Loss: 0.3675769711
Iteration 8347 => Loss: 0.3675758283
Iteration 8348 => Loss: 0.3675746857
Iteration 8349 => Loss: 0.3675735430
Iteration 8350 => Loss: 0.3675724004
Iteration 8351 => Loss: 0.3675712579
Iteration 8352 => Loss: 0.3675701153
Iteration 8353 => Loss: 0.3675689728
Iteration 8354 => Loss: 0.3675678304
Iteration 8355 => Loss: 0.3675666880
Iteration 8356 => Loss: 0.3675655456
Iteration 8357 => Loss: 0.3675644033
Iteration 8358 => Loss: 0.3675632610
Iteration 8359 => Loss: 0.3675621187
Iteration 8360 => Loss: 0.3675609765
Iteration 8361 => Loss: 0.3675598344
Iteration 8362 => Loss: 0.3675586922
Iteration 8363 => Loss: 0.3675575501
Iteration 8364 => Loss: 0.3675564080
Iteration 8365 => Loss: 0.3675552660
Iteration 8366 => Loss: 0.3675541240
Iteration 8367 => Loss: 0.3675529821
Iteration 8368 => Loss: 0.3675518402
Iteration 8369 => Loss: 0.3675506983
Iteration 8370 => Loss: 0.3675495565
Iteration 8371 => Loss: 0.3675484147
Iteration 8372 => Loss: 0.3675472729
Iteration 8373 => Loss: 0.3675461312
Iteration 8374 => Loss: 0.3675449895
Iteration 8375 => Loss: 0.3675438479
Iteration 8376 => Loss: 0.3675427063
Iteration 8377 => Loss: 0.3675415647
Iteration 8378 => Loss: 0.3675404232
Iteration 8379 => Loss: 0.3675392817
Iteration 8380 => Loss: 0.3675381403
Iteration 8381 => Loss: 0.3675369989
Iteration 8382 => Loss: 0.3675358575
Iteration 8383 => Loss: 0.3675347161
Iteration 8384 => Loss: 0.3675335748
Iteration 8385 => Loss: 0.3675324336
Iteration 8386 => Loss: 0.3675312924
Iteration 8387 => Loss: 0.3675301512
Iteration 8388 => Loss: 0.3675290100
Iteration 8389 => Loss: 0.3675278689
Iteration 8390 => Loss: 0.3675267279
Iteration 8391 => Loss: 0.3675255868
Iteration 8392 => Loss: 0.3675244458
Iteration 8393 => Loss: 0.3675233049
Iteration 8394 => Loss: 0.3675221640
Iteration 8395 => Loss: 0.3675210231
Iteration 8396 => Loss: 0.3675198822
Iteration 8397 => Loss: 0.3675187414
Iteration 8398 => Loss: 0.3675176007
Iteration 8399 => Loss: 0.3675164599
Iteration 8400 => Loss: 0.3675153192
Iteration 8401 => Loss: 0.3675141786
Iteration 8402 => Loss: 0.3675130380
Iteration 8403 => Loss: 0.3675118974
Iteration 8404 => Loss: 0.3675107569
Iteration 8405 => Loss: 0.3675096163
Iteration 8406 => Loss: 0.3675084759
Iteration 8407 => Loss: 0.3675073355
Iteration 8408 => Loss: 0.3675061951
Iteration 8409 => Loss: 0.3675050547
Iteration 8410 => Loss: 0.3675039144
Iteration 8411 => Loss: 0.3675027741
Iteration 8412 => Loss: 0.3675016339
Iteration 8413 => Loss: 0.3675004937
Iteration 8414 => Loss: 0.3674993535
Iteration 8415 => Loss: 0.3674982134
Iteration 8416 => Loss: 0.3674970733
Iteration 8417 => Loss: 0.3674959332
Iteration 8418 => Loss: 0.3674947932
Iteration 8419 => Loss: 0.3674936532
Iteration 8420 => Loss: 0.3674925133
Iteration 8421 => Loss: 0.3674913734
Iteration 8422 => Loss: 0.3674902335
Iteration 8423 => Loss: 0.3674890937
Iteration 8424 => Loss: 0.3674879539
Iteration 8425 => Loss: 0.3674868141
Iteration 8426 => Loss: 0.3674856744
Iteration 8427 => Loss: 0.3674845347
Iteration 8428 => Loss: 0.3674833951
Iteration 8429 => Loss: 0.3674822555
Iteration 8430 => Loss: 0.3674811159
Iteration 8431 => Loss: 0.3674799764
Iteration 8432 => Loss: 0.3674788369
Iteration 8433 => Loss: 0.3674776974
Iteration 8434 => Loss: 0.3674765580
Iteration 8435 => Loss: 0.3674754186
Iteration 8436 => Loss: 0.3674742793
Iteration 8437 => Loss: 0.3674731399
Iteration 8438 => Loss: 0.3674720007
Iteration 8439 => Loss: 0.3674708614
Iteration 8440 => Loss: 0.3674697222
Iteration 8441 => Loss: 0.3674685831
Iteration 8442 => Loss: 0.3674674439
Iteration 8443 => Loss: 0.3674663048
Iteration 8444 => Loss: 0.3674651658
Iteration 8445 => Loss: 0.3674640268
Iteration 8446 => Loss: 0.3674628878
Iteration 8447 => Loss: 0.3674617488
Iteration 8448 => Loss: 0.3674606099
Iteration 8449 => Loss: 0.3674594711
Iteration 8450 => Loss: 0.3674583322
Iteration 8451 => Loss: 0.3674571934
Iteration 8452 => Loss: 0.3674560547
Iteration 8453 => Loss: 0.3674549159
Iteration 8454 => Loss: 0.3674537773
Iteration 8455 => Loss: 0.3674526386
Iteration 8456 => Loss: 0.3674515000
Iteration 8457 => Loss: 0.3674503614
Iteration 8458 => Loss: 0.3674492229
Iteration 8459 => Loss: 0.3674480844
Iteration 8460 => Loss: 0.3674469459
Iteration 8461 => Loss: 0.3674458075
Iteration 8462 => Loss: 0.3674446691
Iteration 8463 => Loss: 0.3674435307
Iteration 8464 => Loss: 0.3674423924
Iteration 8465 => Loss: 0.3674412541
Iteration 8466 => Loss: 0.3674401158
Iteration 8467 => Loss: 0.3674389776
Iteration 8468 => Loss: 0.3674378395
Iteration 8469 => Loss: 0.3674367013
Iteration 8470 => Loss: 0.3674355632
Iteration 8471 => Loss: 0.3674344251
Iteration 8472 => Loss: 0.3674332871
Iteration 8473 => Loss: 0.3674321491
Iteration 8474 => Loss: 0.3674310111
Iteration 8475 => Loss: 0.3674298732
Iteration 8476 => Loss: 0.3674287353
Iteration 8477 => Loss: 0.3674275975
Iteration 8478 => Loss: 0.3674264597
Iteration 8479 => Loss: 0.3674253219
Iteration 8480 => Loss: 0.3674241841
Iteration 8481 => Loss: 0.3674230464
Iteration 8482 => Loss: 0.3674219088
Iteration 8483 => Loss: 0.3674207711
Iteration 8484 => Loss: 0.3674196335
Iteration 8485 => Loss: 0.3674184960
Iteration 8486 => Loss: 0.3674173584
Iteration 8487 => Loss: 0.3674162209
Iteration 8488 => Loss: 0.3674150835
Iteration 8489 => Loss: 0.3674139461
Iteration 8490 => Loss: 0.3674128087
Iteration 8491 => Loss: 0.3674116713
Iteration 8492 => Loss: 0.3674105340
Iteration 8493 => Loss: 0.3674093967
Iteration 8494 => Loss: 0.3674082595
Iteration 8495 => Loss: 0.3674071223
Iteration 8496 => Loss: 0.3674059851
Iteration 8497 => Loss: 0.3674048480
Iteration 8498 => Loss: 0.3674037109
Iteration 8499 => Loss: 0.3674025738
Iteration 8500 => Loss: 0.3674014368
Iteration 8501 => Loss: 0.3674002998
Iteration 8502 => Loss: 0.3673991629
Iteration 8503 => Loss: 0.3673980259
Iteration 8504 => Loss: 0.3673968891
Iteration 8505 => Loss: 0.3673957522
Iteration 8506 => Loss: 0.3673946154
Iteration 8507 => Loss: 0.3673934786
Iteration 8508 => Loss: 0.3673923419
Iteration 8509 => Loss: 0.3673912052
Iteration 8510 => Loss: 0.3673900685
Iteration 8511 => Loss: 0.3673889319
Iteration 8512 => Loss: 0.3673877953
Iteration 8513 => Loss: 0.3673866587
Iteration 8514 => Loss: 0.3673855222
Iteration 8515 => Loss: 0.3673843857
Iteration 8516 => Loss: 0.3673832492
Iteration 8517 => Loss: 0.3673821128
Iteration 8518 => Loss: 0.3673809764
Iteration 8519 => Loss: 0.3673798400
Iteration 8520 => Loss: 0.3673787037
Iteration 8521 => Loss: 0.3673775674
Iteration 8522 => Loss: 0.3673764312
Iteration 8523 => Loss: 0.3673752950
Iteration 8524 => Loss: 0.3673741588
Iteration 8525 => Loss: 0.3673730227
Iteration 8526 => Loss: 0.3673718866
Iteration 8527 => Loss: 0.3673707505
Iteration 8528 => Loss: 0.3673696145
Iteration 8529 => Loss: 0.3673684785
Iteration 8530 => Loss: 0.3673673425
Iteration 8531 => Loss: 0.3673662066
Iteration 8532 => Loss: 0.3673650707
Iteration 8533 => Loss: 0.3673639348
Iteration 8534 => Loss: 0.3673627990
Iteration 8535 => Loss: 0.3673616632
Iteration 8536 => Loss: 0.3673605274
Iteration 8537 => Loss: 0.3673593917
Iteration 8538 => Loss: 0.3673582560
Iteration 8539 => Loss: 0.3673571204
Iteration 8540 => Loss: 0.3673559848
Iteration 8541 => Loss: 0.3673548492
Iteration 8542 => Loss: 0.3673537136
Iteration 8543 => Loss: 0.3673525781
Iteration 8544 => Loss: 0.3673514426
Iteration 8545 => Loss: 0.3673503072
Iteration 8546 => Loss: 0.3673491718
Iteration 8547 => Loss: 0.3673480364
Iteration 8548 => Loss: 0.3673469011
Iteration 8549 => Loss: 0.3673457658
Iteration 8550 => Loss: 0.3673446305
Iteration 8551 => Loss: 0.3673434953
Iteration 8552 => Loss: 0.3673423601
Iteration 8553 => Loss: 0.3673412249
Iteration 8554 => Loss: 0.3673400898
Iteration 8555 => Loss: 0.3673389547
Iteration 8556 => Loss: 0.3673378196
Iteration 8557 => Loss: 0.3673366846
Iteration 8558 => Loss: 0.3673355496
Iteration 8559 => Loss: 0.3673344147
Iteration 8560 => Loss: 0.3673332797
Iteration 8561 => Loss: 0.3673321448
Iteration 8562 => Loss: 0.3673310100
Iteration 8563 => Loss: 0.3673298752
Iteration 8564 => Loss: 0.3673287404
Iteration 8565 => Loss: 0.3673276056
Iteration 8566 => Loss: 0.3673264709
Iteration 8567 => Loss: 0.3673253362
Iteration 8568 => Loss: 0.3673242016
Iteration 8569 => Loss: 0.3673230670
Iteration 8570 => Loss: 0.3673219324
Iteration 8571 => Loss: 0.3673207979
Iteration 8572 => Loss: 0.3673196634
Iteration 8573 => Loss: 0.3673185289
Iteration 8574 => Loss: 0.3673173944
Iteration 8575 => Loss: 0.3673162600
Iteration 8576 => Loss: 0.3673151257
Iteration 8577 => Loss: 0.3673139913
Iteration 8578 => Loss: 0.3673128570
Iteration 8579 => Loss: 0.3673117228
Iteration 8580 => Loss: 0.3673105885
Iteration 8581 => Loss: 0.3673094543
Iteration 8582 => Loss: 0.3673083201
Iteration 8583 => Loss: 0.3673071860
Iteration 8584 => Loss: 0.3673060519
Iteration 8585 => Loss: 0.3673049179
Iteration 8586 => Loss: 0.3673037838
Iteration 8587 => Loss: 0.3673026498
Iteration 8588 => Loss: 0.3673015159
Iteration 8589 => Loss: 0.3673003819
Iteration 8590 => Loss: 0.3672992480
Iteration 8591 => Loss: 0.3672981142
Iteration 8592 => Loss: 0.3672969803
Iteration 8593 => Loss: 0.3672958466
Iteration 8594 => Loss: 0.3672947128
Iteration 8595 => Loss: 0.3672935791
Iteration 8596 => Loss: 0.3672924454
Iteration 8597 => Loss: 0.3672913117
Iteration 8598 => Loss: 0.3672901781
Iteration 8599 => Loss: 0.3672890445
Iteration 8600 => Loss: 0.3672879110
Iteration 8601 => Loss: 0.3672867774
Iteration 8602 => Loss: 0.3672856439
Iteration 8603 => Loss: 0.3672845105
Iteration 8604 => Loss: 0.3672833771
Iteration 8605 => Loss: 0.3672822437
Iteration 8606 => Loss: 0.3672811103
Iteration 8607 => Loss: 0.3672799770
Iteration 8608 => Loss: 0.3672788437
Iteration 8609 => Loss: 0.3672777105
Iteration 8610 => Loss: 0.3672765772
Iteration 8611 => Loss: 0.3672754441
Iteration 8612 => Loss: 0.3672743109
Iteration 8613 => Loss: 0.3672731778
Iteration 8614 => Loss: 0.3672720447
Iteration 8615 => Loss: 0.3672709117
Iteration 8616 => Loss: 0.3672697786
Iteration 8617 => Loss: 0.3672686457
Iteration 8618 => Loss: 0.3672675127
Iteration 8619 => Loss: 0.3672663798
Iteration 8620 => Loss: 0.3672652469
Iteration 8621 => Loss: 0.3672641141
Iteration 8622 => Loss: 0.3672629812
Iteration 8623 => Loss: 0.3672618485
Iteration 8624 => Loss: 0.3672607157
Iteration 8625 => Loss: 0.3672595830
Iteration 8626 => Loss: 0.3672584503
Iteration 8627 => Loss: 0.3672573177
Iteration 8628 => Loss: 0.3672561850
Iteration 8629 => Loss: 0.3672550525
Iteration 8630 => Loss: 0.3672539199
Iteration 8631 => Loss: 0.3672527874
Iteration 8632 => Loss: 0.3672516549
Iteration 8633 => Loss: 0.3672505224
Iteration 8634 => Loss: 0.3672493900
Iteration 8635 => Loss: 0.3672482576
Iteration 8636 => Loss: 0.3672471253
Iteration 8637 => Loss: 0.3672459930
Iteration 8638 => Loss: 0.3672448607
Iteration 8639 => Loss: 0.3672437284
Iteration 8640 => Loss: 0.3672425962
Iteration 8641 => Loss: 0.3672414640
Iteration 8642 => Loss: 0.3672403319
Iteration 8643 => Loss: 0.3672391998
Iteration 8644 => Loss: 0.3672380677
Iteration 8645 => Loss: 0.3672369356
Iteration 8646 => Loss: 0.3672358036
Iteration 8647 => Loss: 0.3672346716
Iteration 8648 => Loss: 0.3672335397
Iteration 8649 => Loss: 0.3672324077
Iteration 8650 => Loss: 0.3672312759
Iteration 8651 => Loss: 0.3672301440
Iteration 8652 => Loss: 0.3672290122
Iteration 8653 => Loss: 0.3672278804
Iteration 8654 => Loss: 0.3672267486
Iteration 8655 => Loss: 0.3672256169
Iteration 8656 => Loss: 0.3672244852
Iteration 8657 => Loss: 0.3672233535
Iteration 8658 => Loss: 0.3672222219
Iteration 8659 => Loss: 0.3672210903
Iteration 8660 => Loss: 0.3672199588
Iteration 8661 => Loss: 0.3672188272
Iteration 8662 => Loss: 0.3672176957
Iteration 8663 => Loss: 0.3672165643
Iteration 8664 => Loss: 0.3672154329
Iteration 8665 => Loss: 0.3672143015
Iteration 8666 => Loss: 0.3672131701
Iteration 8667 => Loss: 0.3672120388
Iteration 8668 => Loss: 0.3672109075
Iteration 8669 => Loss: 0.3672097762
Iteration 8670 => Loss: 0.3672086450
Iteration 8671 => Loss: 0.3672075138
Iteration 8672 => Loss: 0.3672063826
Iteration 8673 => Loss: 0.3672052515
Iteration 8674 => Loss: 0.3672041203
Iteration 8675 => Loss: 0.3672029893
Iteration 8676 => Loss: 0.3672018582
Iteration 8677 => Loss: 0.3672007272
Iteration 8678 => Loss: 0.3671995963
Iteration 8679 => Loss: 0.3671984653
Iteration 8680 => Loss: 0.3671973344
Iteration 8681 => Loss: 0.3671962035
Iteration 8682 => Loss: 0.3671950727
Iteration 8683 => Loss: 0.3671939419
Iteration 8684 => Loss: 0.3671928111
Iteration 8685 => Loss: 0.3671916803
Iteration 8686 => Loss: 0.3671905496
Iteration 8687 => Loss: 0.3671894189
Iteration 8688 => Loss: 0.3671882883
Iteration 8689 => Loss: 0.3671871577
Iteration 8690 => Loss: 0.3671860271
Iteration 8691 => Loss: 0.3671848965
Iteration 8692 => Loss: 0.3671837660
Iteration 8693 => Loss: 0.3671826355
Iteration 8694 => Loss: 0.3671815051
Iteration 8695 => Loss: 0.3671803746
Iteration 8696 => Loss: 0.3671792442
Iteration 8697 => Loss: 0.3671781139
Iteration 8698 => Loss: 0.3671769836
Iteration 8699 => Loss: 0.3671758533
Iteration 8700 => Loss: 0.3671747230
Iteration 8701 => Loss: 0.3671735928
Iteration 8702 => Loss: 0.3671724626
Iteration 8703 => Loss: 0.3671713324
Iteration 8704 => Loss: 0.3671702023
Iteration 8705 => Loss: 0.3671690722
Iteration 8706 => Loss: 0.3671679421
Iteration 8707 => Loss: 0.3671668120
Iteration 8708 => Loss: 0.3671656820
Iteration 8709 => Loss: 0.3671645521
Iteration 8710 => Loss: 0.3671634221
Iteration 8711 => Loss: 0.3671622922
Iteration 8712 => Loss: 0.3671611623
Iteration 8713 => Loss: 0.3671600325
Iteration 8714 => Loss: 0.3671589026
Iteration 8715 => Loss: 0.3671577729
Iteration 8716 => Loss: 0.3671566431
Iteration 8717 => Loss: 0.3671555134
Iteration 8718 => Loss: 0.3671543837
Iteration 8719 => Loss: 0.3671532540
Iteration 8720 => Loss: 0.3671521244
Iteration 8721 => Loss: 0.3671509948
Iteration 8722 => Loss: 0.3671498653
Iteration 8723 => Loss: 0.3671487357
Iteration 8724 => Loss: 0.3671476062
Iteration 8725 => Loss: 0.3671464767
Iteration 8726 => Loss: 0.3671453473
Iteration 8727 => Loss: 0.3671442179
Iteration 8728 => Loss: 0.3671430885
Iteration 8729 => Loss: 0.3671419592
Iteration 8730 => Loss: 0.3671408299
Iteration 8731 => Loss: 0.3671397006
Iteration 8732 => Loss: 0.3671385714
Iteration 8733 => Loss: 0.3671374421
Iteration 8734 => Loss: 0.3671363130
Iteration 8735 => Loss: 0.3671351838
Iteration 8736 => Loss: 0.3671340547
Iteration 8737 => Loss: 0.3671329256
Iteration 8738 => Loss: 0.3671317965
Iteration 8739 => Loss: 0.3671306675
Iteration 8740 => Loss: 0.3671295385
Iteration 8741 => Loss: 0.3671284095
Iteration 8742 => Loss: 0.3671272806
Iteration 8743 => Loss: 0.3671261517
Iteration 8744 => Loss: 0.3671250228
Iteration 8745 => Loss: 0.3671238940
Iteration 8746 => Loss: 0.3671227652
Iteration 8747 => Loss: 0.3671216364
Iteration 8748 => Loss: 0.3671205077
Iteration 8749 => Loss: 0.3671193790
Iteration 8750 => Loss: 0.3671182503
Iteration 8751 => Loss: 0.3671171216
Iteration 8752 => Loss: 0.3671159930
Iteration 8753 => Loss: 0.3671148644
Iteration 8754 => Loss: 0.3671137359
Iteration 8755 => Loss: 0.3671126073
Iteration 8756 => Loss: 0.3671114788
Iteration 8757 => Loss: 0.3671103504
Iteration 8758 => Loss: 0.3671092219
Iteration 8759 => Loss: 0.3671080935
Iteration 8760 => Loss: 0.3671069652
Iteration 8761 => Loss: 0.3671058368
Iteration 8762 => Loss: 0.3671047085
Iteration 8763 => Loss: 0.3671035802
Iteration 8764 => Loss: 0.3671024520
Iteration 8765 => Loss: 0.3671013238
Iteration 8766 => Loss: 0.3671001956
Iteration 8767 => Loss: 0.3670990674
Iteration 8768 => Loss: 0.3670979393
Iteration 8769 => Loss: 0.3670968112
Iteration 8770 => Loss: 0.3670956832
Iteration 8771 => Loss: 0.3670945551
Iteration 8772 => Loss: 0.3670934271
Iteration 8773 => Loss: 0.3670922992
Iteration 8774 => Loss: 0.3670911712
Iteration 8775 => Loss: 0.3670900433
Iteration 8776 => Loss: 0.3670889154
Iteration 8777 => Loss: 0.3670877876
Iteration 8778 => Loss: 0.3670866598
Iteration 8779 => Loss: 0.3670855320
Iteration 8780 => Loss: 0.3670844043
Iteration 8781 => Loss: 0.3670832765
Iteration 8782 => Loss: 0.3670821488
Iteration 8783 => Loss: 0.3670810212
Iteration 8784 => Loss: 0.3670798936
Iteration 8785 => Loss: 0.3670787660
Iteration 8786 => Loss: 0.3670776384
Iteration 8787 => Loss: 0.3670765108
Iteration 8788 => Loss: 0.3670753833
Iteration 8789 => Loss: 0.3670742559
Iteration 8790 => Loss: 0.3670731284
Iteration 8791 => Loss: 0.3670720010
Iteration 8792 => Loss: 0.3670708736
Iteration 8793 => Loss: 0.3670697463
Iteration 8794 => Loss: 0.3670686189
Iteration 8795 => Loss: 0.3670674917
Iteration 8796 => Loss: 0.3670663644
Iteration 8797 => Loss: 0.3670652372
Iteration 8798 => Loss: 0.3670641100
Iteration 8799 => Loss: 0.3670629828
Iteration 8800 => Loss: 0.3670618556
Iteration 8801 => Loss: 0.3670607285
Iteration 8802 => Loss: 0.3670596015
Iteration 8803 => Loss: 0.3670584744
Iteration 8804 => Loss: 0.3670573474
Iteration 8805 => Loss: 0.3670562204
Iteration 8806 => Loss: 0.3670550934
Iteration 8807 => Loss: 0.3670539665
Iteration 8808 => Loss: 0.3670528396
Iteration 8809 => Loss: 0.3670517128
Iteration 8810 => Loss: 0.3670505859
Iteration 8811 => Loss: 0.3670494591
Iteration 8812 => Loss: 0.3670483323
Iteration 8813 => Loss: 0.3670472056
Iteration 8814 => Loss: 0.3670460789
Iteration 8815 => Loss: 0.3670449522
Iteration 8816 => Loss: 0.3670438255
Iteration 8817 => Loss: 0.3670426989
Iteration 8818 => Loss: 0.3670415723
Iteration 8819 => Loss: 0.3670404458
Iteration 8820 => Loss: 0.3670393192
Iteration 8821 => Loss: 0.3670381927
Iteration 8822 => Loss: 0.3670370662
Iteration 8823 => Loss: 0.3670359398
Iteration 8824 => Loss: 0.3670348134
Iteration 8825 => Loss: 0.3670336870
Iteration 8826 => Loss: 0.3670325606
Iteration 8827 => Loss: 0.3670314343
Iteration 8828 => Loss: 0.3670303080
Iteration 8829 => Loss: 0.3670291818
Iteration 8830 => Loss: 0.3670280555
Iteration 8831 => Loss: 0.3670269293
Iteration 8832 => Loss: 0.3670258032
Iteration 8833 => Loss: 0.3670246770
Iteration 8834 => Loss: 0.3670235509
Iteration 8835 => Loss: 0.3670224248
Iteration 8836 => Loss: 0.3670212988
Iteration 8837 => Loss: 0.3670201727
Iteration 8838 => Loss: 0.3670190467
Iteration 8839 => Loss: 0.3670179208
Iteration 8840 => Loss: 0.3670167948
Iteration 8841 => Loss: 0.3670156689
Iteration 8842 => Loss: 0.3670145431
Iteration 8843 => Loss: 0.3670134172
Iteration 8844 => Loss: 0.3670122914
Iteration 8845 => Loss: 0.3670111656
Iteration 8846 => Loss: 0.3670100399
Iteration 8847 => Loss: 0.3670089141
Iteration 8848 => Loss: 0.3670077884
Iteration 8849 => Loss: 0.3670066628
Iteration 8850 => Loss: 0.3670055371
Iteration 8851 => Loss: 0.3670044115
Iteration 8852 => Loss: 0.3670032860
Iteration 8853 => Loss: 0.3670021604
Iteration 8854 => Loss: 0.3670010349
Iteration 8855 => Loss: 0.3669999094
Iteration 8856 => Loss: 0.3669987840
Iteration 8857 => Loss: 0.3669976585
Iteration 8858 => Loss: 0.3669965331
Iteration 8859 => Loss: 0.3669954078
Iteration 8860 => Loss: 0.3669942824
Iteration 8861 => Loss: 0.3669931571
Iteration 8862 => Loss: 0.3669920318
Iteration 8863 => Loss: 0.3669909066
Iteration 8864 => Loss: 0.3669897813
Iteration 8865 => Loss: 0.3669886562
Iteration 8866 => Loss: 0.3669875310
Iteration 8867 => Loss: 0.3669864059
Iteration 8868 => Loss: 0.3669852808
Iteration 8869 => Loss: 0.3669841557
Iteration 8870 => Loss: 0.3669830306
Iteration 8871 => Loss: 0.3669819056
Iteration 8872 => Loss: 0.3669807806
Iteration 8873 => Loss: 0.3669796557
Iteration 8874 => Loss: 0.3669785307
Iteration 8875 => Loss: 0.3669774059
Iteration 8876 => Loss: 0.3669762810
Iteration 8877 => Loss: 0.3669751561
Iteration 8878 => Loss: 0.3669740313
Iteration 8879 => Loss: 0.3669729065
Iteration 8880 => Loss: 0.3669717818
Iteration 8881 => Loss: 0.3669706571
Iteration 8882 => Loss: 0.3669695324
Iteration 8883 => Loss: 0.3669684077
Iteration 8884 => Loss: 0.3669672831
Iteration 8885 => Loss: 0.3669661585
Iteration 8886 => Loss: 0.3669650339
Iteration 8887 => Loss: 0.3669639094
Iteration 8888 => Loss: 0.3669627848
Iteration 8889 => Loss: 0.3669616603
Iteration 8890 => Loss: 0.3669605359
Iteration 8891 => Loss: 0.3669594115
Iteration 8892 => Loss: 0.3669582871
Iteration 8893 => Loss: 0.3669571627
Iteration 8894 => Loss: 0.3669560383
Iteration 8895 => Loss: 0.3669549140
Iteration 8896 => Loss: 0.3669537897
Iteration 8897 => Loss: 0.3669526655
Iteration 8898 => Loss: 0.3669515413
Iteration 8899 => Loss: 0.3669504171
Iteration 8900 => Loss: 0.3669492929
Iteration 8901 => Loss: 0.3669481687
Iteration 8902 => Loss: 0.3669470446
Iteration 8903 => Loss: 0.3669459206
Iteration 8904 => Loss: 0.3669447965
Iteration 8905 => Loss: 0.3669436725
Iteration 8906 => Loss: 0.3669425485
Iteration 8907 => Loss: 0.3669414245
Iteration 8908 => Loss: 0.3669403006
Iteration 8909 => Loss: 0.3669391767
Iteration 8910 => Loss: 0.3669380528
Iteration 8911 => Loss: 0.3669369289
Iteration 8912 => Loss: 0.3669358051
Iteration 8913 => Loss: 0.3669346813
Iteration 8914 => Loss: 0.3669335575
Iteration 8915 => Loss: 0.3669324338
Iteration 8916 => Loss: 0.3669313101
Iteration 8917 => Loss: 0.3669301864
Iteration 8918 => Loss: 0.3669290628
Iteration 8919 => Loss: 0.3669279392
Iteration 8920 => Loss: 0.3669268156
Iteration 8921 => Loss: 0.3669256920
Iteration 8922 => Loss: 0.3669245685
Iteration 8923 => Loss: 0.3669234450
Iteration 8924 => Loss: 0.3669223215
Iteration 8925 => Loss: 0.3669211980
Iteration 8926 => Loss: 0.3669200746
Iteration 8927 => Loss: 0.3669189512
Iteration 8928 => Loss: 0.3669178278
Iteration 8929 => Loss: 0.3669167045
Iteration 8930 => Loss: 0.3669155812
Iteration 8931 => Loss: 0.3669144579
Iteration 8932 => Loss: 0.3669133347
Iteration 8933 => Loss: 0.3669122115
Iteration 8934 => Loss: 0.3669110883
Iteration 8935 => Loss: 0.3669099651
Iteration 8936 => Loss: 0.3669088420
Iteration 8937 => Loss: 0.3669077189
Iteration 8938 => Loss: 0.3669065958
Iteration 8939 => Loss: 0.3669054727
Iteration 8940 => Loss: 0.3669043497
Iteration 8941 => Loss: 0.3669032267
Iteration 8942 => Loss: 0.3669021037
Iteration 8943 => Loss: 0.3669009808
Iteration 8944 => Loss: 0.3668998579
Iteration 8945 => Loss: 0.3668987350
Iteration 8946 => Loss: 0.3668976122
Iteration 8947 => Loss: 0.3668964893
Iteration 8948 => Loss: 0.3668953666
Iteration 8949 => Loss: 0.3668942438
Iteration 8950 => Loss: 0.3668931210
Iteration 8951 => Loss: 0.3668919983
Iteration 8952 => Loss: 0.3668908757
Iteration 8953 => Loss: 0.3668897530
Iteration 8954 => Loss: 0.3668886304
Iteration 8955 => Loss: 0.3668875078
Iteration 8956 => Loss: 0.3668863852
Iteration 8957 => Loss: 0.3668852627
Iteration 8958 => Loss: 0.3668841402
Iteration 8959 => Loss: 0.3668830177
Iteration 8960 => Loss: 0.3668818952
Iteration 8961 => Loss: 0.3668807728
Iteration 8962 => Loss: 0.3668796504
Iteration 8963 => Loss: 0.3668785280
Iteration 8964 => Loss: 0.3668774057
Iteration 8965 => Loss: 0.3668762834
Iteration 8966 => Loss: 0.3668751611
Iteration 8967 => Loss: 0.3668740388
Iteration 8968 => Loss: 0.3668729166
Iteration 8969 => Loss: 0.3668717944
Iteration 8970 => Loss: 0.3668706722
Iteration 8971 => Loss: 0.3668695500
Iteration 8972 => Loss: 0.3668684279
Iteration 8973 => Loss: 0.3668673058
Iteration 8974 => Loss: 0.3668661838
Iteration 8975 => Loss: 0.3668650617
Iteration 8976 => Loss: 0.3668639397
Iteration 8977 => Loss: 0.3668628178
Iteration 8978 => Loss: 0.3668616958
Iteration 8979 => Loss: 0.3668605739
Iteration 8980 => Loss: 0.3668594520
Iteration 8981 => Loss: 0.3668583301
Iteration 8982 => Loss: 0.3668572083
Iteration 8983 => Loss: 0.3668560865
Iteration 8984 => Loss: 0.3668549647
Iteration 8985 => Loss: 0.3668538429
Iteration 8986 => Loss: 0.3668527212
Iteration 8987 => Loss: 0.3668515995
Iteration 8988 => Loss: 0.3668504778
Iteration 8989 => Loss: 0.3668493562
Iteration 8990 => Loss: 0.3668482345
Iteration 8991 => Loss: 0.3668471130
Iteration 8992 => Loss: 0.3668459914
Iteration 8993 => Loss: 0.3668448699
Iteration 8994 => Loss: 0.3668437483
Iteration 8995 => Loss: 0.3668426269
Iteration 8996 => Loss: 0.3668415054
Iteration 8997 => Loss: 0.3668403840
Iteration 8998 => Loss: 0.3668392626
Iteration 8999 => Loss: 0.3668381412
Iteration 9000 => Loss: 0.3668370199
Iteration 9001 => Loss: 0.3668358986
Iteration 9002 => Loss: 0.3668347773
Iteration 9003 => Loss: 0.3668336560
Iteration 9004 => Loss: 0.3668325348
Iteration 9005 => Loss: 0.3668314136
Iteration 9006 => Loss: 0.3668302924
Iteration 9007 => Loss: 0.3668291713
Iteration 9008 => Loss: 0.3668280501
Iteration 9009 => Loss: 0.3668269290
Iteration 9010 => Loss: 0.3668258080
Iteration 9011 => Loss: 0.3668246869
Iteration 9012 => Loss: 0.3668235659
Iteration 9013 => Loss: 0.3668224449
Iteration 9014 => Loss: 0.3668213240
Iteration 9015 => Loss: 0.3668202031
Iteration 9016 => Loss: 0.3668190822
Iteration 9017 => Loss: 0.3668179613
Iteration 9018 => Loss: 0.3668168404
Iteration 9019 => Loss: 0.3668157196
Iteration 9020 => Loss: 0.3668145988
Iteration 9021 => Loss: 0.3668134781
Iteration 9022 => Loss: 0.3668123573
Iteration 9023 => Loss: 0.3668112366
Iteration 9024 => Loss: 0.3668101159
Iteration 9025 => Loss: 0.3668089953
Iteration 9026 => Loss: 0.3668078746
Iteration 9027 => Loss: 0.3668067540
Iteration 9028 => Loss: 0.3668056335
Iteration 9029 => Loss: 0.3668045129
Iteration 9030 => Loss: 0.3668033924
Iteration 9031 => Loss: 0.3668022719
Iteration 9032 => Loss: 0.3668011514
Iteration 9033 => Loss: 0.3668000310
Iteration 9034 => Loss: 0.3667989106
Iteration 9035 => Loss: 0.3667977902
Iteration 9036 => Loss: 0.3667966699
Iteration 9037 => Loss: 0.3667955495
Iteration 9038 => Loss: 0.3667944292
Iteration 9039 => Loss: 0.3667933090
Iteration 9040 => Loss: 0.3667921887
Iteration 9041 => Loss: 0.3667910685
Iteration 9042 => Loss: 0.3667899483
Iteration 9043 => Loss: 0.3667888281
Iteration 9044 => Loss: 0.3667877080
Iteration 9045 => Loss: 0.3667865879
Iteration 9046 => Loss: 0.3667854678
Iteration 9047 => Loss: 0.3667843477
Iteration 9048 => Loss: 0.3667832277
Iteration 9049 => Loss: 0.3667821077
Iteration 9050 => Loss: 0.3667809877
Iteration 9051 => Loss: 0.3667798678
Iteration 9052 => Loss: 0.3667787478
Iteration 9053 => Loss: 0.3667776279
Iteration 9054 => Loss: 0.3667765081
Iteration 9055 => Loss: 0.3667753882
Iteration 9056 => Loss: 0.3667742684
Iteration 9057 => Loss: 0.3667731486
Iteration 9058 => Loss: 0.3667720289
Iteration 9059 => Loss: 0.3667709091
Iteration 9060 => Loss: 0.3667697894
Iteration 9061 => Loss: 0.3667686697
Iteration 9062 => Loss: 0.3667675501
Iteration 9063 => Loss: 0.3667664304
Iteration 9064 => Loss: 0.3667653108
Iteration 9065 => Loss: 0.3667641913
Iteration 9066 => Loss: 0.3667630717
Iteration 9067 => Loss: 0.3667619522
Iteration 9068 => Loss: 0.3667608327
Iteration 9069 => Loss: 0.3667597132
Iteration 9070 => Loss: 0.3667585938
Iteration 9071 => Loss: 0.3667574744
Iteration 9072 => Loss: 0.3667563550
Iteration 9073 => Loss: 0.3667552356
Iteration 9074 => Loss: 0.3667541163
Iteration 9075 => Loss: 0.3667529970
Iteration 9076 => Loss: 0.3667518777
Iteration 9077 => Loss: 0.3667507584
Iteration 9078 => Loss: 0.3667496392
Iteration 9079 => Loss: 0.3667485200
Iteration 9080 => Loss: 0.3667474008
Iteration 9081 => Loss: 0.3667462817
Iteration 9082 => Loss: 0.3667451626
Iteration 9083 => Loss: 0.3667440435
Iteration 9084 => Loss: 0.3667429244
Iteration 9085 => Loss: 0.3667418054
Iteration 9086 => Loss: 0.3667406863
Iteration 9087 => Loss: 0.3667395674
Iteration 9088 => Loss: 0.3667384484
Iteration 9089 => Loss: 0.3667373295
Iteration 9090 => Loss: 0.3667362106
Iteration 9091 => Loss: 0.3667350917
Iteration 9092 => Loss: 0.3667339728
Iteration 9093 => Loss: 0.3667328540
Iteration 9094 => Loss: 0.3667317352
Iteration 9095 => Loss: 0.3667306164
Iteration 9096 => Loss: 0.3667294976
Iteration 9097 => Loss: 0.3667283789
Iteration 9098 => Loss: 0.3667272602
Iteration 9099 => Loss: 0.3667261415
Iteration 9100 => Loss: 0.3667250229
Iteration 9101 => Loss: 0.3667239043
Iteration 9102 => Loss: 0.3667227857
Iteration 9103 => Loss: 0.3667216671
Iteration 9104 => Loss: 0.3667205486
Iteration 9105 => Loss: 0.3667194301
Iteration 9106 => Loss: 0.3667183116
Iteration 9107 => Loss: 0.3667171931
Iteration 9108 => Loss: 0.3667160747
Iteration 9109 => Loss: 0.3667149563
Iteration 9110 => Loss: 0.3667138379
Iteration 9111 => Loss: 0.3667127195
Iteration 9112 => Loss: 0.3667116012
Iteration 9113 => Loss: 0.3667104829
Iteration 9114 => Loss: 0.3667093646
Iteration 9115 => Loss: 0.3667082464
Iteration 9116 => Loss: 0.3667071281
Iteration 9117 => Loss: 0.3667060099
Iteration 9118 => Loss: 0.3667048918
Iteration 9119 => Loss: 0.3667037736
Iteration 9120 => Loss: 0.3667026555
Iteration 9121 => Loss: 0.3667015374
Iteration 9122 => Loss: 0.3667004193
Iteration 9123 => Loss: 0.3666993013
Iteration 9124 => Loss: 0.3666981833
Iteration 9125 => Loss: 0.3666970653
Iteration 9126 => Loss: 0.3666959473
Iteration 9127 => Loss: 0.3666948294
Iteration 9128 => Loss: 0.3666937115
Iteration 9129 => Loss: 0.3666925936
Iteration 9130 => Loss: 0.3666914757
Iteration 9131 => Loss: 0.3666903579
Iteration 9132 => Loss: 0.3666892401
Iteration 9133 => Loss: 0.3666881223
Iteration 9134 => Loss: 0.3666870045
Iteration 9135 => Loss: 0.3666858868
Iteration 9136 => Loss: 0.3666847691
Iteration 9137 => Loss: 0.3666836514
Iteration 9138 => Loss: 0.3666825337
Iteration 9139 => Loss: 0.3666814161
Iteration 9140 => Loss: 0.3666802985
Iteration 9141 => Loss: 0.3666791809
Iteration 9142 => Loss: 0.3666780634
Iteration 9143 => Loss: 0.3666769459
Iteration 9144 => Loss: 0.3666758284
Iteration 9145 => Loss: 0.3666747109
Iteration 9146 => Loss: 0.3666735934
Iteration 9147 => Loss: 0.3666724760
Iteration 9148 => Loss: 0.3666713586
Iteration 9149 => Loss: 0.3666702412
Iteration 9150 => Loss: 0.3666691239
Iteration 9151 => Loss: 0.3666680066
Iteration 9152 => Loss: 0.3666668893
Iteration 9153 => Loss: 0.3666657720
Iteration 9154 => Loss: 0.3666646548
Iteration 9155 => Loss: 0.3666635376
Iteration 9156 => Loss: 0.3666624204
Iteration 9157 => Loss: 0.3666613032
Iteration 9158 => Loss: 0.3666601861
Iteration 9159 => Loss: 0.3666590690
Iteration 9160 => Loss: 0.3666579519
Iteration 9161 => Loss: 0.3666568348
Iteration 9162 => Loss: 0.3666557178
Iteration 9163 => Loss: 0.3666546008
Iteration 9164 => Loss: 0.3666534838
Iteration 9165 => Loss: 0.3666523668
Iteration 9166 => Loss: 0.3666512499
Iteration 9167 => Loss: 0.3666501330
Iteration 9168 => Loss: 0.3666490161
Iteration 9169 => Loss: 0.3666478992
Iteration 9170 => Loss: 0.3666467824
Iteration 9171 => Loss: 0.3666456656
Iteration 9172 => Loss: 0.3666445488
Iteration 9173 => Loss: 0.3666434320
Iteration 9174 => Loss: 0.3666423153
Iteration 9175 => Loss: 0.3666411986
Iteration 9176 => Loss: 0.3666400819
Iteration 9177 => Loss: 0.3666389653
Iteration 9178 => Loss: 0.3666378486
Iteration 9179 => Loss: 0.3666367320
Iteration 9180 => Loss: 0.3666356155
Iteration 9181 => Loss: 0.3666344989
Iteration 9182 => Loss: 0.3666333824
Iteration 9183 => Loss: 0.3666322659
Iteration 9184 => Loss: 0.3666311494
Iteration 9185 => Loss: 0.3666300330
Iteration 9186 => Loss: 0.3666289165
Iteration 9187 => Loss: 0.3666278001
Iteration 9188 => Loss: 0.3666266838
Iteration 9189 => Loss: 0.3666255674
Iteration 9190 => Loss: 0.3666244511
Iteration 9191 => Loss: 0.3666233348
Iteration 9192 => Loss: 0.3666222185
Iteration 9193 => Loss: 0.3666211023
Iteration 9194 => Loss: 0.3666199860
Iteration 9195 => Loss: 0.3666188698
Iteration 9196 => Loss: 0.3666177537
Iteration 9197 => Loss: 0.3666166375
Iteration 9198 => Loss: 0.3666155214
Iteration 9199 => Loss: 0.3666144053
Iteration 9200 => Loss: 0.3666132892
Iteration 9201 => Loss: 0.3666121732
Iteration 9202 => Loss: 0.3666110571
Iteration 9203 => Loss: 0.3666099411
Iteration 9204 => Loss: 0.3666088252
Iteration 9205 => Loss: 0.3666077092
Iteration 9206 => Loss: 0.3666065933
Iteration 9207 => Loss: 0.3666054774
Iteration 9208 => Loss: 0.3666043615
Iteration 9209 => Loss: 0.3666032457
Iteration 9210 => Loss: 0.3666021299
Iteration 9211 => Loss: 0.3666010141
Iteration 9212 => Loss: 0.3665998983
Iteration 9213 => Loss: 0.3665987825
Iteration 9214 => Loss: 0.3665976668
Iteration 9215 => Loss: 0.3665965511
Iteration 9216 => Loss: 0.3665954355
Iteration 9217 => Loss: 0.3665943198
Iteration 9218 => Loss: 0.3665932042
Iteration 9219 => Loss: 0.3665920886
Iteration 9220 => Loss: 0.3665909730
Iteration 9221 => Loss: 0.3665898575
Iteration 9222 => Loss: 0.3665887419
Iteration 9223 => Loss: 0.3665876264
Iteration 9224 => Loss: 0.3665865110
Iteration 9225 => Loss: 0.3665853955
Iteration 9226 => Loss: 0.3665842801
Iteration 9227 => Loss: 0.3665831647
Iteration 9228 => Loss: 0.3665820493
Iteration 9229 => Loss: 0.3665809340
Iteration 9230 => Loss: 0.3665798187
Iteration 9231 => Loss: 0.3665787034
Iteration 9232 => Loss: 0.3665775881
Iteration 9233 => Loss: 0.3665764728
Iteration 9234 => Loss: 0.3665753576
Iteration 9235 => Loss: 0.3665742424
Iteration 9236 => Loss: 0.3665731272
Iteration 9237 => Loss: 0.3665720121
Iteration 9238 => Loss: 0.3665708970
Iteration 9239 => Loss: 0.3665697819
Iteration 9240 => Loss: 0.3665686668
Iteration 9241 => Loss: 0.3665675517
Iteration 9242 => Loss: 0.3665664367
Iteration 9243 => Loss: 0.3665653217
Iteration 9244 => Loss: 0.3665642067
Iteration 9245 => Loss: 0.3665630918
Iteration 9246 => Loss: 0.3665619768
Iteration 9247 => Loss: 0.3665608619
Iteration 9248 => Loss: 0.3665597471
Iteration 9249 => Loss: 0.3665586322
Iteration 9250 => Loss: 0.3665575174
Iteration 9251 => Loss: 0.3665564026
Iteration 9252 => Loss: 0.3665552878
Iteration 9253 => Loss: 0.3665541730
Iteration 9254 => Loss: 0.3665530583
Iteration 9255 => Loss: 0.3665519436
Iteration 9256 => Loss: 0.3665508289
Iteration 9257 => Loss: 0.3665497143
Iteration 9258 => Loss: 0.3665485996
Iteration 9259 => Loss: 0.3665474850
Iteration 9260 => Loss: 0.3665463704
Iteration 9261 => Loss: 0.3665452559
Iteration 9262 => Loss: 0.3665441413
Iteration 9263 => Loss: 0.3665430268
Iteration 9264 => Loss: 0.3665419123
Iteration 9265 => Loss: 0.3665407979
Iteration 9266 => Loss: 0.3665396834
Iteration 9267 => Loss: 0.3665385690
Iteration 9268 => Loss: 0.3665374546
Iteration 9269 => Loss: 0.3665363403
Iteration 9270 => Loss: 0.3665352259
Iteration 9271 => Loss: 0.3665341116
Iteration 9272 => Loss: 0.3665329973
Iteration 9273 => Loss: 0.3665318831
Iteration 9274 => Loss: 0.3665307688
Iteration 9275 => Loss: 0.3665296546
Iteration 9276 => Loss: 0.3665285404
Iteration 9277 => Loss: 0.3665274262
Iteration 9278 => Loss: 0.3665263121
Iteration 9279 => Loss: 0.3665251980
Iteration 9280 => Loss: 0.3665240839
Iteration 9281 => Loss: 0.3665229698
Iteration 9282 => Loss: 0.3665218558
Iteration 9283 => Loss: 0.3665207417
Iteration 9284 => Loss: 0.3665196277
Iteration 9285 => Loss: 0.3665185138
Iteration 9286 => Loss: 0.3665173998
Iteration 9287 => Loss: 0.3665162859
Iteration 9288 => Loss: 0.3665151720
Iteration 9289 => Loss: 0.3665140581
Iteration 9290 => Loss: 0.3665129442
Iteration 9291 => Loss: 0.3665118304
Iteration 9292 => Loss: 0.3665107166
Iteration 9293 => Loss: 0.3665096028
Iteration 9294 => Loss: 0.3665084891
Iteration 9295 => Loss: 0.3665073753
Iteration 9296 => Loss: 0.3665062616
Iteration 9297 => Loss: 0.3665051479
Iteration 9298 => Loss: 0.3665040343
Iteration 9299 => Loss: 0.3665029206
Iteration 9300 => Loss: 0.3665018070
Iteration 9301 => Loss: 0.3665006934
Iteration 9302 => Loss: 0.3664995799
Iteration 9303 => Loss: 0.3664984663
Iteration 9304 => Loss: 0.3664973528
Iteration 9305 => Loss: 0.3664962393
Iteration 9306 => Loss: 0.3664951258
Iteration 9307 => Loss: 0.3664940124
Iteration 9308 => Loss: 0.3664928990
Iteration 9309 => Loss: 0.3664917856
Iteration 9310 => Loss: 0.3664906722
Iteration 9311 => Loss: 0.3664895588
Iteration 9312 => Loss: 0.3664884455
Iteration 9313 => Loss: 0.3664873322
Iteration 9314 => Loss: 0.3664862189
Iteration 9315 => Loss: 0.3664851057
Iteration 9316 => Loss: 0.3664839925
Iteration 9317 => Loss: 0.3664828793
Iteration 9318 => Loss: 0.3664817661
Iteration 9319 => Loss: 0.3664806529
Iteration 9320 => Loss: 0.3664795398
Iteration 9321 => Loss: 0.3664784267
Iteration 9322 => Loss: 0.3664773136
Iteration 9323 => Loss: 0.3664762005
Iteration 9324 => Loss: 0.3664750875
Iteration 9325 => Loss: 0.3664739745
Iteration 9326 => Loss: 0.3664728615
Iteration 9327 => Loss: 0.3664717485
Iteration 9328 => Loss: 0.3664706356
Iteration 9329 => Loss: 0.3664695226
Iteration 9330 => Loss: 0.3664684097
Iteration 9331 => Loss: 0.3664672969
Iteration 9332 => Loss: 0.3664661840
Iteration 9333 => Loss: 0.3664650712
Iteration 9334 => Loss: 0.3664639584
Iteration 9335 => Loss: 0.3664628456
Iteration 9336 => Loss: 0.3664617329
Iteration 9337 => Loss: 0.3664606201
Iteration 9338 => Loss: 0.3664595074
Iteration 9339 => Loss: 0.3664583947
Iteration 9340 => Loss: 0.3664572821
Iteration 9341 => Loss: 0.3664561694
Iteration 9342 => Loss: 0.3664550568
Iteration 9343 => Loss: 0.3664539442
Iteration 9344 => Loss: 0.3664528317
Iteration 9345 => Loss: 0.3664517191
Iteration 9346 => Loss: 0.3664506066
Iteration 9347 => Loss: 0.3664494941
Iteration 9348 => Loss: 0.3664483816
Iteration 9349 => Loss: 0.3664472692
Iteration 9350 => Loss: 0.3664461568
Iteration 9351 => Loss: 0.3664450444
Iteration 9352 => Loss: 0.3664439320
Iteration 9353 => Loss: 0.3664428196
Iteration 9354 => Loss: 0.3664417073
Iteration 9355 => Loss: 0.3664405950
Iteration 9356 => Loss: 0.3664394827
Iteration 9357 => Loss: 0.3664383705
Iteration 9358 => Loss: 0.3664372582
Iteration 9359 => Loss: 0.3664361460
Iteration 9360 => Loss: 0.3664350338
Iteration 9361 => Loss: 0.3664339217
Iteration 9362 => Loss: 0.3664328095
Iteration 9363 => Loss: 0.3664316974
Iteration 9364 => Loss: 0.3664305853
Iteration 9365 => Loss: 0.3664294732
Iteration 9366 => Loss: 0.3664283612
Iteration 9367 => Loss: 0.3664272492
Iteration 9368 => Loss: 0.3664261372
Iteration 9369 => Loss: 0.3664250252
Iteration 9370 => Loss: 0.3664239132
Iteration 9371 => Loss: 0.3664228013
Iteration 9372 => Loss: 0.3664216894
Iteration 9373 => Loss: 0.3664205775
Iteration 9374 => Loss: 0.3664194656
Iteration 9375 => Loss: 0.3664183538
Iteration 9376 => Loss: 0.3664172420
Iteration 9377 => Loss: 0.3664161302
Iteration 9378 => Loss: 0.3664150184
Iteration 9379 => Loss: 0.3664139067
Iteration 9380 => Loss: 0.3664127950
Iteration 9381 => Loss: 0.3664116833
Iteration 9382 => Loss: 0.3664105716
Iteration 9383 => Loss: 0.3664094599
Iteration 9384 => Loss: 0.3664083483
Iteration 9385 => Loss: 0.3664072367
Iteration 9386 => Loss: 0.3664061251
Iteration 9387 => Loss: 0.3664050135
Iteration 9388 => Loss: 0.3664039020
Iteration 9389 => Loss: 0.3664027905
Iteration 9390 => Loss: 0.3664016790
Iteration 9391 => Loss: 0.3664005675
Iteration 9392 => Loss: 0.3663994561
Iteration 9393 => Loss: 0.3663983447
Iteration 9394 => Loss: 0.3663972333
Iteration 9395 => Loss: 0.3663961219
Iteration 9396 => Loss: 0.3663950106
Iteration 9397 => Loss: 0.3663938992
Iteration 9398 => Loss: 0.3663927879
Iteration 9399 => Loss: 0.3663916766
Iteration 9400 => Loss: 0.3663905654
Iteration 9401 => Loss: 0.3663894541
Iteration 9402 => Loss: 0.3663883429
Iteration 9403 => Loss: 0.3663872317
Iteration 9404 => Loss: 0.3663861206
Iteration 9405 => Loss: 0.3663850094
Iteration 9406 => Loss: 0.3663838983
Iteration 9407 => Loss: 0.3663827872
Iteration 9408 => Loss: 0.3663816761
Iteration 9409 => Loss: 0.3663805651
Iteration 9410 => Loss: 0.3663794540
Iteration 9411 => Loss: 0.3663783430
Iteration 9412 => Loss: 0.3663772321
Iteration 9413 => Loss: 0.3663761211
Iteration 9414 => Loss: 0.3663750102
Iteration 9415 => Loss: 0.3663738992
Iteration 9416 => Loss: 0.3663727883
Iteration 9417 => Loss: 0.3663716775
Iteration 9418 => Loss: 0.3663705666
Iteration 9419 => Loss: 0.3663694558
Iteration 9420 => Loss: 0.3663683450
Iteration 9421 => Loss: 0.3663672342
Iteration 9422 => Loss: 0.3663661235
Iteration 9423 => Loss: 0.3663650127
Iteration 9424 => Loss: 0.3663639020
Iteration 9425 => Loss: 0.3663627913
Iteration 9426 => Loss: 0.3663616807
Iteration 9427 => Loss: 0.3663605700
Iteration 9428 => Loss: 0.3663594594
Iteration 9429 => Loss: 0.3663583488
Iteration 9430 => Loss: 0.3663572383
Iteration 9431 => Loss: 0.3663561277
Iteration 9432 => Loss: 0.3663550172
Iteration 9433 => Loss: 0.3663539067
Iteration 9434 => Loss: 0.3663527962
Iteration 9435 => Loss: 0.3663516857
Iteration 9436 => Loss: 0.3663505753
Iteration 9437 => Loss: 0.3663494649
Iteration 9438 => Loss: 0.3663483545
Iteration 9439 => Loss: 0.3663472441
Iteration 9440 => Loss: 0.3663461338
Iteration 9441 => Loss: 0.3663450235
Iteration 9442 => Loss: 0.3663439132
Iteration 9443 => Loss: 0.3663428029
Iteration 9444 => Loss: 0.3663416926
Iteration 9445 => Loss: 0.3663405824
Iteration 9446 => Loss: 0.3663394722
Iteration 9447 => Loss: 0.3663383620
Iteration 9448 => Loss: 0.3663372518
Iteration 9449 => Loss: 0.3663361417
Iteration 9450 => Loss: 0.3663350316
Iteration 9451 => Loss: 0.3663339215
Iteration 9452 => Loss: 0.3663328114
Iteration 9453 => Loss: 0.3663317013
Iteration 9454 => Loss: 0.3663305913
Iteration 9455 => Loss: 0.3663294813
Iteration 9456 => Loss: 0.3663283713
Iteration 9457 => Loss: 0.3663272614
Iteration 9458 => Loss: 0.3663261514
Iteration 9459 => Loss: 0.3663250415
Iteration 9460 => Loss: 0.3663239316
Iteration 9461 => Loss: 0.3663228217
Iteration 9462 => Loss: 0.3663217119
Iteration 9463 => Loss: 0.3663206021
Iteration 9464 => Loss: 0.3663194923
Iteration 9465 => Loss: 0.3663183825
Iteration 9466 => Loss: 0.3663172727
Iteration 9467 => Loss: 0.3663161630
Iteration 9468 => Loss: 0.3663150533
Iteration 9469 => Loss: 0.3663139436
Iteration 9470 => Loss: 0.3663128339
Iteration 9471 => Loss: 0.3663117242
Iteration 9472 => Loss: 0.3663106146
Iteration 9473 => Loss: 0.3663095050
Iteration 9474 => Loss: 0.3663083954
Iteration 9475 => Loss: 0.3663072859
Iteration 9476 => Loss: 0.3663061763
Iteration 9477 => Loss: 0.3663050668
Iteration 9478 => Loss: 0.3663039573
Iteration 9479 => Loss: 0.3663028479
Iteration 9480 => Loss: 0.3663017384
Iteration 9481 => Loss: 0.3663006290
Iteration 9482 => Loss: 0.3662995196
Iteration 9483 => Loss: 0.3662984102
Iteration 9484 => Loss: 0.3662973009
Iteration 9485 => Loss: 0.3662961915
Iteration 9486 => Loss: 0.3662950822
Iteration 9487 => Loss: 0.3662939729
Iteration 9488 => Loss: 0.3662928636
Iteration 9489 => Loss: 0.3662917544
Iteration 9490 => Loss: 0.3662906452
Iteration 9491 => Loss: 0.3662895360
Iteration 9492 => Loss: 0.3662884268
Iteration 9493 => Loss: 0.3662873176
Iteration 9494 => Loss: 0.3662862085
Iteration 9495 => Loss: 0.3662850994
Iteration 9496 => Loss: 0.3662839903
Iteration 9497 => Loss: 0.3662828812
Iteration 9498 => Loss: 0.3662817722
Iteration 9499 => Loss: 0.3662806632
Iteration 9500 => Loss: 0.3662795541
Iteration 9501 => Loss: 0.3662784452
Iteration 9502 => Loss: 0.3662773362
Iteration 9503 => Loss: 0.3662762273
Iteration 9504 => Loss: 0.3662751184
Iteration 9505 => Loss: 0.3662740095
Iteration 9506 => Loss: 0.3662729006
Iteration 9507 => Loss: 0.3662717917
Iteration 9508 => Loss: 0.3662706829
Iteration 9509 => Loss: 0.3662695741
Iteration 9510 => Loss: 0.3662684653
Iteration 9511 => Loss: 0.3662673566
Iteration 9512 => Loss: 0.3662662478
Iteration 9513 => Loss: 0.3662651391
Iteration 9514 => Loss: 0.3662640304
Iteration 9515 => Loss: 0.3662629217
Iteration 9516 => Loss: 0.3662618131
Iteration 9517 => Loss: 0.3662607045
Iteration 9518 => Loss: 0.3662595959
Iteration 9519 => Loss: 0.3662584873
Iteration 9520 => Loss: 0.3662573787
Iteration 9521 => Loss: 0.3662562702
Iteration 9522 => Loss: 0.3662551617
Iteration 9523 => Loss: 0.3662540532
Iteration 9524 => Loss: 0.3662529447
Iteration 9525 => Loss: 0.3662518362
Iteration 9526 => Loss: 0.3662507278
Iteration 9527 => Loss: 0.3662496194
Iteration 9528 => Loss: 0.3662485110
Iteration 9529 => Loss: 0.3662474026
Iteration 9530 => Loss: 0.3662462943
Iteration 9531 => Loss: 0.3662451860
Iteration 9532 => Loss: 0.3662440777
Iteration 9533 => Loss: 0.3662429694
Iteration 9534 => Loss: 0.3662418611
Iteration 9535 => Loss: 0.3662407529
Iteration 9536 => Loss: 0.3662396447
Iteration 9537 => Loss: 0.3662385365
Iteration 9538 => Loss: 0.3662374283
Iteration 9539 => Loss: 0.3662363202
Iteration 9540 => Loss: 0.3662352120
Iteration 9541 => Loss: 0.3662341039
Iteration 9542 => Loss: 0.3662329959
Iteration 9543 => Loss: 0.3662318878
Iteration 9544 => Loss: 0.3662307798
Iteration 9545 => Loss: 0.3662296717
Iteration 9546 => Loss: 0.3662285637
Iteration 9547 => Loss: 0.3662274558
Iteration 9548 => Loss: 0.3662263478
Iteration 9549 => Loss: 0.3662252399
Iteration 9550 => Loss: 0.3662241320
Iteration 9551 => Loss: 0.3662230241
Iteration 9552 => Loss: 0.3662219162
Iteration 9553 => Loss: 0.3662208084
Iteration 9554 => Loss: 0.3662197006
Iteration 9555 => Loss: 0.3662185928
Iteration 9556 => Loss: 0.3662174850
Iteration 9557 => Loss: 0.3662163772
Iteration 9558 => Loss: 0.3662152695
Iteration 9559 => Loss: 0.3662141618
Iteration 9560 => Loss: 0.3662130541
Iteration 9561 => Loss: 0.3662119464
Iteration 9562 => Loss: 0.3662108388
Iteration 9563 => Loss: 0.3662097311
Iteration 9564 => Loss: 0.3662086235
Iteration 9565 => Loss: 0.3662075159
Iteration 9566 => Loss: 0.3662064084
Iteration 9567 => Loss: 0.3662053008
Iteration 9568 => Loss: 0.3662041933
Iteration 9569 => Loss: 0.3662030858
Iteration 9570 => Loss: 0.3662019783
Iteration 9571 => Loss: 0.3662008709
Iteration 9572 => Loss: 0.3661997634
Iteration 9573 => Loss: 0.3661986560
Iteration 9574 => Loss: 0.3661975486
Iteration 9575 => Loss: 0.3661964413
Iteration 9576 => Loss: 0.3661953339
Iteration 9577 => Loss: 0.3661942266
Iteration 9578 => Loss: 0.3661931193
Iteration 9579 => Loss: 0.3661920120
Iteration 9580 => Loss: 0.3661909047
Iteration 9581 => Loss: 0.3661897975
Iteration 9582 => Loss: 0.3661886903
Iteration 9583 => Loss: 0.3661875831
Iteration 9584 => Loss: 0.3661864759
Iteration 9585 => Loss: 0.3661853687
Iteration 9586 => Loss: 0.3661842616
Iteration 9587 => Loss: 0.3661831545
Iteration 9588 => Loss: 0.3661820474
Iteration 9589 => Loss: 0.3661809403
Iteration 9590 => Loss: 0.3661798333
Iteration 9591 => Loss: 0.3661787262
Iteration 9592 => Loss: 0.3661776192
Iteration 9593 => Loss: 0.3661765122
Iteration 9594 => Loss: 0.3661754053
Iteration 9595 => Loss: 0.3661742983
Iteration 9596 => Loss: 0.3661731914
Iteration 9597 => Loss: 0.3661720845
Iteration 9598 => Loss: 0.3661709776
Iteration 9599 => Loss: 0.3661698708
Iteration 9600 => Loss: 0.3661687639
Iteration 9601 => Loss: 0.3661676571
Iteration 9602 => Loss: 0.3661665503
Iteration 9603 => Loss: 0.3661654436
Iteration 9604 => Loss: 0.3661643368
Iteration 9605 => Loss: 0.3661632301
Iteration 9606 => Loss: 0.3661621234
Iteration 9607 => Loss: 0.3661610167
Iteration 9608 => Loss: 0.3661599100
Iteration 9609 => Loss: 0.3661588034
Iteration 9610 => Loss: 0.3661576967
Iteration 9611 => Loss: 0.3661565901
Iteration 9612 => Loss: 0.3661554835
Iteration 9613 => Loss: 0.3661543770
Iteration 9614 => Loss: 0.3661532704
Iteration 9615 => Loss: 0.3661521639
Iteration 9616 => Loss: 0.3661510574
Iteration 9617 => Loss: 0.3661499509
Iteration 9618 => Loss: 0.3661488445
Iteration 9619 => Loss: 0.3661477380
Iteration 9620 => Loss: 0.3661466316
Iteration 9621 => Loss: 0.3661455252
Iteration 9622 => Loss: 0.3661444189
Iteration 9623 => Loss: 0.3661433125
Iteration 9624 => Loss: 0.3661422062
Iteration 9625 => Loss: 0.3661410999
Iteration 9626 => Loss: 0.3661399936
Iteration 9627 => Loss: 0.3661388873
Iteration 9628 => Loss: 0.3661377811
Iteration 9629 => Loss: 0.3661366749
Iteration 9630 => Loss: 0.3661355686
Iteration 9631 => Loss: 0.3661344625
Iteration 9632 => Loss: 0.3661333563
Iteration 9633 => Loss: 0.3661322502
Iteration 9634 => Loss: 0.3661311440
Iteration 9635 => Loss: 0.3661300379
Iteration 9636 => Loss: 0.3661289319
Iteration 9637 => Loss: 0.3661278258
Iteration 9638 => Loss: 0.3661267198
Iteration 9639 => Loss: 0.3661256138
Iteration 9640 => Loss: 0.3661245078
Iteration 9641 => Loss: 0.3661234018
Iteration 9642 => Loss: 0.3661222958
Iteration 9643 => Loss: 0.3661211899
Iteration 9644 => Loss: 0.3661200840
Iteration 9645 => Loss: 0.3661189781
Iteration 9646 => Loss: 0.3661178722
Iteration 9647 => Loss: 0.3661167664
Iteration 9648 => Loss: 0.3661156605
Iteration 9649 => Loss: 0.3661145547
Iteration 9650 => Loss: 0.3661134490
Iteration 9651 => Loss: 0.3661123432
Iteration 9652 => Loss: 0.3661112374
Iteration 9653 => Loss: 0.3661101317
Iteration 9654 => Loss: 0.3661090260
Iteration 9655 => Loss: 0.3661079203
Iteration 9656 => Loss: 0.3661068147
Iteration 9657 => Loss: 0.3661057090
Iteration 9658 => Loss: 0.3661046034
Iteration 9659 => Loss: 0.3661034978
Iteration 9660 => Loss: 0.3661023922
Iteration 9661 => Loss: 0.3661012867
Iteration 9662 => Loss: 0.3661001811
Iteration 9663 => Loss: 0.3660990756
Iteration 9664 => Loss: 0.3660979701
Iteration 9665 => Loss: 0.3660968647
Iteration 9666 => Loss: 0.3660957592
Iteration 9667 => Loss: 0.3660946538
Iteration 9668 => Loss: 0.3660935484
Iteration 9669 => Loss: 0.3660924430
Iteration 9670 => Loss: 0.3660913376
Iteration 9671 => Loss: 0.3660902322
Iteration 9672 => Loss: 0.3660891269
Iteration 9673 => Loss: 0.3660880216
Iteration 9674 => Loss: 0.3660869163
Iteration 9675 => Loss: 0.3660858110
Iteration 9676 => Loss: 0.3660847058
Iteration 9677 => Loss: 0.3660836006
Iteration 9678 => Loss: 0.3660824954
Iteration 9679 => Loss: 0.3660813902
Iteration 9680 => Loss: 0.3660802850
Iteration 9681 => Loss: 0.3660791799
Iteration 9682 => Loss: 0.3660780747
Iteration 9683 => Loss: 0.3660769696
Iteration 9684 => Loss: 0.3660758646
Iteration 9685 => Loss: 0.3660747595
Iteration 9686 => Loss: 0.3660736544
Iteration 9687 => Loss: 0.3660725494
Iteration 9688 => Loss: 0.3660714444
Iteration 9689 => Loss: 0.3660703394
Iteration 9690 => Loss: 0.3660692345
Iteration 9691 => Loss: 0.3660681295
Iteration 9692 => Loss: 0.3660670246
Iteration 9693 => Loss: 0.3660659197
Iteration 9694 => Loss: 0.3660648148
Iteration 9695 => Loss: 0.3660637100
Iteration 9696 => Loss: 0.3660626052
Iteration 9697 => Loss: 0.3660615003
Iteration 9698 => Loss: 0.3660603955
Iteration 9699 => Loss: 0.3660592908
Iteration 9700 => Loss: 0.3660581860
Iteration 9701 => Loss: 0.3660570813
Iteration 9702 => Loss: 0.3660559766
Iteration 9703 => Loss: 0.3660548719
Iteration 9704 => Loss: 0.3660537672
Iteration 9705 => Loss: 0.3660526625
Iteration 9706 => Loss: 0.3660515579
Iteration 9707 => Loss: 0.3660504533
Iteration 9708 => Loss: 0.3660493487
Iteration 9709 => Loss: 0.3660482441
Iteration 9710 => Loss: 0.3660471396
Iteration 9711 => Loss: 0.3660460350
Iteration 9712 => Loss: 0.3660449305
Iteration 9713 => Loss: 0.3660438260
Iteration 9714 => Loss: 0.3660427216
Iteration 9715 => Loss: 0.3660416171
Iteration 9716 => Loss: 0.3660405127
Iteration 9717 => Loss: 0.3660394083
Iteration 9718 => Loss: 0.3660383039
Iteration 9719 => Loss: 0.3660371995
Iteration 9720 => Loss: 0.3660360952
Iteration 9721 => Loss: 0.3660349908
Iteration 9722 => Loss: 0.3660338865
Iteration 9723 => Loss: 0.3660327823
Iteration 9724 => Loss: 0.3660316780
Iteration 9725 => Loss: 0.3660305737
Iteration 9726 => Loss: 0.3660294695
Iteration 9727 => Loss: 0.3660283653
Iteration 9728 => Loss: 0.3660272611
Iteration 9729 => Loss: 0.3660261570
Iteration 9730 => Loss: 0.3660250528
Iteration 9731 => Loss: 0.3660239487
Iteration 9732 => Loss: 0.3660228446
Iteration 9733 => Loss: 0.3660217405
Iteration 9734 => Loss: 0.3660206364
Iteration 9735 => Loss: 0.3660195324
Iteration 9736 => Loss: 0.3660184283
Iteration 9737 => Loss: 0.3660173243
Iteration 9738 => Loss: 0.3660162204
Iteration 9739 => Loss: 0.3660151164
Iteration 9740 => Loss: 0.3660140124
Iteration 9741 => Loss: 0.3660129085
Iteration 9742 => Loss: 0.3660118046
Iteration 9743 => Loss: 0.3660107007
Iteration 9744 => Loss: 0.3660095969
Iteration 9745 => Loss: 0.3660084930
Iteration 9746 => Loss: 0.3660073892
Iteration 9747 => Loss: 0.3660062854
Iteration 9748 => Loss: 0.3660051816
Iteration 9749 => Loss: 0.3660040778
Iteration 9750 => Loss: 0.3660029741
Iteration 9751 => Loss: 0.3660018704
Iteration 9752 => Loss: 0.3660007667
Iteration 9753 => Loss: 0.3659996630
Iteration 9754 => Loss: 0.3659985593
Iteration 9755 => Loss: 0.3659974557
Iteration 9756 => Loss: 0.3659963521
Iteration 9757 => Loss: 0.3659952485
Iteration 9758 => Loss: 0.3659941449
Iteration 9759 => Loss: 0.3659930413
Iteration 9760 => Loss: 0.3659919378
Iteration 9761 => Loss: 0.3659908342
Iteration 9762 => Loss: 0.3659897307
Iteration 9763 => Loss: 0.3659886273
Iteration 9764 => Loss: 0.3659875238
Iteration 9765 => Loss: 0.3659864203
Iteration 9766 => Loss: 0.3659853169
Iteration 9767 => Loss: 0.3659842135
Iteration 9768 => Loss: 0.3659831101
Iteration 9769 => Loss: 0.3659820068
Iteration 9770 => Loss: 0.3659809034
Iteration 9771 => Loss: 0.3659798001
Iteration 9772 => Loss: 0.3659786968
Iteration 9773 => Loss: 0.3659775935
Iteration 9774 => Loss: 0.3659764902
Iteration 9775 => Loss: 0.3659753870
Iteration 9776 => Loss: 0.3659742838
Iteration 9777 => Loss: 0.3659731806
Iteration 9778 => Loss: 0.3659720774
Iteration 9779 => Loss: 0.3659709742
Iteration 9780 => Loss: 0.3659698711
Iteration 9781 => Loss: 0.3659687679
Iteration 9782 => Loss: 0.3659676648
Iteration 9783 => Loss: 0.3659665617
Iteration 9784 => Loss: 0.3659654587
Iteration 9785 => Loss: 0.3659643556
Iteration 9786 => Loss: 0.3659632526
Iteration 9787 => Loss: 0.3659621496
Iteration 9788 => Loss: 0.3659610466
Iteration 9789 => Loss: 0.3659599436
Iteration 9790 => Loss: 0.3659588407
Iteration 9791 => Loss: 0.3659577378
Iteration 9792 => Loss: 0.3659566348
Iteration 9793 => Loss: 0.3659555320
Iteration 9794 => Loss: 0.3659544291
Iteration 9795 => Loss: 0.3659533262
Iteration 9796 => Loss: 0.3659522234
Iteration 9797 => Loss: 0.3659511206
Iteration 9798 => Loss: 0.3659500178
Iteration 9799 => Loss: 0.3659489150
Iteration 9800 => Loss: 0.3659478123
Iteration 9801 => Loss: 0.3659467096
Iteration 9802 => Loss: 0.3659456068
Iteration 9803 => Loss: 0.3659445041
Iteration 9804 => Loss: 0.3659434015
Iteration 9805 => Loss: 0.3659422988
Iteration 9806 => Loss: 0.3659411962
Iteration 9807 => Loss: 0.3659400936
Iteration 9808 => Loss: 0.3659389910
Iteration 9809 => Loss: 0.3659378884
Iteration 9810 => Loss: 0.3659367858
Iteration 9811 => Loss: 0.3659356833
Iteration 9812 => Loss: 0.3659345808
Iteration 9813 => Loss: 0.3659334783
Iteration 9814 => Loss: 0.3659323758
Iteration 9815 => Loss: 0.3659312734
Iteration 9816 => Loss: 0.3659301709
Iteration 9817 => Loss: 0.3659290685
Iteration 9818 => Loss: 0.3659279661
Iteration 9819 => Loss: 0.3659268637
Iteration 9820 => Loss: 0.3659257614
Iteration 9821 => Loss: 0.3659246590
Iteration 9822 => Loss: 0.3659235567
Iteration 9823 => Loss: 0.3659224544
Iteration 9824 => Loss: 0.3659213521
Iteration 9825 => Loss: 0.3659202499
Iteration 9826 => Loss: 0.3659191476
Iteration 9827 => Loss: 0.3659180454
Iteration 9828 => Loss: 0.3659169432
Iteration 9829 => Loss: 0.3659158410
Iteration 9830 => Loss: 0.3659147388
Iteration 9831 => Loss: 0.3659136367
Iteration 9832 => Loss: 0.3659125346
Iteration 9833 => Loss: 0.3659114325
Iteration 9834 => Loss: 0.3659103304
Iteration 9835 => Loss: 0.3659092283
Iteration 9836 => Loss: 0.3659081263
Iteration 9837 => Loss: 0.3659070242
Iteration 9838 => Loss: 0.3659059222
Iteration 9839 => Loss: 0.3659048202
Iteration 9840 => Loss: 0.3659037183
Iteration 9841 => Loss: 0.3659026163
Iteration 9842 => Loss: 0.3659015144
Iteration 9843 => Loss: 0.3659004125
Iteration 9844 => Loss: 0.3658993106
Iteration 9845 => Loss: 0.3658982087
Iteration 9846 => Loss: 0.3658971068
Iteration 9847 => Loss: 0.3658960050
Iteration 9848 => Loss: 0.3658949032
Iteration 9849 => Loss: 0.3658938014
Iteration 9850 => Loss: 0.3658926996
Iteration 9851 => Loss: 0.3658915979
Iteration 9852 => Loss: 0.3658904961
Iteration 9853 => Loss: 0.3658893944
Iteration 9854 => Loss: 0.3658882927
Iteration 9855 => Loss: 0.3658871910
Iteration 9856 => Loss: 0.3658860894
Iteration 9857 => Loss: 0.3658849877
Iteration 9858 => Loss: 0.3658838861
Iteration 9859 => Loss: 0.3658827845
Iteration 9860 => Loss: 0.3658816829
Iteration 9861 => Loss: 0.3658805813
Iteration 9862 => Loss: 0.3658794798
Iteration 9863 => Loss: 0.3658783783
Iteration 9864 => Loss: 0.3658772768
Iteration 9865 => Loss: 0.3658761753
Iteration 9866 => Loss: 0.3658750738
Iteration 9867 => Loss: 0.3658739724
Iteration 9868 => Loss: 0.3658728709
Iteration 9869 => Loss: 0.3658717695
Iteration 9870 => Loss: 0.3658706681
Iteration 9871 => Loss: 0.3658695668
Iteration 9872 => Loss: 0.3658684654
Iteration 9873 => Loss: 0.3658673641
Iteration 9874 => Loss: 0.3658662627
Iteration 9875 => Loss: 0.3658651615
Iteration 9876 => Loss: 0.3658640602
Iteration 9877 => Loss: 0.3658629589
Iteration 9878 => Loss: 0.3658618577
Iteration 9879 => Loss: 0.3658607565
Iteration 9880 => Loss: 0.3658596553
Iteration 9881 => Loss: 0.3658585541
Iteration 9882 => Loss: 0.3658574529
Iteration 9883 => Loss: 0.3658563518
Iteration 9884 => Loss: 0.3658552506
Iteration 9885 => Loss: 0.3658541495
Iteration 9886 => Loss: 0.3658530485
Iteration 9887 => Loss: 0.3658519474
Iteration 9888 => Loss: 0.3658508463
Iteration 9889 => Loss: 0.3658497453
Iteration 9890 => Loss: 0.3658486443
Iteration 9891 => Loss: 0.3658475433
Iteration 9892 => Loss: 0.3658464423
Iteration 9893 => Loss: 0.3658453414
Iteration 9894 => Loss: 0.3658442404
Iteration 9895 => Loss: 0.3658431395
Iteration 9896 => Loss: 0.3658420386
Iteration 9897 => Loss: 0.3658409378
Iteration 9898 => Loss: 0.3658398369
Iteration 9899 => Loss: 0.3658387361
Iteration 9900 => Loss: 0.3658376352
Iteration 9901 => Loss: 0.3658365344
Iteration 9902 => Loss: 0.3658354337
Iteration 9903 => Loss: 0.3658343329
Iteration 9904 => Loss: 0.3658332322
Iteration 9905 => Loss: 0.3658321314
Iteration 9906 => Loss: 0.3658310307
Iteration 9907 => Loss: 0.3658299300
Iteration 9908 => Loss: 0.3658288294
Iteration 9909 => Loss: 0.3658277287
Iteration 9910 => Loss: 0.3658266281
Iteration 9911 => Loss: 0.3658255275
Iteration 9912 => Loss: 0.3658244269
Iteration 9913 => Loss: 0.3658233263
Iteration 9914 => Loss: 0.3658222257
Iteration 9915 => Loss: 0.3658211252
Iteration 9916 => Loss: 0.3658200247
Iteration 9917 => Loss: 0.3658189242
Iteration 9918 => Loss: 0.3658178237
Iteration 9919 => Loss: 0.3658167233
Iteration 9920 => Loss: 0.3658156228
Iteration 9921 => Loss: 0.3658145224
Iteration 9922 => Loss: 0.3658134220
Iteration 9923 => Loss: 0.3658123216
Iteration 9924 => Loss: 0.3658112212
Iteration 9925 => Loss: 0.3658101209
Iteration 9926 => Loss: 0.3658090206
Iteration 9927 => Loss: 0.3658079202
Iteration 9928 => Loss: 0.3658068200
Iteration 9929 => Loss: 0.3658057197
Iteration 9930 => Loss: 0.3658046194
Iteration 9931 => Loss: 0.3658035192
Iteration 9932 => Loss: 0.3658024190
Iteration 9933 => Loss: 0.3658013188
Iteration 9934 => Loss: 0.3658002186
Iteration 9935 => Loss: 0.3657991184
Iteration 9936 => Loss: 0.3657980183
Iteration 9937 => Loss: 0.3657969182
Iteration 9938 => Loss: 0.3657958181
Iteration 9939 => Loss: 0.3657947180
Iteration 9940 => Loss: 0.3657936179
Iteration 9941 => Loss: 0.3657925179
Iteration 9942 => Loss: 0.3657914178
Iteration 9943 => Loss: 0.3657903178
Iteration 9944 => Loss: 0.3657892178
Iteration 9945 => Loss: 0.3657881179
Iteration 9946 => Loss: 0.3657870179
Iteration 9947 => Loss: 0.3657859180
Iteration 9948 => Loss: 0.3657848181
Iteration 9949 => Loss: 0.3657837182
Iteration 9950 => Loss: 0.3657826183
Iteration 9951 => Loss: 0.3657815184
Iteration 9952 => Loss: 0.3657804186
Iteration 9953 => Loss: 0.3657793188
Iteration 9954 => Loss: 0.3657782189
Iteration 9955 => Loss: 0.3657771192
Iteration 9956 => Loss: 0.3657760194
Iteration 9957 => Loss: 0.3657749196
Iteration 9958 => Loss: 0.3657738199
Iteration 9959 => Loss: 0.3657727202
Iteration 9960 => Loss: 0.3657716205
Iteration 9961 => Loss: 0.3657705208
Iteration 9962 => Loss: 0.3657694212
Iteration 9963 => Loss: 0.3657683215
Iteration 9964 => Loss: 0.3657672219
Iteration 9965 => Loss: 0.3657661223
Iteration 9966 => Loss: 0.3657650227
Iteration 9967 => Loss: 0.3657639232
Iteration 9968 => Loss: 0.3657628236
Iteration 9969 => Loss: 0.3657617241
Iteration 9970 => Loss: 0.3657606246
Iteration 9971 => Loss: 0.3657595251
Iteration 9972 => Loss: 0.3657584256
Iteration 9973 => Loss: 0.3657573262
Iteration 9974 => Loss: 0.3657562267
Iteration 9975 => Loss: 0.3657551273
Iteration 9976 => Loss: 0.3657540279
Iteration 9977 => Loss: 0.3657529285
Iteration 9978 => Loss: 0.3657518292
Iteration 9979 => Loss: 0.3657507298
Iteration 9980 => Loss: 0.3657496305
Iteration 9981 => Loss: 0.3657485312
Iteration 9982 => Loss: 0.3657474319
Iteration 9983 => Loss: 0.3657463327
Iteration 9984 => Loss: 0.3657452334
Iteration 9985 => Loss: 0.3657441342
Iteration 9986 => Loss: 0.3657430350
Iteration 9987 => Loss: 0.3657419358
Iteration 9988 => Loss: 0.3657408366
Iteration 9989 => Loss: 0.3657397374
Iteration 9990 => Loss: 0.3657386383
Iteration 9991 => Loss: 0.3657375392
Iteration 9992 => Loss: 0.3657364401
Iteration 9993 => Loss: 0.3657353410
Iteration 9994 => Loss: 0.3657342419
Iteration 9995 => Loss: 0.3657331429
Iteration 9996 => Loss: 0.3657320439
Iteration 9997 => Loss: 0.3657309448
Iteration 9998 => Loss: 0.3657298458
Iteration 9999 => Loss: 0.3657287469

Success: 25/30 (83.33%)
w=%s [[-0.37450392  0.51754011 -0.35263466  0.25625742]]
